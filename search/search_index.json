{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"conclusion/","title":"Related Sessions at Cisco Live","text":""},{"location":"conclusion/#related-sessions-at-cisco-live","title":"Related Sessions at Cisco Live","text":"<ul> <li>BRKXXX-1111 My friend's breakout session</li> </ul>"},{"location":"lab1_getting_started/","title":"Lab 1 - Getting Started","text":""},{"location":"lab1_getting_started/#lab-1-getting-started","title":"Lab 1 - Getting Started","text":""},{"location":"lab1_getting_started/#section-1","title":"Section 1","text":"<p>Please use the following credentials to connect to device:</p> <code>IP Address</code> 1.1.1.1 <code>Username</code> admin <code>Password</code> C1sco123 <p>My content</p> <p>Note</p> <p>This is a note</p> <p>Cisco IOS code block:</p> <pre><code>hostname ABC\ninterface GigabitEthernet1\n ip address 122.1.1.1\n</code></pre> <p>Image:</p> <p></p>"},{"location":"lab1_getting_started/#section-2","title":"Section 2","text":"<p>More content</p>"},{"location":"overview/","title":"Overview","text":""},{"location":"overview/#overview","title":"Overview","text":""},{"location":"overview/#learning-objectives","title":"Learning Objectives","text":"<p>This lab will give you an introduction to ...</p>"},{"location":"overview/#disclaimer","title":"Disclaimer","text":"<p>Although the lab design and configuration examples could be used as a reference, for design related questions please contact your representative at Cisco, or a Cisco partner.</p>"},{"location":"overview/#lab-access","title":"Lab Access","text":"<p>From your workstation open an RDP (Remote Desktop) session to the following host named \"wkst1\":</p> <ul> <li>IP: 1.2.3.4</li> <li>Username: corp\\demouser</li> <li>Password: C1sco12345</li> </ul>"},{"location":"overview/#getting-started","title":"Getting Started","text":"<p>This lab leverages Cisco dCloud ...</p>"},{"location":"topologies/","title":"Lab topologies","text":""},{"location":"topologies/#lab-topologies","title":"Lab topologies","text":""},{"location":"advanced/Lab1/","title":"Overview","text":""},{"location":"advanced/Lab1/#overview","title":"Overview","text":""},{"location":"advanced/Lab1/#learning-objectives","title":"Learning Objectives","text":"<p>Welcome to the AI-powered Customer &amp; Agent Experiences lab. This lab is considered an advanced lab. Take your time completing each of the steps. You have 24 hours to complete the lab with your pod user. The lab content will be available to you even after your pod is no longer available. </p> <p>In this lab, you will gain hands-on experience with Webex Contact Center's advanced AI solutions. This lab is designed to help you understand the Cisco Text-to-Speech engine and explore the capabilities of the Webex AI Agent, which utilizes built-in and proprietary models as well as natural language processing (NLP). You'll learn how to seamlessly escalate conversations from an AI agent to a human agent, ensuring efficient and intelligent customer interactions. </p> <p>In addition, we will cover several exciting AI-driven features such as Agent Wellness, which supports the well-being of agents during interactions, and Call Drop Summary, a feature that captures and summarizes previous dropped calls. These innovations demonstrate the power of AI in enhancing both customer and agent experiences. </p> <p>To further enhance your learning, we have included bonus lab content. This will allow you to familiarize yourself with our Supervisor Desktop, future enhancements to streamline Agent and Supervisor sign-in, and future AI Agent capabilities. </p> <p>Let\u2019s dive in and explore how Webex AI is shaping the future of customer service and agent support. </p>"},{"location":"advanced/Lab1/#disclaimer","title":"Disclaimer","text":"<p>Although the lab design and configuration examples could be used as a reference, for design related questions please contact your representative at Cisco, or a Cisco partner.</p>"},{"location":"graphics/Lab1/dummy/","title":"Dummy","text":""},{"location":"graphics/Lab2/dummy/","title":"Dummy","text":""},{"location":"graphics/download/1/","title":"1","text":""},{"location":"graphics/overview/dummy/","title":"Dummy","text":""},{"location":"graphics/temp/dummy/","title":"Dummy","text":""},{"location":"howToUse/admonition/","title":"Admonition","text":"<p>In addition to the  stock admonitions which are available out of the box we have added some additional branded admonitions which were created by Bobby McGonigle. </p> <p>Blank</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <pre><code>console.log('Hello Blank!')\n</code></pre> <p>Vidcast</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <pre><code>console.log('Hello Vidcast!')\n</code></pre> <p>Download</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <pre><code>console.log('Hello Download!')\n</code></pre> <p>Cedeploy</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <pre><code>console.log('Hello Ce-Deploy!')\n</code></pre> <p>Webex</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <pre><code>console.log('Hello Webex!')\n</code></pre> <p>Gif</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <pre><code>console.log('How should I pronounce Gif?')\n</code></pre> <p>Important</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <pre><code>console.log('Hello Important!')\n</code></pre> <p>Challenge</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <pre><code>console.log('Hello Challenge!')\n</code></pre> <p>Tool</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <pre><code>console.log('Hello Tool!')\n</code></pre> <p>Curious</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <pre><code>console.log('Hello Curious!')\n</code></pre>"},{"location":"howToUse/customFeatures/","title":"customFeatures","text":""},{"location":"howToUse/customFeatures/#adding-a-copy-button-without-a-code-block","title":"Adding a Copy Button Without a Code Block","text":"<p><code>This will copy the following text: &lt;copy&gt;Text to copy&lt;/copy&gt;</code> </p> <p>This will copy the following text: Text to copy</p>"},{"location":"howToUse/customFeatures/#adding-user-specific-variables-into-your-lab-guide","title":"Adding user specific variables into your lab guide","text":"<p>There may be times in which you want to embed some attendee specific information into the instructions of your lab guide, like credentials or phone numbers, which will be used on multiple pages of your lab guide.  You can gather the information via a form or you can pass a pre-encoded JSON string as a URL parameter to populate the variable values into the browser's session storage.  Then you can use a simple HTML tag with a special class name to update the values in the lab guide.  This feature can be combined with the copy button method above.</p>"},{"location":"howToUse/customFeatures/#form-method","title":"Form Method","text":"Show me the code <pre><code>&lt;form id=\"info\"&gt;\n\n\n&lt;label for=\"Admin\"&gt;Admin Login:&lt;/label&gt;\n&lt;input type=\"text\" id=\"Admin\" name=\"Admin\"&gt;&lt;br&gt;\n\n&lt;label for=\"PW\"&gt;Admin Password:&lt;/label&gt;\n&lt;input type=\"text\" id=\"PW\" name=\"PW\"&gt;&lt;br&gt;\n\n&lt;label for=\"EP\"&gt;Inbound Channel Name:&lt;/label&gt;\n&lt;input type=\"text\" id=\"EP\" name=\"EP\"&gt;&lt;br&gt;\n\n&lt;label for=\"DN\"&gt;Inbound Channel Phone Number:&lt;/label&gt;\n&lt;input type=\"text\" id=\"DN\" name=\"DN\"&gt;&lt;br&gt;\n\n&lt;label for=\"Queue\"&gt;Queue 1 Name:&lt;/label&gt;\n&lt;input type=\"text\" id=\"Queue\" name=\"Queue\"&gt;&lt;br&gt;\n\n&lt;label for=\"Queue2\"&gt;Queue 2 Name:&lt;/label&gt;\n&lt;input type=\"text\" id=\"Queue2\" name=\"Queue2\"&gt;&lt;br&gt;\n\n&lt;label for=\"Team\"&gt;Team 1 Name:&lt;/label&gt;\n&lt;input type=\"text\" id=\"Team\" name=\"Team\"&gt;&lt;br&gt;\n\n&lt;label for=\"Team2\"&gt;Team 2 Name:&lt;/label&gt;\n&lt;input type=\"text\" id=\"Team2\" name=\"Team2\"&gt;&lt;br&gt;\n&lt;br&gt;\n&lt;button onclick=\"setValues()\"&gt;Update Lab Guide&lt;/button&gt;\n&lt;/form&gt;\n</code></pre> Example Input Form Admin Login: Admin Password: Inbound Channel Name: Inbound Channel Phone Number: Queue 1 Name: Queue 2 Name: Team 1 Name: Team 2 Name: Update Lab Guide <p>Login: Provided by proctor</p> <p>Password: Provided by proctor</p> <p>Assigned Inbound Channel Name: Provided by proctor</p> <p>Assigned Inbound Channel Number: Provided by proctor</p> <p>Assigned Queue Name 1: Provided by proctor</p> <p>Assigned Queue Name 2: Provided by proctor</p> <p>Assigned Team name 1: Provided by proctor</p> <p>Assigned Team name 2: Provided by proctor</p>"},{"location":"howToUse/customFeatures/#url-method","title":"URL Method","text":"<p>If you have a lot of attendee variables in your lab, you may choose to precompile and encode them so that you can simply provide a URL link which will load all of their required information.</p> <p>To see this in action, add this string at the end of the URL for any page on this site: ?eyJBZG1pbiI6ImFkbWluQHh5ei5iaXoiLCJQVyI6InNVcGVyU2VjcmV0MTIzISIsIkVQIjoiRVAxIiwiRE4iOiIrMTkxMDU1NTEyMTUyIiwiUXVldWUiOiJRdWV1ZTEiLCJRdWV1ZTIiOiJRdWV1ZTIiLCJUZWFtIjoiVGVhbTEiLCJUZWFtMiI6IlRlYW0yIn0=</p>"},{"location":"howToUse/initialSetup/","title":"Initial Setup","text":""},{"location":"howToUse/initialSetup/#initial-setup","title":"Initial Setup","text":"<p>This lab guide template uses MKDocs to take your markdown documentation and transform it into an interactive web based lab guide.  You will need to install some software on your PC or Mac in order to take full advantage of the tool which will allow you to view your changes as you save them and ensure that your formatting is exactly how you want it.</p>"},{"location":"howToUse/initialSetup/#prerequisite-software-to-install","title":"Prerequisite Software to Install","text":"<ol> <li>Python</li> <li>Visual Studio Code</li> <li>Git</li> </ol>"},{"location":"howToUse/initialSetup/#setting-up-your-lab-guide-on-your-computer","title":"Setting up your lab guide on your computer","text":""},{"location":"howToUse/initialSetup/#clone-your-repository-with-git","title":"Clone your repository with git","text":"<p>Open Visual Studio Code</p> <p>Click the Source Control button in the left menu </p> <p>Click Clone Repository</p> <p>Enter the repository source:  https://github.com/WebexCC-SA/WebexCC-SA/WxCC_Suggested_Responses.git</p> <p>Select or create a new folder to clone the repository into.</p>"},{"location":"howToUse/initialSetup/#build-the-environment","title":"Build the environment","text":"<p>When prompted to open the cloned repository, select open.</p> <p>Drag open the terminal at the bottom of the Visual Studio Code window</p> Show Me <p></p> If you are on a PCIf you are on a Mac <p>In your terminal enter the following commands:</p> <p>python -m venv venv</p> <p>Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser</p> <p>venv\\Scripts\\activate.ps1</p> <p>pip install -r requirements.txt</p> <p>mkdocs serve</p> <p>Open a browser to http://127.0.0.1:8000 </p> <p>In your terminal enter the following commands:</p> <p>python -m venv venv</p> <p>source venv/bin/activate</p> <p>pip install -r requirements.txt</p> <p>mkdocs serve</p> <p>Open a browser to http://127.0.0.1:8000</p>"},{"location":"howToUse/postInitial/","title":"Using the tool after the initial setup","text":""},{"location":"howToUse/postInitial/#using-the-tool-after-the-initial-setup","title":"Using the tool after the initial setup","text":"<p>After the initial setup you will only need to take the following steps:</p> <p>Open Visual Studio Code</p> <p>Click the Source Control button in the left menu </p> <p>Click Open Folder and navigate to the folder where you cloned the repository</p> If you are on a PCIf you are on a Mac <p>In your terminal enter the following commands:</p> <p>venv\\Scripts\\activate.ps1</p> <p>mkdocs serve</p> <p>Open a browser to http://127.0.0.1:8000</p> <p>In your terminal enter the following commands:</p> <p>source venv/bin/activate</p> <p>mkdocs serve</p> <p>Open a browser to http://127.0.0.1:8000</p>"},{"location":"howToUse/references/","title":"References","text":""},{"location":"howToUse/references/#mk-docs-feature-reference","title":"MK Docs Feature Reference:","text":"<p>https://squidfunk.github.io/mkdocs-material/reference/ </p>"},{"location":"howToUse/references/#markdown-cheat-sheets","title":"Markdown Cheat Sheets:","text":"<p>https://www.markdownguide.org/cheat-sheet/ </p> <p>https://github.com/lifeparticle/Markdown-Cheatsheet </p>"},{"location":"howToUse/syncChanges/","title":"Publishing Your Changes","text":""},{"location":"howToUse/syncChanges/#publishing-your-changes","title":"Publishing Your Changes","text":"<p>As you progress with the creation of your lab guide, you should sync your changes periodically to GitHub.  </p>"},{"location":"howToUse/syncChanges/#syncing-your-changes-to-github","title":"Syncing your changes to GitHub","text":"<p>Make sure that you have saved all of the files you want to sync up to the repository</p> <p>Click the Source Control button in the left menu </p> <p>Click the plus sign next to each file you want to sync as you hover over the file names or alternatively, click the plus sign next to changes</p> <p>Enter a note about the changes you are making in the message text box</p> <p>Click the down chevron  on the commit button to reveal more options</p> <p>Select Commit &amp; Sync </p>"},{"location":"howToUse/syncChanges/#after-you-sync-your-changes-it-will-take-a-few-minutes-for-github-actions-to-build-the-website-so-that-you-can-view-all-of-the-changes-you-made","title":"After you Sync your changes, it will take a few minutes for GitHub Actions to build the website so that you can view all of the changes you made.","text":""},{"location":"main/AIAgentTrack_Mission1/","title":"Mission 1: Create AI Autonomous Agent.","text":""},{"location":"main/AIAgentTrack_Mission1/#mission-1-create-ai-autonomous-agent","title":"Mission 1: Create AI Autonomous Agent.","text":""},{"location":"main/AIAgentTrack_Mission1/#mission-overview","title":"Mission overview","text":"<p>Your mission is to:</p> <p>Create an AI agent and upload the knowledge base (KB) to enable the agent to provide answers about available flowers and assist customers with creating an order.</p>"},{"location":"main/AIAgentTrack_Mission1/#build","title":"Build","text":""},{"location":"main/AIAgentTrack_Mission1/#task-1-creating-new-ai-agent-with-knowladge-base","title":"Task 1. Creating new AI Agent with Knowladge Base.","text":"<ol> <li> <p>[IMPORTANT] Download .xlsx the file Flowrs_Catalog.     </p> <p>Flower_Catalog.xlsx - file contains information on the available single flowers and bouquets, including the price of the flowers or bouquets and occasions that suit the flowers. </p> </li> <li> <p>Open up and review the file.      </p> </li> <li> <p>Ignore if already logged-in into Control hub with your Admin user. Login into Webex Control Hub by using your Admin profile wxcclabs+admin_ID@gmail.com. You will see another login screen with OKTA on it where you may need to enter the email address again and the password provided to you.</p> </li> <li> <p>Go to Contact Center from the left side navigation panel, and under Quick Links, click on Webex AI Agent</p> <p> </p> </li> <li> <p>In AI Agent Builder navigate to Knowledge from left hand side menu panel. </p> </li> <li> <p>Click Create Knowledge Base, provide Knowledge base name as _2000_AI_KB, then click Create.</p> <p></p> </li> <li> <p>Click Add File or drag and drop file Flower_Catalog.xlsx you downloaded from external drive on Step 1. Then click Process Files. Wait until the file is processed. It could take 1-2 mins.</p> <p></p> <p>[Read Only] : You can also natively create a Knowledge Base document by Clicking Documents then Create Document and paste the content. Save it.  </p> </li> <li> <p>Navigate to Dashboard from the right-hand side menu panel and click Create Agent </p> </li> <li>Select Start from Scratch and click Next</li> <li> <p>On Create an AI agent page select the following select the type of agent: Autonomous</p> </li> <li> <p>New section Add the essential details will appear. Provide the following information, then click Create:</p> <p>Agent Name: _2000_AutoAI_Lab</p> <p>System ID is created automatically</p> <p>AI engine: Webex AI Pro 1.0</p> <p>Agent's goal: This is Flower Shop. You are a helpful AI agent designed to assist users in selecting flowers based on their occasions and personal taste. You can also set up delivery and send a confirmation SMS with the order details.</p> <p></p> </li> <li> <p>Customize the Welcome message with: Hi there, my name is Blossom, the AI Agent. How can I assist you?</p> <p></p> </li> <li> <p>In the instructions add additional specific guidlines that you would like the AI Agent to follow. Just copy the text below and paste it to the Instractions section: </p> <p>Always first check what is the event for the flowers so you can provide the best option. </p> <p>Always print the total at the end of the conversation at any stage.</p> <p>Assist in Flower Selection: Provide information on individual flowers, including descriptions, prices, and symbolic meanings. Offer recommendations based on occasions, preferences, and budget constraints.</p> <p>Guide in Bouquet Creation: Suggest bouquet options tailored to specific occasions such as weddings, anniversaries, birthdays, and more. Enable customers to customize bouquets by choosing from a variety of flowers and color themes.</p> <p>Enhance Customer Experience: Offer personalized advice by understanding customer needs and preferences. Ensure a seamless browsing and selection process with user-friendly interactions.</p> <p>Educate Customers: Provide educational insights into the meanings and symbolism of different flowers to aid in thoughtful selection. Share care tips for maintaining flower freshness and longevity.</p> <p>Facilitate Transactions: Assist customers in placing orders efficiently, ensuring accuracy and satisfaction. Provide support for payment processing and order confirmations.</p> <p>Ensure Availability and Freshness: Inform customers about seasonal availability to help them make timely selections. Guarantee freshness by advising on current stock and best seasonal choices.</p> <p>Promote Special Offers: Highlight promotions, discounts, and special packages to attract and retain customers. Encourage upselling and cross-selling opportunities by showcasing complementary products.</p> <p>Ask if the customer needs the deliver. Collect the address and add price of the delivery to the Total. </p> <p>Always read back the address that customer provided and ask for confirmation if it is correct. If it is not correct, ask to provide the address again.</p> <p>Always ask if the customer needs to confirmation SMS before completing the order. </p> </li> <li> <p>Switch to Knowledge tab and from Knowledge base drop-down list select _2000_AI_KB.     </p> </li> <li> <p>Click Publish. Provide any version name in popped up window (ex. \"1.0\"). </p> </li> </ol>"},{"location":"main/AIAgentTrack_Mission1/#task-2-test-your-ai-agent","title":"Task 2. Test your AI Agent","text":"<ol> <li> <p>Click on Preview and testing the AI Agent to understnad how it behaives using Chat channel. You can start the conversation with: I need flower for my friend. And try to customize you order.  </p> </li> <li> <p>Click on Preview and testing the AI Agent to understnad how it behaives using Voice channel. You can start the conversation with: \"I need flower for my friend\" and try to customize you order. </p> <p>Note: This Lab is being conducted in a classroom with approximately 30 attendees. Environmental factors, such as background noise and other attendees speaking next to you, may affect the response accuracy. For best results, it is strongly recommended to use computer headphones, if available.</p> </li> </ol> <p></p> <p>Congratulations, you have officially completed this mission! \ud83c\udf89\ud83c\udf89 </p>"},{"location":"main/AIAgentTrack_Mission3/","title":"Mission 3: Seamless AI to Human Agent Handoffs","text":""},{"location":"main/AIAgentTrack_Mission3/#mission-3-seamless-ai-to-human-agent-handoffs","title":"Mission 3: Seamless AI to Human Agent Handoffs","text":"<p>Note</p> <p>This task relies on completing Mission 7 of the Fundamental Labs. Ensure that mission is completed to have a fully functional AI Scripted Agent feature in the Contact Center.</p>"},{"location":"main/AIAgentTrack_Mission3/#story","title":"Story","text":"<p>This lab is designed to explore how to pass contextual intelligence from AI Agents to Webex Contact Center agents. It involves leveraging AI Summaries for Webex AI  agent conversational transcripts . By completing this lab, you will gain practical skills and knowledge on how to provide the right context to agents to better handle customer queries.</p>"},{"location":"main/AIAgentTrack_Mission3/#call-flow-overview","title":"Call Flow Overview","text":"<ol> <li>A new call enters the flow.</li> <li>The AI Agent engages with the caller by asking pre-configured questions.</li> <li>The AI Agent gathers all necessary details and hands the call back to the flow.</li> <li>The flow utilizes the last identified intent to route the call appropriately.</li> </ol>"},{"location":"main/AIAgentTrack_Mission3/#mission-details","title":"Mission Details","text":"<p>Your mission is to:</p> <ol> <li>Configure a smoth handoff to live human agent from AI Agent.</li> <li>Modify Virtual Agent transcript</li> <li>Configure routing based on last used intent</li> <li>Use AI Assistant</li> </ol>"},{"location":"main/AIAgentTrack_Mission3/#build","title":"Build","text":""},{"location":"main/AIAgentTrack_Mission3/#transfer-to-human-agent","title":"Transfer to Human Agent","text":"<ol> <li> <p>Before you start this lab, please make sure the webex contact center Your_Attendee_ID_Channel is set your TaskBot_Flow_Your_Attendee_ID.</p> <p> </p> </li> <li> <p>In Control Hub select Contact Center from the left panel and then navigate to Flows from the left panel. Search and open your flow TaskBot_Flow_Your_Attendee_ID. </p> </li> <li> <p>Switch the Edit button to On to enable Edit mode in the flow builder then drag and drop following nodes:</p> <ul> <li>Queue Contact activity onto the Flow from the left side panel</li> </ul> <p>Connect the Escalated path from the Virtual Agent V2 activity to the Queue Contact activity.</p> <p>Connect the Queue Contact activity to the Play Music activity</p> <p>Connect the Failure path from the Queue Contact activity to the Disconnect Contact activity.</p> <p>Queue name: Your_Attendee_ID_Queue </p> <ul> <li>Play Music</li> </ul> <p>Create a loop by connecting the Play Music activity back to itself - to create a music loop, following the diagram provided.</p> <p>Connect the Failure path from the Play Music activity to the Disconnect Contact activity.</p> <p>Music File: defaultmusic_on_hold.wav </p> </li> <li> <p>Validate and Publish Flow. In popped up window click on dropdown menu to select Latest label, then click Publish </p> <p></p> </li> </ol>"},{"location":"main/AIAgentTrack_Mission3/#checkpoint-transfer-to-human-agent","title":"Checkpoint: Transfer to Human Agent","text":"<ol> <li>Your Agent desktop session should be still active but if not, use Webex CC Desktop application  and login with agent credentials you have been provided wxcclabs+agent_IDYour_Attendee_ID@gmail.com. You will see another login screen with OKTA on it where you may need to enter the email address again and the password provided to you. </li> <li>Select Team Your_Attendee_ID_Team. Click Submit. Allow browser to access Microphone by clicking Allow on ever visit.</li> <li> <p>Make your agent Available and you're ready to make a call.</p> <p></p> </li> <li> <p>Dial the support number assigned to your Your_Attendee_ID_Channel channel and during the conversation with the virtual Agent, say, \"Please transfer me to an Agent.\" Answer the call on the agent desktop when you receive a ring notification and verify the trasciption is passed to Agent Desktop.</p> </li> <li> <p>Once the call is answered, disconnect the call by clicking on the End button.</p> <p></p> </li> </ol>"},{"location":"main/AIAgentTrack_Mission3/#disable-virtual-agent-transcript","title":"Disable Virtual Agent Transcript","text":"<ol> <li>Open your flow TaskBot_Flow_Your_Attendee_ID and switch Edit: Off mode to Edit: On if it's not.</li> <li>Select the Virtual Agent v2 activity and, in the right side panel, scroll down and notice the option for Enable Conversation Transcript.</li> <li>Disable the Virtual Agent v2 transcript by unchecking Enable Conversation Transcript option.</li> <li> <p>Validate and Publish Flow. In popped up window click on dropdown menu to select Latest label, then click Publish .</p> <p></p> </li> </ol>"},{"location":"main/AIAgentTrack_Mission3/#checkpoint-disable-virtual-agent-transcript","title":"Checkpoint: Disable Virtual Agent Transcript","text":"<ol> <li>Make sure your agent is Available and if not, login to you Desktop as explained in previous Quick Test (see above)</li> <li> <p>Dial into the same support and observe that the conversation transcript is Not available on the Agent Desktop when Enable Conversation Transcript is unchecked.</p> <p></p> </li> </ol>"},{"location":"main/AIAgentTrack_Mission3/#routing-based-on-last-intent","title":"Routing Based on Last Intent","text":"<ol> <li> <p>[IMPORTANT] Please make sure to Enable the Virtual Agent transcript by checking Enable Conversation Transcript option for the Virtual Agent V2 activity. Select the Virtual Agent V2 activity and, in the right side panel, scroll down and notice the option for Enable Conversation Transcript. </p> </li> <li> <p>Enable the Virtual Agent v2 transcript by checking Enable Conversation Transcript option.</p> <p></p> </li> <li> <p>Add 2 new flow variables: </p> <p>Name: <code>last_intent</code></p> <p>Type: <code>String</code></p> <p>Default Value: <code>empty</code></p> <p>Name: <code>vameta</code></p> <p>Type: <code>JSON</code></p> <p>Default Value: <code>{}</code> </p> <p></p> </li> <li> <p>Drag Set Variable node to canvas:</p> <p>Activity Name: <code>VA_Metadata</code></p> <p>Variable: <code>vameta</code></p> <p>Set To Variable: <code>VirtualAgentV2_</code>&lt;&gt;<code>.MetaData</code></p> <p>Connect <code>Escalated</code> edge of VirtualAgent to the VA_Metadata node </p> <p>Note</p> <p>&lt;*&gt; in VirtualAgentV2 name is autogenerated and is different in all cases. You shouldn't be confused as you have only one VirtualAgentV2 node in the current flow</p> <p></p> </li> <li> <p>Drag and drop the Parse activity to the flow</p> <p>Connect the VA_Metadata activity to the Parse activity.</p> <p>Input variable: <code>VirtualAgentV2_</code>&lt;&gt;<code>.MetaData</code></p> <p>Content Type: <code>JSON</code></p> <p>Output Variable: <code>last_intent</code></p> <p>Path Expression: <code>$.previous-intent.name</code></p> <p></p> </li> <li> <p>Drag and drop the Condition activity to the flow</p> <p>Connect the Parse activity to the Condition activity.</p> <p>Connect the False output from the Condition activity to the Queue Contact activity</p> <p>Condition : False</p> </li> <li> <p>Add Play Message: </p> <p>Enable Text-To-Speech</p> <p>Select the Connector: Cisco Cloud Text-to-Speech</p> <p>Click the Add Text-to-Speech Message button and paste text: Routing to an agent skilled at booking an appointment.</p> <p>Delete the Selection for Audio File</p> <p>Connect True exit path of Condition node created in Step 5 to this Play Message node</p> <p>Connect Play Message node to Queue Contact </p> </li> <li> <p>Validate and Publish Flow. In popped up window click on dropdown menu to select Latest label, then click Publish </p> <p></p> </li> </ol>"},{"location":"main/AIAgentTrack_Mission3/#checkpoint-last-intent-based-routing","title":"Checkpoint: Last Intent Based Routing","text":"<ol> <li>Make sure your agent is Available and if not, login to you Desktop as explained in previous Quick Test (see above)</li> <li> <p>Make a call to your test number. During your interaction with the Virtual Agent start requesting for an appointement and then request a transfer to a live agent by saying, \"Please transfer me to an Agent.\" If the last intent was \"Book appointment\", you will hear the Text-to-Speech message: \"Routing to an agent skilled at booking an appointment.\". </p> <p>Sample Conversation</p> <p>\"I would like to Book  an appointment\"</p> <p>What date are you considering for your visit </p> <p>\"Feb 20th\"</p> <p>Could tell us preferred time for your visit </p> <p>\"3PM\"</p> <p>Which doctor you want appointment with</p> <p>\"Dr John\"</p> <p>What is name of the  patience </p> <p>\"Peter\"</p> <p>Could you tell us patience Date of Birth</p> <p>\"Please transfer me to an agent \"</p> </li> <li> <p>Answer the call on the agent desktop when it rings.</p> </li> <li>Go back to your flow and click on Analyze tab at the bottom of the canvas. Observe the last call behavior.</li> <li> <p>Open Debug tool and open your last call. Click on VA_Metadata which is our renames Set Variable. See that metadata from VirtualAgentV2_&lt;*&gt;.MetaData was written into vameta flow variable we created on Step 3.   </p> </li> <li> <p>Copy JSON from debuger and paste it into https://jsonpath.com/ Inputs.</p> </li> <li>Change Debug mode to Design in Flow Designer and copy the path from Parse node into JSONPath of the https://jsonpath.com/. You should get last intent name as \"Book Apppointement\"</li> </ol> <p></p>"},{"location":"main/AIAgentTrack_Mission3/#checkpoint-ai-assistant","title":"Checkpoint: AI assistant","text":"<ol> <li> <p>Click on the AI assistant icon located on the top left navigation panel.</p> <p></p> </li> <li> <p>Dial the support number assigned to your Your_Attendee_ID_Channel and initiate a conversation with below</p> </li> <li> <p>During the interaction with the virtual Agent, request a transfer by saying, \"Please transfer me to an Agent.\" Answer the call on the agent desktop upon receiving the ring notification.</p> </li> <li> <p>Observe that, after answering the call, a summary of the Virtual Agent interaction is now displayed on the agent desktop</p> </li> </ol> <p></p> <p>Congratulations, you have officially completed the Intelligent Virtual Agent Handoffs mission! \ud83c\udf89\ud83c\udf89 </p>"},{"location":"main/AIAgentTrack_Mission5/","title":"AIAgentTrack Mission5","text":""},{"location":"main/AIAgentTrack_Mission5/#story","title":"Story","text":"<p>The mission is designed to provide a hands-on understanding of creating Cisco Virtual Agents, covering key tasks such as creating a virtual agent using a template, integrating the bot with flow for voice calls, updating bot responses, adding new intents and entities, enhancing training data using generative AI, and leveraging bot transcripts and analytics for insights.</p>"},{"location":"main/AIAgentTrack_Mission5/#call-flow-overview","title":"Call Flow Overview","text":"<ol> <li>A new call enters the flow. </li> <li>The AI Agent interacts with the caller by asking configured questions. </li> <li>The AI Agent ends the conversation after collecting all the necessary details. </li> </ol>"},{"location":"main/AIAgentTrack_Mission5/#mission-details","title":"Mission Details","text":"<p>This mission is designed to provide an in-depth understanding of the Webex AI Agents available in Webex Contact Center. By completing this section of the lab, you will:</p> <ul> <li>Gain practical skills and knowledge on how to effectively utilize Webex Contact Center's AI capabilities to create self-service automation.v</li> <li>Improve the containment rate of your contact center, increasing efficiency and reducing costs.</li> <li>Learn how to create an effective AI Voice solution using Cisco's Webex Connect Bot builder platform and Webex Contact Center Flow Designer.</li> <li>Understand the use of Generative AI to fast-track bot development and save time.</li> <li>Troubleshoot AI Agent functionality to enhance performance.</li> </ul>"},{"location":"main/AIAgentTrack_Mission5/#build","title":"Build","text":""},{"location":"main/AIAgentTrack_Mission5/#creating-a-ai-agent-using-a-template","title":"Creating a AI Agent using a Template","text":"<ol> <li> <p>Login into Webex Control Hub by using your Admin profile wxcclabs+admin_IDYour_Attendee_ID@gmail.com. You will see another login screen with OKTA on it where you may need to enter the email address again and the password provided to you.</p> </li> <li> <p>Go to Contact Center from the left side navigation panel, and under Quick Links, click on Webex AI Agent</p> <p> </p> </li> <li> <p>Click on Create agent to create a new bot. Select the Appointment Booking Template and click on Next button.</p> </li> <li>Agent Name Your_Attendee_ID_TaskBot_CL2025 and click Create</li> <li>Make the bot live by clicking on the Make Live button on the top right.</li> <li> <p>Enter v1 in the popup modal which appears after clicking on Make Live.</p> <p> </p> </li> <li> <p>Click on the Preview button on the top right side to test the bot. Try the bot flow by typing \"I would like to cancel an appointment\"</p> <p>Sample Conversation</p> <p>AI Agent: Welcome to Cumulus Healthcare. How may I assist you today? You: \"I would like to cancel an appointment\" AI Agent: Please provide the patient's 6-digit insurance number. You:\"123456\" AI Agent: Please provide your 10-digit phone number. You:\"0123456789\" AI Agent: You have an appointment on 20/01/2025 at 15:00. Would you like to cancel it? You:\"yes\" AI Agent: Your appointment for 20/01/2025 at 15:00 is cancelled.</p> <p> </p> </li> </ol>"},{"location":"main/AIAgentTrack_Mission5/#integrating-the-bot-with-flow-for-voice-calls","title":"Integrating the Bot with Flow for Voice Calls","text":"<ol> <li> <p>In Control Hub navigate to Flows, click on Manage Flows dropdown list and select Create Flows</p> </li> <li> <p>Select Start Fresh and name the new flow TaskBot_Flow_Your_Attendee_ID.</p> <p> </p> </li> <li> <p>Make sure the Edit mode at the top is set to ON. Then, drag and drop the Virtual Agent V2 and DisconnectContact activity from the left panel onto the canvas.</p> <p>Note</p> <p>Please make sure to use VirtualAgentV2 activity and NOT VirtualAgent also present on the Activity Library for Backward Compatability.</p> <p>Connect the New Phone Contact output node edge to this VirtualAgentV2 node</p> <p>Connect the Handled outputs to DisconnectContact </p> <p>Connect the Escalated outputs to DisconnectContact </p> <p>Connect the Errored outputs to DisconnectContact </p> <p>Select Static Contact Center AI Config</p> <p>Contact Center AI Config: Webex AI Agent (Scripted)</p> <p>Virtual Agent: Your_Attendee_ID_TaskBot_CL2025</p> </li> <li> <p>On bottom right corner toggle Validation from Off to On</p> </li> <li> <p>Click Publish Flow. In Popped up window click on dropdown menu to select Latest label, then click Publish</p> <p> </p> </li> <li> <p>Assign the Flow to your Channel (Entry Point) - Do this by first going to Channel, search for your channel Your_Attendee_ID_Channel.</p> </li> <li>Click on Your_Attendee_ID_Channel</li> <li> <p>In Entry Point Settings section change the following:</p> <p>Routing Flow: TaskBot_Flow_Your_Attendee_ID</p> <p>Version Label: Latest</p> <p> </p> </li> <li> <p>Dial Support Number assigned to your Your_Attendee_ID_Channel to test the Virtual Agent over a voice call.</p> </li> </ol>"},{"location":"main/AIAgentTrack_Mission5/#updating-bot-responses","title":"Updating Bot Responses","text":"<p>In this step, we will learn how to update bot responses and test these changes, both in preview mode and by making a live call. Testing in preview mode allows you to ensure the changes worked as expected, while making a live call confirms the bot's performance in a real-world scenario.</p> <ol> <li> <p>Login into Webex Control Hub by using your Admin profile wxcclabs+admin_IDYour_Attendee_ID@gmail.com. You will see another login screen with OKTA on it where you may need to enter the email address again and the password provided to you.</p> </li> <li> <p>Go to Contact Center from the left side navigation panel, and under Quick Links, click on Webex AI Agent</p> <p> </p> </li> <li> <p>Search and open your bot Your_Attendee_ID_TaskBot_CL2025 that you created earlier. Then go to the Responses tab on the left-hand panel.</p> <p>Select the Welcome message in Default message</p> <p>Update the text to \"Welcome to Cumulus Healthcare. How may I assist you today?\" for the Default (web) channel.</p> <p>Navigate to the Voice Channel and update the text to \"Welcome to Cumulus Healthcare. How may I assist you today?\"</p> <p>Click on the update button to confirm the changes. Make the bot live by clicking on the Make Live button</p> <p> </p> </li> <li> <p>Click on Preview to test if the Greeting has been successfully updated.</p> <p></p> </li> </ol>"},{"location":"main/AIAgentTrack_Mission5/#adding-new-intents-entities","title":"Adding New Intents &amp; Entities","text":"<p>In this step, we will learn how to add new intents and entities to enhance the bot's ability to understand and respond to a broader range of user inputs. These updates will be tested in both preview mode and during a live call to confirm that the bot correctly identifies the new intents and entities and provides appropriate responses.</p> <ol> <li> <p>To expedite the completion of this lab, it is recommended to remove all languages except the default language(English), and proceed with the lab. After disabling all the languages please make sure to hit on Save changes and you should see a green Agent updated message that confirms the action. </p> <p></p> </li> <li> <p>Navigate to the Training Tab from the left-hand panel and click on the Create Intent button located in the top right corner.</p> </li> <li> <p>Add a new intent by providing the intent name as ReferralRequest and include the following two utterances:</p> <ul> <li>I would like a referral for a cardiologist.</li> <li>I need a referral to visit a neurologist.</li> </ul> <p> </p> </li> <li> <p>Click on Link entity and add patient phone number as an entity.</p> <p>Check the Required checkbox </p> <p>Select the template key as askPhoneNumber, which will be used to prompt the patient for their phone number.</p> </li> <li> <p>Again, click on Link Entity and add patient dob (date of birth) </p> <p>Check Required checkbox</p> <p>Select the template key as askPatientDob. When this intent is matched, it will trigger the Virtual Agent to ask the user to provide their phone number and date of birth for verification purposes.</p> <p> </p> </li> <li> <p>On the same page at the bottom, click on Response drop-down list with Final Template Key and scroll down to Create new.</p> <p>Template key: ReferralResp</p> <p>Text Response (Optional): Your request has been logged and will be reviewed by our team. You will receive a callback once it's approved. Is there anything else I can assist you with?</p> <p>Click Create</p> </li> <li> <p>Click on Save.</p> <p> </p> </li> <li> <p>Return to the Training tab and click on the Train button to update the bot's understanding with the new intent and entities.</p> </li> <li>Add a comment such as Added referral request intent to track the changes.</li> <li>Click on Make Live to update the live version of the bot with these changes.</li> <li> <p>Provide a description for the update and choose Make Live or Make Live both if there are other unsaved changes pending.</p> <p> </p> </li> <li> <p>Use the Preview feature to test the bot flow with the input query: I need a referral for a cardiologist.</p> </li> <li> <p>You can also test this interaction in voice mode by dialing the Supported Number assigned to your pod.</p> <p> </p> </li> </ol>"},{"location":"main/AIAgentTrack_Mission5/#adding-training-data-using-generative-ai","title":"Adding Training Data using Generative AI","text":"<p>In this step, we will learn how to enhance the bot's capabilities by adding training data using generative AI and validate the changes by making a call.</p> <ol> <li> <p>Return to the Referral Request intent that you created in the previous exercise.</p> </li> <li> <p>Click on the \"Generate\" button to utilize Generative AI for creating additional training phrases.</p> </li> <li> <p>Enter a description such as \"generate intents for requesting a referral to different doctor specialties from primary care.\" Set the Number of Variants to 10, which will determine the number of new phrases to be generated.</p> <p> </p> </li> <li> <p>Once the new phrases are generated, click on the Save button located in the top right corner to add them to your intent.</p> </li> <li>Navigate back to the Training tab and click on the Train button to incorporate the new generative data into the bot's model.</li> <li>Add a comment such as \"added generative training data\" to keep track of this specific update.</li> <li>Click on the Make Live button situated in the top right corner to apply the changes to the live version of your bot.</li> <li> <p>Confirm the update by clicking on Make Live or Make Live both if there are other unsaved changes pending.</p> <p> </p> </li> <li> <p>Test the updated bot flow by using the Preview button and inputting queries related to the new training data.</p> <p></p> </li> </ol>"},{"location":"main/AIAgentTrack_Mission5/#bot-transcripts-analytics","title":"Bot Transcripts &amp; Analytics","text":"<p>In this step, we will explore how to access and analyze bot transcripts and analytics to gain insights into user interactions.</p> <ol> <li> <p>Click on Sessions in the left-hand panel of your bot builder interface to view all the call history. Click on any Session ID to delve into a more detailed analysis of that particular interaction.</p> </li> <li> <p>If you encounter encrypted content, click on Decrypt Content to proceed with the review.</p> </li> <li> <p>Review the transcript for the selected interaction to gain insights into how the conversation unfolded.</p> <p></p> </li> <li> <p>Click on individual messages from the user to examine the intents and entities identified by the Virtual Agent during the conversation.</p> </li> <li> <p>By carefully analyzing these transcripts and analytics, you can identify areas for improvement, understand user behavior, and refine the Virtual Agent's performance accordingly. </p> <p></p> </li> </ol> <p>Congratulations, you have officially completed the Cisco Virtual Assistant mission! \ud83c\udf89\ud83c\udf89 </p>"},{"location":"main/AIAgentTrack_NewUI_Mission2/","title":"AIAgentTrack NewUI Mission2","text":""},{"location":"main/AIAgentTrack_NewUI_Mission2/#mission-details","title":"Mission Details","text":"<p>This mission is designed to provide an in-depth understanding of the Scripted AI Agents. By completing this section of the lab, you will:</p> <ul> <li>Gain practical skills and knowledge on how to effectively utilize Scripted AI Agent to create self-service automation.</li> <li>Improve the containment rate of your contact center, increasing efficiency and reducing costs.</li> <li>Understand the use of Generative AI to fast-track AI Agent development and save time.</li> <li>Troubleshoot the Scipted AI Agent functionality to enhance performance.</li> </ul>"},{"location":"main/AIAgentTrack_NewUI_Mission2/#build","title":"Build","text":""},{"location":"main/AIAgentTrack_NewUI_Mission2/#task-1-creating-a-ai-agent-using-a-template","title":"Task 1. Creating a AI Agent using a Template","text":"<ol> <li> <p>[IMPORTANT] Download the Scripted Agent.</p> <p>ScriptedAIAgent.json - The Appointment Booking template for the AI Agent in Webex Contact Center enables customers to schedule, reschedule, or cancel appointments through an AI-powered virtual agent, integrating with backend systems for real-time availability and confirmations. </p> </li> <li> <p>Login into Webex Control Hub by using your Admin profile wxcclabs+admin_IDYour_Attendee_ID@gmail.com. You will see another login screen with OKTA on it where you may need to enter the email address again and the password provided to you.</p> </li> <li> <p>Go to Contact Center from the left side navigation panel, and under Quick Links, click on Webex AI Agent</p> <p> </p> </li> <li> <p>Click on Import agent to create a new AI Agent by importing preconfigured template. Click on Upload button, locate and select ScriptedAIAgent.json you downloaded at the beginning of the mission.</p> </li> <li>Name your Agent as Your_Attendee_ID_Scripted_AI and click Import</li> <li>Make the bot live by clicking on the Publish button on the top right.</li> <li> <p>Enter v1 in the popup window, then click Publish.     </p> </li> <li> <p>Click on the Preview button on the top right side to test the bot. Try the bot flow by typing \"I would like to cancel an appointment\"</p> <p>Sample Conversation</p> <p>AI Agent: Welcome to Cumulus Healthcare. How may I assist you today? You: I would like to cancel an appointment AI Agent: Please provide the patient's 6-digit insurance number. You: 123456 AI Agent: Please provide your 10-digit phone number. You: 0123456789 AI Agent: You have an appointment on 20/01/2025 at 15:00. Would you like to cancel it? You: yes AI Agent: Your appointment for 20/01/2025 at 15:00 is cancelled.</p> <p></p> </li> </ol>"},{"location":"main/AIAgentTrack_NewUI_Mission2/#task-2-integrating-the-bot-with-flow-for-voice-calls","title":"Task 2. Integrating the Bot with Flow for Voice Calls","text":"<ol> <li> <p>In Control Hub navigate to Flows, click on Manage Flows dropdown list and select Create Flows</p> </li> <li> <p>Select Start Fresh and name the new flow Scripted_AI_Flow_Your_Attendee_ID.      </p> </li> <li> <p>Make sure the Edit mode at the top is set to ON. Then, drag and drop the Virtual Agent V2 and DisconnectContact activity from the left panel onto the canvas.</p> <p>Note</p> <p>Please make sure to use VirtualAgentV2 activity and NOT VirtualAgent also present on the Activity Library for Backward Compatability.</p> <p>Connect the New Phone Contact output node edge to this VirtualAgentV2 node</p> <p>Connect the Handled outputs to DisconnectContact </p> <p>Connect the Escalated outputs to DisconnectContact </p> <p>Connect the Errored outputs to DisconnectContact </p> <p>Select Static Contact Center AI Config</p> <p>Contact Center AI Config: Webex AI Agent (Scripted)</p> <p>Virtual Agent: Your_Attendee_ID_Scripted_AI</p> </li> <li> <p>On bottom right corner toggle Validation from Off to On</p> </li> <li> <p>Click Publish Flow. In Popped up window click on dropdown menu to select Latest label, then click Publish </p> </li> <li> <p>Assign the Flow to your Channel (Entry Point) - Do this by first going to Channel, search for your channel Your_Attendee_ID_2000_Channel.</p> </li> <li>Click on Your_Attendee_ID_2000_Channel</li> <li> <p>In Entry Point Settings section change the following:</p> <p>Routing Flow: Scripted_AI_Flow_Your_Attendee_ID</p> <p>Version Label: Latest</p> <p></p> </li> <li> <p>Dial Support Number assigned to your Your_Attendee_ID_2000_Channel to test the Virtual Agent over a voice call.</p> </li> </ol>"},{"location":"main/AIAgentTrack_NewUI_Mission2/#task-3-updating-bot-responses","title":"Task 3. Updating Bot Responses","text":"<p>In this step, we will learn how to update bot responses and test these changes, both in preview mode and by making a live call. Testing in preview mode allows you to ensure the changes worked as expected, while making a live call confirms the bot's performance in a real-world scenario.</p> <ol> <li> <p>Login into Webex Control Hub by using your Admin profile wxcclabs+admin_IDYour_Attendee_ID@gmail.com. You will see another login screen with OKTA on it where you may need to enter the email address again and the password provided to you.</p> </li> <li> <p>Go to Contact Center from the left side navigation panel, and under Quick Links, click on Webex AI Agent</p> <p> </p> </li> <li> <p>Search and open your bot Your_Attendee_ID_Scripted_AI that you created earlier.      </p> </li> <li> <p>In the Configuration menu navigate to Script tab, then Responses tab</p> <p>Select the Welcome message in Default message</p> <p>Update the text to \"Welcome to Cumulus Healthcare. We are here to help. How may I assist you today?\" for the Default (web) channel.</p> <p>Switch to the Voice Channel and update the text to \"Welcome to Cumulus Healthcare. We are here to help. How may I assist you today?\"</p> <p>Click on the Save button to confirm the changes. Make the bot live by clicking on the Publish button. Add a version name on pop-up window and click Publish again. </p> <p></p> </li> <li> <p>Click on Preview to test if the Greeting has been successfully updated.</p> <p></p> </li> </ol>"},{"location":"main/AIAgentTrack_NewUI_Mission2/#task-4-adding-new-intents-entities","title":"Task 4. Adding New Intents &amp; Entities","text":"<p>In this step, we will learn how to add new intents and entities to enhance the bot's ability to understand and respond to a broader range of user inputs. These updates will be tested in both preview mode and during a live call to confirm that the bot correctly identifies the new intents and entities and provides appropriate responses.</p> <ol> <li>While on the Script configuration page, switch to Intents tab and click on the Create Intent button located in the top right corner.</li> <li> <p>Add a new intent by providing the intent name as ReferralRequest and include the following two utterances:</p> <ul> <li>I would like a referral for a cardiologist.</li> <li>I need a referral to visit a neurologist.</li> </ul> <p></p> </li> <li> <p>Click on + Link and add patient phone number as an entity.</p> <p>Check the Required checkbox </p> <p>Select the template key as askPhoneNumber, which will be used to prompt the patient for their phone number.</p> <p> </p> </li> <li> <p>Again, click on + Link and add patient dob (date of birth) </p> <p>Check Required checkbox</p> <p>Select the template key as askPatientDob. When this intent is matched, it will trigger the Virtual Agent to ask the user to provide their phone number and date of birth for verification purposes.</p> <p> </p> </li> <li> <p>On the same page in Response section at the bottom, click on Select a response drop down list and scroll down to Create new.</p> <p>Template key: ReferralResp_</p> <p>On Default (Web) tab replace the text with: Your request has been logged and will be reviewed by our team. You will receive a callback once it's approved. Is there anything else I can assist you with?</p> <p>[Optional]: Adding text to a Voice is not mandatory as Default (Web) works here as well. But you can slightly change the message depending on the channel.</p> <p>Click on + next to Default (Web) and select Voice</p> <p>In the Text section replace the text with: Your request has been logged and will be reviewed by our team. You will receive a callback once it's approved. Is there anything else I can assist you with?</p> <p>Click on Create. Click on Add. </p> </li> <li> <p>Click on the Save Changes button to confirm the changes. Make the bot live by clicking on the Publish button. Add a version name on pop-up window and click Publish again. </p> <p></p> </li> <li> <p>Use the Preview feature to test the bot flow with the input query: I need a referral for a cardiologist.</p> </li> <li> <p>You can also test this interaction in voice mode by dialing the Supported Number assigned to your pod.</p> <p></p> </li> </ol>"},{"location":"main/AIAgentTrack_NewUI_Mission2/#task-5-adding-training-data-using-generative-ai","title":"Task 5. Adding Training Data using Generative AI","text":"<p>In this step, we will learn how to enhance the bot's capabilities by adding training data using generative AI and validate the changes by making a call.</p> <ol> <li> <p>While on the Script configuration page, navigate to Intents tab and select ReferralRequest intent that you created in the previous exercise.</p> </li> <li> <p>Click on the Generate button to utilize Generative AI for creating additional training phrases.</p> </li> <li> <p>Enter a description such as \"Generate intents for requesting a referral to different doctor specialties from primary care.\" Set the Number of Variants to 10, which will determine the number of new phrases to be generated.</p> </li> <li> <p>Click on Save.</p> </li> <li> <p>Click on the Save Changes button to confirm the changes. Make the bot live by clicking on the Publish button. Add a version name on pop-up window and click Publish again. </p> <p></p> </li> <li> <p>Test the updated bot flow by using the Preview button and inputting queries related to the new training data.</p> <p></p> </li> </ol>"},{"location":"main/AIAgentTrack_NewUI_Mission2/#bot-transcripts-analytics","title":"Bot Transcripts &amp; Analytics","text":"<p>In this step, we will explore how to access and analyze bot transcripts and analytics to gain insights into user interactions.</p> <ol> <li> <p>Click on Sessions in the left-hand panel of your bot builder interface to view all the call history. Click on any Session ID to delve into a more detailed analysis of that particular interaction.</p> </li> <li> <p>If you encounter encrypted content, click on Decrypt Content to proceed with the review.</p> </li> <li> <p>Review the transcript for the selected interaction to gain insights into how the conversation unfolded.</p> <p></p> </li> <li> <p>Click on individual messages from the user to examine the intents and entities identified by the Virtual Agent during the conversation.</p> </li> <li> <p>By carefully analyzing these transcripts and analytics, you can identify areas for improvement, understand user behavior, and refine the Virtual Agent's performance accordingly. </p> <p></p> </li> </ol> <p>Congratulations, you have officially completed the Cisco Virtual Agent mission! \ud83c\udf89\ud83c\udf89 </p>"},{"location":"main/AI_Assistant_CallDropSummary/","title":"Mission 2: AI Assistant - Call Drop Summary","text":""},{"location":"main/AI_Assistant_CallDropSummary/#mission-2-ai-assistant-call-drop-summary","title":"Mission 2: AI Assistant - Call Drop Summary","text":""},{"location":"main/AI_Assistant_CallDropSummary/#feature-description","title":"Feature Description","text":"<p>Customers find it frustrating to repeat themselves, especially after a call drop. Now, agents can pick up where the call left off, reducing frustration and handling time, while empowering agents to work more efficiently.</p> <p>The Cisco AI Assistant provides a summary of the recently dropped interaction, detailing the reason for the call and the last action discussed. This enables agents to seamlessly resume the conversation.</p>"},{"location":"main/AI_Assistant_CallDropSummary/#mission-details","title":"Mission Details","text":"<p>Your mission is to:</p> <ol> <li>The current mission does not include any configuration steps, but rather testing only.</li> <li>Your task is to test AI Assistant Call Drop Summary feature</li> </ol> <p>Note</p> <p>This model requires meaningful audio to transcribe and provide a summary of the conversation. You will need to simulate both the customer and the agent speaking. If you have any questions, reach out to the lab instructors for help.</p> <p>For the current mission, an optimal way to test is by using your cellphone with the Webex App installed. However, if you use the same device for both the caller and the agent, here\u2019s a tip: mute your cellphone when speaking as the agent and mute your Agent Desktop when speaking as the customer.</p>"},{"location":"main/AI_Assistant_CallDropSummary/#testing","title":"Testing","text":"<ol> <li> <p>Switch to Control Hub and navigate to Channels under Customer Experience Section</p> <p>Locate your Inbound Channel (you can use the search): Your_Attendee_ID_Channel</p> <p>Select the Routing Flow: Main_Flow_Your_Attendee_ID</p> <p>Select the Version Label: Latest</p> <p>Click Save in the lower right corner of the screen</p> </li> <li> <p>Your Agent desktop session should be still active but if not, use Webex CC Desktop application  and login with agent credentials you have been provided wxcclabs+agent_IDYour_Attendee_ID@gmail.com. You will see another login screen with OKTA on it where you may need to enter the email address again and the password provided to you. </p> </li> <li>Select Team Your_Attendee_ID_Team. Click Submit. Allow browser to access Microphone by clicking Allow on every visit.</li> <li> <p>Make your agent Available and you're ready to make a call.</p> <p></p> </li> <li> <p>Dial the support number assigned to your Your_Attendee_ID_Channel channel.</p> </li> <li> <p>Answer the call on Agent Desktop and use the provided script to simulate an agent/customer conversation (minimum 30 seconds).</p> <p>Call Drop Summary Script</p> <p>Agent: Good morning, thank you for calling Airway Express. My name is Michelle. How can I assist you today? You: Hi Michelle, I'm having an issue trying to make an adjustment to a flight I have with you. I booked a flight from Amsterdam to London, but now I need to add a leg to go from London to New York a couple of days later. I just can't seem to do it through the website. Agent: I'm sorry to hear you're experiencing issues with our app. I can definitely help you with that. Could I have your flight confirmation number to start with, please? You: &lt;..Silence..&gt; Agent: Hello, hello, hello</p> </li> <li> <p>From the Agent Call Controls, transfer the call to transfer call to the Queue\u202fQ_CallDrop. Click the \u201cQueue\u201d radio button to search for this Queue.</p> </li> </ol> <p></p> <ol> <li> <p>Wait for the call to timeout and disconnect. This simulates an accidental call drop.</p> <p>Note</p> <p>Since the call drop must be system initiated, the queue Q_CallDrop has been pre-configured with a maximum time in queue of 10 seconds (pictured on screenshot from Control Hub). Wait in the queue for about 10 seconds for the system to drop the call \"automatically\". </p> <p></p> </li> <li> <p>Make sure your agent session is active and your agent is in Available state.</p> </li> <li> <p>Dial the support number assigned to your Your_Attendee_ID_Channel channel again. This will simulate a customer calling back after a call was dropped and trying to connect again to resolve the original issue.</p> </li> <li> <p>Accept the call on the Agent Desktop. The AI Assistant notifies the agent of the available call drop summary.</p> </li> <li> <p>Open the AI Assistant to review the summary. This summary can be used by the agent to pick up where the previous agent left off, reducing customer frustration and need for them to repeat themselves.</p> </li> </ol> <p></p> <p>Congratulations, you have officially completed the Call Drop Summary lab! \ud83c\udf89\ud83c\udf89 </p>"},{"location":"main/AI_Lab_Assist_AutoCSAT/","title":"AI Lab Assist AutoCSAT","text":""},{"location":"main/AI_Lab_Assist_AutoCSAT/#feature-description","title":"Feature Description","text":"<p>The survey feature in Webex Contact Center is a valuable tool for gathering customer feedback. However, experience shows that only a small percentage of customers take the time to complete surveys. Typically, surveys are filled out by customers who are either extremely satisfied or dissatisfied, which may not represent the full spectrum of customer experiences.</p> <p>The Auto CSAT model is a Cisco native AI model leveraging deep learning techniques to predict the CSAT score for every customer interaction.</p> <p>The predicted CSAT scores are tailored to each customer, reflecting their unique experiences with customer service.</p> <p>Survey data and interaction data are utilized to predict and assign a CSAT score to each interaction.</p> <p>The Auto CSAT scores generated for every interaction are stored in the contact records, which can be retrieved by authorized partners and customers for delivering insights and maximize customer satisfaction and agent performance.</p>"},{"location":"main/AI_Lab_Assist_AutoCSAT/#mission-details","title":"Mission Details","text":"<p>Your mission is to learn how to view the AutoCSAT score for customer interactions using the Analyzer report and the Supervisor Dashboard.</p>"},{"location":"main/AI_Lab_Assist_AutoCSAT/#build","title":"Build","text":""},{"location":"main/AI_Lab_Assist_AutoCSAT/#task-1-read-only-order-provisioning-control-hub-settings","title":"Task 1 [READ ONLY]. Order Provisioning &amp; Control Hub Settings","text":"<ol> <li> <p>You should purchase the new AI Assistant SKU A-FLEX-AI-ASST from CCW.</p> </li> <li> <p>Once you purchase the offer, admins with the appropriate profile and access controls will be able to view the AI Assistant menu in Control Hub.</p> </li> <li> <p>You can enable or disable the AutoCSAT feature directly from the Control Hub.</p> </li> <li>AutoCSAT can be enabled for all agents or for selected individual agents.</li> </ol> <p>Note: To activate post-call survey functionality, historical customer data is required to train the AutoCSAT model. There are two ways to collect this data: 1. Capture surveys using Webex Contact Center Experience Management. 2. Capture customer survey responses using the Global variable within your flow.</p> <ul> <li>Make a note in AutoCSAT setting in Controlhub we using Global Variable </li> </ul> <p></p>"},{"location":"main/AI_Lab_Assist_AutoCSAT/#task-2-explore-autocsat-using-analyzer-report-and-supervisor-dashboard","title":"Task 2 Explore AutoCSAT using Analyzer report and Supervisor Dashboard","text":"<ol> <li> <p>Under Contact Center in Control Hub, click Overview and from Quick Links open up Analyser.      </p> </li> <li> <p>Go to Visualizations and search for the report with name Auto CSAT. It should have the ID -1282. Open the report.      </p> </li> <li> <p>In the report you can see AutoCSAT that were generated for the calls, based on the Queue. You can see AutoCSAT information related to specific calls by drill-down into the AutoCSAT fields.      </p> </li> <li> <p>[READ ONLY] When you log in to the Supervisor Dashboard, you can view the AutoCSAT score for specific calls and listen to the call recordings directly from the supervisor desktop. (The Supervisor user account is not configured for this lab. Please refer to the screenshot below to understand the experience of viewing the AutoCSAT from the Supervisor desktop.)     </p> </li> </ol> <p>Congratulations, you have officially completed this mission! \ud83c\udf89\ud83c\udf89 </p>"},{"location":"main/AI_Lab_Assist_Conclusion/","title":"AI Lab Assist Conclusion","text":""},{"location":"main/AI_Lab_Assist_Conclusion/#lab-summary-webex-ai-assistance","title":"Lab Summary: Webex AI Assistance","text":"<p>In this lab, you explored key AI features in Webex Contact Center that enhance customer service and agent efficiency.</p>"},{"location":"main/AI_Lab_Assist_Conclusion/#highlights","title":"Highlights","text":"<ul> <li>Agent Transfer Summary: Gives agents context from Virtual Agent interactions.</li> <li>Real-Time Transcription: Improves accuracy and response time.</li> <li>Dropped-Call Summary: Helps agents resume conversations smoothly.</li> <li>Auto CSAT: Uses AI to predict satisfaction for every interaction, beyond traditional surveys.</li> </ul>"},{"location":"main/AI_Lab_Assist_Conclusion/#takeaway","title":"Takeaway","text":"<p>Cisco AI features streamline operations, boost communication, and elevate the customer experience in modern contact centers.</p>"},{"location":"main/AI_Lab_Assist_Mission1/","title":"AI Lab Assist Mission1","text":""},{"location":"main/AI_Lab_Assist_Mission1/#feature-description","title":"Feature Description","text":"<p>AI Agent Transfer Summary enhances agent efficiency and elevate customer experiences.</p> <p>When a customer calls the contact center and interacts with an AI Agent, they may request to speak with a live human agent at some point during the conversation. Once connected to an agent, it is important for the agent to receive a concise summary of the customer's interaction with the AI Agent. This summary provides the agent with a quick overview of the customer's call reason. The \"AI Agent Handoff Summary\" feature provides this summary, displaying it on the agent's desktop within the AI-Assistant Widget.</p>"},{"location":"main/AI_Lab_Assist_Mission1/#mission-details","title":"Mission Details","text":"<p>Your mission is to:</p> <ol> <li>Configure a smooth handoff to live human agent from AI Agent.</li> <li>Modify Virtual Agent transcript</li> <li>Use AI Assistant</li> </ol>"},{"location":"main/AI_Lab_Assist_Mission1/#build","title":"Build","text":""},{"location":"main/AI_Lab_Assist_Mission1/#task-1-read-only-order-provisioning-control-hub-settings","title":"Task 1 [READ ONLY]. Order Provisioning &amp; Control Hub Settings","text":"<ol> <li> <p>You should purchase the new AI Assistant SKU A-FLEX-AI-ASST from CCW.</p> </li> <li> <p>Once you purchase the offer, admins with the appropriate profile and access controls will be able to see the AI Assistant menu in Control Hub. After purchasing the offer, the customer can enable/disable the Virtual Agent Transfer Summary features from the Control Hub.    </p> </li> <li> <p>The Agent needs to be logged in to the Team that is configured with Desktop Layout that has \"ai-assistant\" features configured.      Note: Default desktop layout already incude the AI Agent Assistance widget      Agents Team:     Desktop Layout:     Desktop Layout file:       Make sure ai-assistant is configured under the advancedHeader.     You can download preconfigured desktop layout here.    Desktop Layout </p> </li> </ol>"},{"location":"main/AI_Lab_Assist_Mission1/#task-2-test-agent-transfer-summary-feature","title":"Task 2. Test Agent Transfer Summary Feature","text":"<ol> <li> <p>Login to the Agent Desktop.     </p> </li> <li> <p>Select telephony option as Desktop.    </p> </li> <li> <p>Make sure you can see Agent Assistant widget.    </p> </li> <li> <p>Confirm that your Channel _2000_Channel is still configured with the flow AutonomousAI_Flow_2000_ that includes the Autonomous AI agent, and the Escalated output is connected to the Queue node. This configuration is expected to remain the same as in the Autonomous AI Agent lab.    </p> </li> <li> <p>Place a test call and, for example, mention that you need some flowers for a wedding party. Allow the AI Agent to complete its response before requesting to transfer the call to a live human agent. </p> </li> <li> <p>Become Available on the Agent Desktop and answer the call. You will see a window with the message AI agent transfer summary is ready pops up. You can click on View Summary from the window.    </p> </li> <li> <p>The AI agent transfer summary is ready notification will disappear after a few seconds. However, you can always reopen it by clicking on the AI Assistant widget.    </p> </li> </ol> <p>Congratulations, you have officially completed this mission! \ud83c\udf89\ud83c\udf89 </p>"},{"location":"main/AI_Lab_Assist_Mission3/","title":"AI Lab Assist Mission3","text":""},{"location":"main/AI_Lab_Assist_Mission3/#feature-description","title":"Feature Description","text":"<p>You can enhance communication efficiency and quality assurance in your contact center with the real-time transcripts feature. It allows agents to access real-time transcriptions of customer interactions directly on their Agent Desktop, enabling them to follow conversations more accurately and respond effectively.</p> <p>Benefits:</p> <p>Accurate communication: Captures conversations precisely, aiding understanding, especially with diverse accents or non-native speakers.  Improved efficiency: Eliminates manual note-taking, enabling agents to focus and resolve issues faster. Better performance: Helps agents deliver timely, accurate solutions, boosting customer trust. Higher customer satisfaction: Reduces misunderstandings, improving CSAT scores and experiences. Training and quality assurance: Provides reliable references for coaching, evaluations, and compliance checks. Seamless integration: Easily integrates with systems, optimizing queue-level management. AI support: Enhances decision-making with complementary AI Assistant features.</p>"},{"location":"main/AI_Lab_Assist_Mission3/#mission-details","title":"Mission Details","text":"<p>Your mission is to:</p> <ol> <li>Enable Real-Time Transcript feature</li> <li>Configure flow with Start Media Stream block</li> <li>Test Real-Time Transcript feature</li> </ol>"},{"location":"main/AI_Lab_Assist_Mission3/#build","title":"Build","text":""},{"location":"main/AI_Lab_Assist_Mission3/#task-1-read-only-order-provisioning-control-hub-settings","title":"Task 1 [READ ONLY]. Order Provisioning &amp; Control Hub Settings","text":"<ol> <li> <p>You should purchase the new AI Assistant SKU A-FLEX-AI-ASST from CCW.</p> </li> <li> <p>Once you purchase the offer, admins with the appropriate profile and access controls will be able to see the AI Assistant menu in Control Hub. Post purchasing the offer, the customer can enable/disable the Real-time Transcriptions from the Control Hub.    </p> </li> <li> <p>The Agent needs to logged in to the Team that is configured with Desktop Layout that has Agent Assistance features configured.      Agents Team:     Desktop Layout:     Desktop Layout file: Make sure RT_TRANSCRIPT widget is configured.      You can download preconfigured desktop layout here.    Desktop Layout </p> </li> </ol>"},{"location":"main/AI_Lab_Assist_Mission3/#task-2-configure-flow-for-real-time-transcripts","title":"Task 2. Configure Flow for real-time transcripts","text":"<ol> <li> <p>Open up your voice flow AutonomousAI_Flow_2000_Your_Attendee_ID and click on Edit.     </p> </li> <li> <p>Click on the Event Flow.     </p> </li> <li> <p>Drag and drop Start Media Stream node and connect AgentAnswer node to the Start Media Stream node. </p> </li> <li>Drag and drop End Flow node and connect Start Media Stream to End Flow.</li> <li>Validate and Publish the flow.      </li> </ol>"},{"location":"main/AI_Lab_Assist_Mission3/#task-3-test-real-time-transcript-feature","title":"Task 3. Test Real-Time Transcript feature","text":"<ol> <li> <p>Login to the Agent Desktop.    </p> </li> <li> <p>Confirm that your Channel Your_Attendee_ID_2000_Channel is still configured with the flow AutonomousAI_Flow_2000_Your_Attendee_ID that includes the Autonomous AI agent, and the Escalated output is connected to the Queue node. This configuration is expected to remain the same as in the Autonomous AI Agent lab.    </p> </li> <li> <p>Place a test call and ask to talk to an agent. </p> </li> <li> <p>Become Available on the Agent Desktop and answer the call. You will see the Live Transcripts window with the latest live transcripts between the caller and the human agent.    </p> </li> </ol> <p>Congratulations, you have officially completed this mission! \ud83c\udf89\ud83c\udf89 </p>"},{"location":"main/AI_Lab_Assist_Mission_2/","title":"AI Lab Assist Mission 2","text":""},{"location":"main/AI_Lab_Assist_Mission_2/#feature-description","title":"Feature Description","text":"<p>Customers find it frustrating to repeat themselves, especially after a call drop. Now, agents can pick up where the call left off, reducing frustration and handling time, while empowering agents to work more efficiently.</p> <p>The Cisco AI Assistant provides a summary of the recently dropped interaction, detailing the reason for the call and the last action discussed. This enables agents to seamlessly resume the conversation.</p>"},{"location":"main/AI_Lab_Assist_Mission_2/#mission-details","title":"Mission Details","text":"<p>Your mission is to:</p> <p>Understand the provisioning process and Control Hub settings required to activate this AI feature. Review the agent configurations with the correct desktop layout. Test the feature.</p>"},{"location":"main/AI_Lab_Assist_Mission_2/#build","title":"Build","text":""},{"location":"main/AI_Lab_Assist_Mission_2/#task-1-read-only-order-provisioning-control-hub-settings","title":"Task 1 [READ ONLY]. Order Provisioning &amp; Control Hub Settings","text":"<ol> <li> <p>You should purchase the new AI Assistant SKU A-FLEX-AI-ASST from CCW.</p> </li> <li> <p>Once you purchase the offer, admins with the appropriate profile and access controls will be able to see the AI Assistant menu in Control Hub. Post purchasing the offer, the customer can enable/disable the Call Drop Summary features from the Control Hub.    </p> </li> <li> <p>The Agent needs to logged in to the Team that is configured with Desktop Layout that has Agent Assistance features configured. Agents Team:     Desktop Layout:     Desktop Layout file: Make sure ai-assistant is configured under the advancedHeader You can download preconfigured desktop layout here.    Desktop Layout</p> </li> </ol>"},{"location":"main/AI_Lab_Assist_Mission_2/#task-2-test-call-drop-summary-feature","title":"Task 2. Test Call Drop Summary Feature","text":"<ol> <li> <p>Login to the Agent Desktop.    </p> </li> <li> <p>Confirm that your Channel _2000_Channel is still configured with the flow AutonomousAI_Flow_2000_ that includes the Autonomous AI agent, and the Escalated output is connected to the Queue node. This configuration is expected to remain the same as in the Autonomous AI Agent lab.    </p> </li> <li> <p>Place a test call and ask to talk to an agent. </p> </li> <li> <p>Become Available on the Agent Desktop and answer the call. </p> </li> <li>Stay on the call for 35 - 45 seconds </li> <li> <p>Have some conversation and then disconnect from the caller side.     </p> </li> <li> <p>Call back from the same number. Ask to talk to an agent. </p> </li> <li> <p>Become Available on the Agent Desktop and answer the call. You will see AI Assistant Widget will have Call Drop Summary and the Agent Transfer Summary.    </p> </li> </ol> <p>Congratulations, you have officially completed this mission! \ud83c\udf89\ud83c\udf89 </p>"},{"location":"main/AI_Lab_Aut_Conclusion/","title":"AI Lab Aut Conclusion","text":"<p>In this lab</p> <p>You successfully explored the capabilities of the Webex Autonomous AI Agent by creating and configuring an AI-powered assistant for a flower shopping experience.</p>"},{"location":"main/AI_Lab_Aut_Conclusion/#key-capabilities-implemented","title":"Key Capabilities Implemented:","text":"<ul> <li>Designed the virtual agent to:</li> <li>Recommend suitable flowers based on the customer's occasion</li> <li> <p>Calculate the total price of the selected flowers</p> </li> <li> <p>Configured actions to:</p> </li> <li>Integrate with a Customer CRM/Database</li> <li> <p>Generate orders and provide customers with a real-time order number</p> </li> <li> <p>Enabled post-order communication by:</p> </li> <li>Sending order confirmation details via SMS</li> <li>Ensuring a seamless and efficient user experience</li> </ul> <p>This setup showcases a complete AI agent workflow\u2014from recommendation to transaction and customer notification\u2014using Webex Contact Center\u2019s Autonomous AI Agent capabilities.</p> <p>This hands-on exercise demonstrated how Webex Autonomous Agent can streamline business processes, enhance customer interactions, and integrate with external systems to deliver a comprehensive solution.</p>"},{"location":"main/AI_Lab_Aut_Mission2/","title":"Mission 2: Configure Action and create an order.","text":""},{"location":"main/AI_Lab_Aut_Mission2/#mission-2-configure-action-and-create-an-order","title":"Mission 2: Configure Action and create an order.","text":"What is Action? [Optional] Action is a task that an AI agent performs by understanding user intents and completes by connecting to external systems. <p>For more information visit Webex Documentation</p>"},{"location":"main/AI_Lab_Aut_Mission2/#_1","title":"Mission 2: Configure Action and create an order.","text":""},{"location":"main/AI_Lab_Aut_Mission2/#mission-overview","title":"Mission overview","text":"<p>Your mission is to:</p> <p>Configure an action to collect order details from the customer and send them to a third-party application via APIs.</p>"},{"location":"main/AI_Lab_Aut_Mission2/#build","title":"Build","text":""},{"location":"main/AI_Lab_Aut_Mission2/#task-1-create-service-and-ai-agent-flow-in-webex-connect","title":"Task 1. Create Service and AI Agent Flow in Webex Connect.","text":"<ol> <li> <p>From Control Hub, go to Contact Center and open up Webex Connect Portal.      </p> </li> <li> <p>Create new Service with name _2000_Service </p> </li> <li> <p>Click on Flows and create new flow with the name Create_Ordedr_Flowers </p> </li> <li> <p>From the Integrations list select AI Agent.      </p> </li> <li> <p>For now, save the flow and Make it live. We will return to configuring this flow later. Creating it now is necessary to complete configurations in the AI Studio Portal.     </p> </li> </ol>"},{"location":"main/AI_Lab_Aut_Mission2/#task-2-configure-action-in-the-ai-studio","title":"Task 2. Configure Action in the AI Studio.","text":"<ol> <li> <p>If not logged-in in AI Agent Studio, login to the AI Studio Portal.     </p> </li> <li> <p>Select your AI agent with name _2000_AutoAI_Lab that we created earlier, go to Actions. You will see one Action is already created by default for the Agent Handoff. We will be creating more actions.</p> <p></p> </li> <li> <p>Click on creat New Action. Configure it with name Create_New_Order and the Action Description Collect order details, delivery address, total and response with the orderNumber once the order is completed.. In the Action score select Slot filling and fulfillment.     </p> </li> <li> <p>Scroll down and click to create New input entity. Fill up the table with the following and then click on Add.  Entity Name: address  Entity Typs: string  Description: Collect the customer's delivery address Example: 548 Catalina Drive, Cary, NC 27515  Required: Yes </p> </li> <li> <p>By following the same pattern, create an entity that specifies whether the customer requires delivery.  Entity Name: delivery Entity Types: string  Description: Check if the customer needs delivery or not. Event if they want to proceed with order without specifying the delivery details. If the customer wants to confirm the order but didn't specify if they need delivery or not, ask one more time if they need the delivery or not. Example: Yes,No Required: Yes</p> </li> <li> <p>By following the same pattern, create an entity to collect the customer's phone number. Entity Name: phoneNumber Entity Typs: string  Description: Collect customer's phone number. Before the customer complete the order, ask if they would like to receive confirmation over the SMS. If so, collect the phone number. Example: 3477579861 Required: Yes</p> </li> <li> <p>By following the same pattern, create an entity to collect the customer's order details. Entity Name: orderDetails Entity Typs: string  Description: Collect the flowers and bouquets information that customer orders. Make sure to do correct math. If one rose is 20 dollars and the customer would like buy 9 roses then the price should be 180 dollars. Don't use double quotes (\") in the generated responses. Example: Romantic Roses standard bouquet and one more bouquet with 9 roses Required: Yes</p> </li> <li> <p>By following the same pattern, create an entity to store the total price information of the order. Entity Name: orderTotal Entity Typs: string  Description: After the customer inform if they need delivery or not, and confirm that they would like to proceed with completing the order, collect the Total information and assigned it to this slot. Example: 150 dollars, 70 dollars Required: Yes</p> </li> <li> <p>By following the same pattern, create an entity to store the order status information. Entity Name: status Entity Typs: string  Description: Always create it as \"new\" Example: new Required: Yes</p> </li> <li> <p>At this point you should see 6 created entities. Please double check it.      </p> </li> <li> <p>In the Webex Connect Builder Fulfillment select Service: _2000_Service and Flow: Create_Order_Flowers Click Add </p> </li> <li> <p>Publish the update of your AI Agent.     </p> </li> </ol>"},{"location":"main/AI_Lab_Aut_Mission2/#task-3-deliver-collected-order-information-to-webex-connect-for-fulfillment","title":"Task 3. Deliver collected order information to Webex Connect for fulfillment.","text":"<ol> <li> <p>Login to the Webex Connect, go to the Service _2000_Service and click on Manage the flow that you have created earlier.    </p> </li> <li> <p>Click on Edit the flow on the right top. Then double click on the AI Agent event. In the Provide Sample JSON, replace the standard JSON body with the following:   </p><pre><code>{\n  \"orderDetails\": \"ID\",\n  \"orderTotal\": \"Type\",\n  \"delivery\": \"Type\",\n  \"address\": \"Type\",\n  \"status\": \"Type\",\n  \"phoneNumber\": \"Type\"\n}\n</code></pre><p></p> </li> <li> <p>Then click on Parse and Save the change.    </p> </li> <li> <p>Drag and drop HTTP Request node from the left side of the Webex Connect Flow Builder. Connect AI Agent block to the HTTP Request block.     </p> </li> <li> <p>Open up HTTP Request node and configure it with the following HTTP Request: </p> <p>Method: POST  Endpoint URL: https://67e9aa0bbdcaa2b7f5b9ed62.mockapi.io/customerOrder Header: Content-Type: application/json  Body:  </p><pre><code>{\n \"orderDetails\": \"$(n2.aiAgent.orderDetails)\",\n \"orderTotal\": \"$(n2.aiAgent.orderTotal)\",\n \"delivery\": \"$(n2.aiAgent.delivery)\",\n \"address\": \"$(n2.aiAgent.address)\",\n \"status\": \"$(n2.aiAgent.status)\",\n \"phoneNumber\": \"$(n2.aiAgent.phoneNumber)\"\n}\n</code></pre> <p></p> <p>Output Variable Type: JSON Click on +Add Variable Output Variable Name: orderNumber Response Entity: Body Response Path $.id</p> <p></p> </li> <li> <p>Compare your settings with the screenshot below to make sure you configured the HTTP Request correctly. Make sure you Save the changies.     </p> </li> <li> <p>Save changies and click on Make Live.    </p> </li> </ol>"},{"location":"main/AI_Lab_Aut_Mission2/#task-4-deliver-data-from-webex-connect-to-ai-studio-for-the-response-to-the-customer","title":"Task 4. Deliver data from Webex Connect to AI studio for the response to the customer.","text":"<ol> <li> <p>[Read Only] Once the HTTP request is completed a new object will be created on the third-party application. You can see all objects by using the this link https://67e9aa0bbdcaa2b7f5b9ed62.mockapi.io/customerOrder. Below you can see the screenshot with all orders information. Currently there are only 2 orders, but by the time of this lab there could be more.     Each order/object will contain all the information that we sent from AI Studio but one - id. This key is created automatically once we create the object. The goal of this Task is to send the value of the id back to the AI Agent so AI Agent can provide it to the customer while they are still in live contact, like you can see on the picture below. </p> </li> <li> <p>[Read Only] When you were configuring HTTP Request in your previous Task, on the bottom of the request you were configuring the Output Variable. This variable will be used to parse the unique order id and pass the value to the Output Variable with name orderNumber. See the screenshot below. In the next step we will be configuring this orderNumber variable to be sent to Webex AI studio. </p> </li> <li> <p>While on your Webex Connect flow, click on Edit the flow then click on the Settings and on the top select Flow Outcomes and expand Last Execution Status. In the Define key-value pairs to be sent to the AI Agent select Enter JSON.    </p> </li> <li> <p>We need to add the key-value pair to the existing JSON body. Add the comma after the last pair and insert \"orderNumber\": \"$(n3.orderNumber)\". Make sure there is no comma after the pair that you inserted. Then click on Save.      Also see this change in action below.     </p> </li> <li> <p>Click on Make Live to publish the flow.     </p> </li> </ol>"},{"location":"main/AI_Lab_Aut_Mission2/#task-5-configure-sms-confirmation","title":"Task 5. Configure SMS confirmation.","text":"<ol> <li> <p>If it is not open, navigate to Webex Connect portal. Find your Service _2000_Service, navigate to the flow and click on Manage the flow.     </p> </li> <li> <p>On the right top click on Edit. Then from the available Utilities on the left side find the SMS and drag and drop the block to the flow. Connect HTTP Request node to the SMS node.     </p> </li> <li> <p>Double click on the SMS block and configure the following:</p> <p>Destination: $(n2.aiAgent.phoneNumber) From Number: 12066478712 Message Type: Text  Message as below: Here is your order details: orderNumber: \"$(n3.orderNumber)\" orderDetails: \"$(n2.aiAgent.orderDetails)\" orderTotal: \"$(n2.aiAgent.orderTotal)\" delivery: \"$(n2.aiAgent.delivery)\" address: \"$(n2.aiAgent.address)\" status: \"$(n2.aiAgent.status)\" phoneNumber: \"$(n2.aiAgent.phoneNumber)\"</p> <p></p> </li> <li> <p>Save and Click on Make Live.     </p> </li> </ol>"},{"location":"main/AI_Lab_Aut_Mission2/#task-6-test-the-order-creating-and-details-delivery-over-sms","title":"Task 6. Test the order creating and details delivery over SMS.","text":"<ol> <li> <p>In the Webex AI Agent Studio, click on preview and order flowers for you friend.     </p> </li> <li> <p>Check if the confirmation SMS was received on your phone.  </p> </li> </ol> <p>Congratulations, you have officially completed this mission! \ud83c\udf89\ud83c\udf89 </p>"},{"location":"main/AI_Lab_Aut_Mission2_New/","title":"Mission 2: Configure Action and create an order.","text":""},{"location":"main/AI_Lab_Aut_Mission2_New/#mission-2-configure-action-and-create-an-order","title":"Mission 2: Configure Action and create an order.","text":"What is Action? [Optional] Action is a task that an AI agent performs by understanding user intents and completes by connecting to external systems. <p>For more information visit Webex Documentation</p>"},{"location":"main/AI_Lab_Aut_Mission2_New/#_1","title":"Mission 2: Configure Action and create an order.","text":""},{"location":"main/AI_Lab_Aut_Mission2_New/#mission-overview","title":"Mission overview","text":"<p>Your mission is to:</p> <p>Configure an action to collect order details from the customer and send them to a third-party application via APIs.</p>"},{"location":"main/AI_Lab_Aut_Mission2_New/#build","title":"Build","text":""},{"location":"main/AI_Lab_Aut_Mission2_New/#task-1-create-service-and-ai-agent-flow-in-webex-connect","title":"Task 1. Create Service and AI Agent Flow in Webex Connect.","text":"<ol> <li> <p>From Control Hub, go to Contact Center and open up Webex Connect Portal.      </p> </li> <li> <p>Create new Service with name Your_Attendee_ID_2000_Service </p> </li> <li> <p>Click on Flows and create new flow with the name Create_Ordedr_Flowers.</p> <p></p> </li> <li> <p>From the Integrations list select AI Agent.      </p> </li> <li> <p>For now, save the flow and make it Live. We will return to configuring this flow later. Creating it now is necessary to complete configurations in the AI Studio Portal.     </p> </li> </ol>"},{"location":"main/AI_Lab_Aut_Mission2_New/#task-2-configure-action-in-the-ai-studio","title":"Task 2. Configure Action in the AI Studio.","text":"<ol> <li> <p>Login to the AI Studio Portal.      </p> </li> <li> <p>Select your AI agent with name Your_Attendee_ID_2000_AutoAI_Lab that your created earlier, go to Actions. You will see one action is already created by default for the Agent Handoff. You will be creating more actions.</p> <p></p> </li> <li> <p>Click on creat New Action. Configure it with name Create_New_Order and the Action Description Collect order details, delivery address, total and response with the orderNumber once the order is completed.. In the Action score select Slot filling and fulfillment.     </p> </li> <li> <p>Scroll down and click to create \"New input entity\". Fill up the table with the following:  Entity Name: address  Entity Typs: string  Description: Collect the customer's delivery address  Example: 548 Catalina Drvie, Cary, NC 27515  Required: Yes </p> </li> <li> <p>By following the same pattern, create an entity that specifies whether the customer requires delivery.  Entity Name: delivery  Entity Typs: string  Description: Check if the customer needs delivery or not. Event if they want to proceed with order without specifying the delivery details. If the customer wants to confirm the order but didn't specify if they need delivery or not, ask one more time if they need the delivery or not.  Example: Yes,No  Required: Yes</p> </li> <li> <p>By following the same pattern, create an entity to collect the customer's email address. Entity Name: email  Entity Typs: string  Description: Before the customer complete the order, ask if they would like to receive confirmation over the email. If so, collect the email address.  Example: mdanylch@cisco.com, ktyagi@cisco.com  Required: Yes</p> </li> <li> <p>By following the same pattern, create an entity to collect the customer's order details. Entity Name: orderDetails  Entity Typs: string  Description: Collect the flowers and bouquets information that customer orders. Make sure to do correct math. If one rose is 20 dollars and the customer would like buy 9 rouses then the price should be 180 dollars. Don't use double quotes (\") in the generated responses.  Example: Romantic Roses standard bouquet and one more bouquet with 9 roses  Required: Yes</p> </li> <li> <p>By following the same pattern, create an entity to store the total price information of the order. Entity Name: orderTotal  Entity Typs: string  Description: After the customer inform if they need delivery or not, and confirm that they would like to proceed with completing the order, collect the Total information and assigned it to this slot.  Example: 150 dollars, 70 $  Required: Yes</p> </li> <li> <p>By following the same pattern, create an entity to store the order status information. Entity Name: status  Entity Typs: string  Description: Always create it as \"new\"  Example: new  Required: Yes</p> </li> <li> <p>At this point you should see 6 created entities. Please double check it.      </p> </li> <li> <p>In the Webex Connect Builder Fulfillment select Service: Your_Attendee_ID_2000_Service and Flow: Create_Order_Flowers </p> </li> <li> <p>Publish the update of your AI Agent.     </p> </li> </ol>"},{"location":"main/AI_Lab_Aut_Mission2_New/#task-3-deliver-collected-order-information-to-webex-connect-for-fulfillment","title":"Task 3. Deliver collected order information to Webex Connect for fulfillment.","text":"<ol> <li> <p>Login to the Webex Connect, got to the Service Your_Attendee_ID_2000_Service and click on Manage the flow that you have created earlier.    </p> </li> <li> <p>Click on Edit the flow on the right top. Then double click on the AI Agent. In the Provide Sample JSON, replace the standard JSON body with the following:   </p><pre><code>{\n  \"orderDetails\": \"ID\",\n  \"orderTotal\": \"Type\",\n  \"delivery\": \"Type\",\n  \"address\": \"Type\",\n  \"status\": \"Type\",\n  \"email\": \"Type\"\n}\n</code></pre><p></p> </li> <li> <p>Then click on Parse and Save the change.    </p> </li> <li> <p>Drag and drop HTTP Request node from the left side of the Webex Connect Flow Builder. Connect AI Agent block to the HTTP Request block.     </p> </li> <li> <p>Open up HTTP Request node and configure it with the following HTTP Request: </p> <p>Method: POST  Endpoint URL: https://67e9aa0bbdcaa2b7f5b9ed62.mockapi.io/customerOrder Header: Content-Type: application/      &gt; json  Body:  </p><pre><code>{\n \"orderDetails\": \"$(n2.aiAgent.orderDetails)\",\n \"orderTotal\": \"$(n2.aiAgent.orderTotal)\",\n \"delivery\": \"$(n2.aiAgent.delivery)\",\n \"address\": \"$(n2.aiAgent.address)\",\n \"status\": \"$(n2.aiAgent.status)\",\n \"email\": \"$(n2.aiAgent.email)\"\n}\n</code></pre> <p></p> <p>Output Variable Type: JSON Output Variable Name: orderNumber Response Entity: Body Response Path $.id</p> <p></p> </li> <li> <p>Compare your settings with the screenshot below to make sure you configured the HTTP Request correctly.     </p> </li> <li> <p>Save changies and publish the flow.    </p> </li> </ol>"},{"location":"main/AI_Lab_Aut_Mission2_New/#task-4-deliver-data-from-webex-connect-to-ai-studio-for-the-response-to-the-customer","title":"Task 4. Deliver data from Webex Connect to AI studio for the response to the customer.","text":"<ol> <li> <p>[Read Only] Once the HTTP request is completed a new object will be created on the third pary application. You can see all opbject by using the this link ttps://67e9aa0bbdcaa2b7f5b9ed62.mockapi.io/customerOrder. Below you can see the screenshot with all order informations. Currently there are only 2, but by the time of this lab there could be more.     Each order/object will content all the information that we sent from AI Studio but one - id. This key is created automatically once we create the object. The goal of this talks to send the value of the ID back to the AI Agent so he can provide it to the customer while they are still in live contact, like you can see on the picture below. </p> </li> <li> <p>[Read Only] When you were configuring HTTP Request in your previous TASK on the bottom of the request you were configuring the Output Variable. This variable will be used to parse the unique order id and pass the value to the Outbobount Variable with name orderNumber. See the screenshot below. In the next step we will be configuring this orderNumber variable to be sent Webex AI studio. </p> </li> <li> <p>While on your Webex Connect flow, click on Edit the flow then click on the settings and on the top select Flow Outcomes. In the JSON payout section select Enter JSON.    </p> </li> <li> <p>We need to add the key-value pear to the existing JSON body. Add the comma after the last pear and insert \"orderNumber\": \"$(n3.orderNumber)\". Make sure there is no comma after the pear that you inserted.       Alse see this change in action below.     </p> </li> </ol>"},{"location":"main/AI_Lab_Aut_Mission2_New/#task-5-configure-email-confirmation","title":"Task 5. Configure email confirmation.","text":"<ol> <li> <p>Open up Webex Connect Portal. Find your Service Your_Attendee_ID_2000_Service, navigate to the flow and click on Manage the flow.     </p> </li> <li> <p>On the right top click on Edit then from the available Utilities on the left side find the Email and drag and drop the block to the flow. Connect HTTP node to the Email node.     </p> </li> <li> <p>Double clikc on the Email Block and configure the following:</p> <p>Destination ID: $(n2.aiAgent.email) From Name: Flower Shop Subject: Fower Order Details  Message as below: Here is your order details: orderNumber: \"$(n2.aiAgent.orderNumber)\" orderDetails: \"$(n2.aiAgent.orderDetails)\" orderTotal: \"$(n2.aiAgent.orderTotal)\" delivery: \"$(n2.aiAgent.delivery)\" address: \"$(n2.aiAgent.address)\" status: \"$(n2.aiAgent.status)\" email: \"$(n2.aiAgent.email)\"</p> <p></p> </li> <li> <p>Save and Publish the flow. When it will ask to select the appliction, choose CCBU2000EmailApp from the list. This is the application that is configured for the eamils for this tenant.     </p> </li> </ol> <p>Congratulations, you have officially completed this mission! \ud83c\udf89\ud83c\udf89 </p>"},{"location":"main/AI_Lab_Aut_Mission3/","title":"Mission 3: Upload prebuilt AI Agent.","text":""},{"location":"main/AI_Lab_Aut_Mission3/#mission-3-upload-prebuilt-ai-agent","title":"Mission 3: Upload prebuilt AI Agent.","text":""},{"location":"main/AI_Lab_Aut_Mission3/#mission-overview","title":"Mission overview","text":"<p>Your mission is to:</p> <p>If you were not able to complete Mission 2 on time or encountered some issues during the configurations, this mission will help you upload a prebuilt AI Agent to proceed with the subsequent Missions and Labs.</p> <p>If you were able to complete the Mission 2, you can skip this mission.</p>"},{"location":"main/AI_Lab_Aut_Mission3/#build","title":"Build","text":""},{"location":"main/AI_Lab_Aut_Mission3/#task-1-download-preconfigured-ai-agent","title":"Task 1. Download preconfigured AI Agent.","text":"<ol> <li> <p>Download prebuild VA using the following link: Download VA Agent</p> </li> <li> <p>On the following page, select Download.    </p> </li> <li> <p>Go to AI Studio and select Import agent. Select the agent that you downloaded in the previouse step and provide the AI agent name as following: Agent Name: Your_Attendee_ID_2000_Upload_AutoAI_Lab </p> </li> <li> <p>Click on Publish, provide a comment and Publish your AI Agent.     </p> </li> <li> <p>Test your AI Agent. Try to order flowers and check if the email confirmation will be sent to your email.     </p> </li> </ol> <p>Congratulations, you have officially completed this mission! \ud83c\udf89\ud83c\udf89 </p>"},{"location":"main/AI_Lab_Aut_MissionX/","title":"Mission Integrating the AI Agent with Flow for Voice Calls","text":""},{"location":"main/AI_Lab_Aut_MissionX/#mission-integrating-the-ai-agent-with-flow-for-voice-calls","title":"Mission  Integrating the AI Agent with Flow for Voice Calls","text":""},{"location":"main/AI_Lab_Aut_MissionX/#mission-overview","title":"Mission overview","text":"<p>Your mission is to:</p> <p>Integrate the AI Agent with the Voice Flow. </p>"},{"location":"main/AI_Lab_Aut_MissionX/#task-1-build-wxcc-voice-flow-with-ai-agent","title":"Task 1. Build WxCC voice flow with AI Agent.","text":"<ol> <li> <p>In Control Hub navigate to Flows, click on Manage Flows dropdown list and select Create Flows. Select Start Fresh.    </p> </li> <li> <p>Name the new flow AutonomousAI_Flow_2000_ and click Create Flow.    </p> </li> <li> <p>Make sure the Edit mode at the top is set to ON. Then, drag and drop the Virtual Agent V2 and DisconnectContact activities from the left panel onto the canvas.</p> <p>Note</p> <p>Please make sure to use VirtualAgentV2 activity and NOT VirtualAgent also present on the Activity Library for Backward Compatability.</p> <p>Connect the New Phone Contact output node edge to this VirtualAgentV2 node</p> <p>Connect the Handled outputs to DisconnectContact </p> <p>Connect the Errored outputs to DisconnectContact </p> <p>Click on VirtulaAgentV2 block and select Static Contact Center AI Config</p> <p>Select Contact Center AI Config as Webex AI Agent (Autonomous)</p> <p>Virtual Agent: _2000_AutoAI_Lab </p> </li> <li> <p>Drag and drop Queue Contact and Play Music nodes. Configure them as the following:</p> <ul> <li>Queue Contact </li> </ul> <p>Connect the Escalated path from the Virtual Agent V2 activity to the Queue Contact activity.</p> <p>Connect the Queue Contact activity to the Play Music activity</p> <p>Connect the Failure path from the Queue Contact activity to the Disconnect Contact activity.</p> <p>Click on Queue Contact node and select Static Queue.</p> <p>Queue name: _2000_Voice_Queue </p> <ul> <li>Play Music</li> </ul> <p>Create a loop by connecting the Play Music activity back to itself - to create a music loop, following the diagram provided.</p> <p>Connect the Failure path from the Play Music activity to the Disconnect Contact activity.</p> <p>Music File: defaultmusic_on_hold_cisco_opus_no_1.wav</p> <p> </p> </li> <li> <p>Validate and Publish Flow. In popped up window click on dropdown menu to select Latest label (DO NOT Select any other tag but only Latest), then click Publish.      </p> </li> <li> <p>Assign the Flow to your Channel (Entry Point) - Do this by first going to Channel, search for your channel _2000_Channel.</p> </li> <li>Click on _2000_Channel </li> <li> <p>In Channel settings section change the following:</p> <p>Routing Flow: AutonomousAI_Flow_2000_</p> <p>Version Label: Latest</p> <p>Music on Hold: defaultmusic_on_hold.wav</p> <p></p> </li> <li> <p>Dial Support Number assigned to your _2000_Channel to test the Autonomous AI Agent over a voice call.</p> </li> </ol>"},{"location":"main/AI_Lab_Aut_MissionX/#task-2-test-agent-handoff-configurations","title":"Task 2. Test Agent Handoff Configurations.","text":"<ol> <li>From the browser start logging in to Agent Desktop with the same credentials. You will see another login screen with OKTA on it where you may need to enter the email address again and the password provided to you. </li> <li>Select Desktop endpoint option and choose the team. _2000_Team. Click Submit. Allow browser to access Microphone by clicking Allow on every visit.</li> <li> <p>Make your agent Available and you're ready to make a call.</p> <p></p> </li> <li> <p>Dial the support number assigned to your _2000_Channel channel, and during the conversation with the AI agent, ask to talk to a representetive or live agent. </p> </li> <li> <p>By default, the Conversation Transcripts setting is enabled in VirtualAgentV2 block.     </p> </li> <li> <p>With this setting enabled, the live agent can see the conversation details between the caller and the AI agent. Please check if you can view the IVR transcripts during your test calls with Agent Handoff.      </p> </li> </ol> <p>Congratulations, you have officially completed the Autonomous AI Agent lab! \ud83c\udf89\ud83c\udf89 </p>"},{"location":"main/AI_Lab_Digital_Ch_Overview/","title":"AI Lab Digital Ch Overview","text":""},{"location":"main/AI_Lab_Digital_Ch_Overview/#story","title":"Story","text":"<p>In this lab, you will learn how to integrate your AI Agent with a Digital Channel. You will configure a Webex Connect flow using the AI Agent you created in the previous lab and test the integration through a sample website. </p>"},{"location":"main/AI_Lab_Digital_Ch_Overview/#call-flow-overview","title":"Call Flow Overview","text":"<ol> <li>A customer starts a chat from the website </li> <li>The AI agent will suggest flowers that suit the occasion.</li> <li>Customers will also be able to design their own bouquets from single flowers.</li> <li>AI Agent will generate the order details and total price based on the infrmation in knowledge base</li> <li>AI Agent will send the information about the order to the third pary system. </li> <li>Customer will receive email confirmation with the order details. </li> <li>The customer can always be transferred to a live agent along with the details of the conversation between the AI agent and the customer.</li> </ol>"},{"location":"main/AI_Lab_Digital_Mission1/","title":"AI Lab Digital Mission1","text":""},{"location":"main/AI_Lab_Digital_Mission1/#mission-objective","title":"Mission Objective","text":"<p>In this mission, you need to complete web chat configuration tasks, including creating a Chat Asset, linking it to a Channel, and test website.</p>"},{"location":"main/AI_Lab_Digital_Mission1/#build","title":"Build","text":""},{"location":"main/AI_Lab_Digital_Mission1/#task-1-find-your-service","title":"Task 1. Find your Service.","text":"<ol> <li>Login to Webex Connect Portal. Go to Services and look for the service that you have created earlier. The name should be Your_Attendee_ID_2000_Service </li> </ol>"},{"location":"main/AI_Lab_Digital_Mission1/#task-2-configure-and-register-chat-asset","title":"Task 2. Configure and Register Chat Asset.","text":"<ol> <li> <p>While on Webex Connect portal, go to Assets -&gt; Apps, press Configure New App and select Mobile / Web option.    </p> </li> <li> <p>Input Name as Chat_App_Your_Attendee_ID_2000</p> </li> <li> <p>Toggle/enable Live Chat / In-AppMessaging to ON and choose Primary Transport Protocol as <code>MQTT</code> &amp; Secondary Transport Protocol as <code>Web Socket</code> then tick Use Secured Port checkbox and press Save button.    </p> <p>Note: If there is an error that your request cannot be processed, please press Save button one more time.</p> </li> <li> <p>Once asset is saved, press Register To Webex Engage at the top.     </p> </li> <li> <p>Choose Your_Attendee_ID_2000_Service from the drop-down list and press Register button.    </p> </li> <li> <p>Check and make sure the asset has been succesfully registered to the service and  Register To Webex Engage button has been greyed out.    </p> </li> <li> <p>Return to Assets -&gt; Apps, find ChatAsset, copy App ID, paste it into the text file and save. We will use it when configuring chat flow later.    </p> </li> </ol>"},{"location":"main/AI_Lab_Digital_Mission1/#task-3-create-entry-point-for-chat","title":"Task 3. Create Entry Point for Chat","text":"<ol> <li> <p>Login to Control Hub and go to Channels and click on Create Channel.    </p> </li> <li> <p>Input Name as Your_Attendee_ID_2000_Chat_Channel </p> </li> <li> <p>Select Chat from the Channel Type drop-down list. Select Chat_App_Your_Attendee_ID_2000 as an Asset Name. Set Service Level Threshold as <code>360</code> and click on Save.    </p> </li> </ol>"},{"location":"main/AI_Lab_Digital_Mission1/#task-4-create-queue-for-chat","title":"Task 4. Create Queue for Chat","text":"<ol> <li> <p>While on the Control Hub portal go to Queues and click on Create a queue.    </p> </li> <li> <p>Input Name as Your_Attendee_ID_2000_Chat_Queue. Also select <code>Chat</code> in the Channel Type section.    </p> </li> <li> <p>Scroll down to Chat Distribution click on Add Group and select Your_Attendee_ID_2000_Team </p> </li> <li> <p>Set Service Level Threshold as <code>7200</code> seconds (2 hours). Set Maximum Time in Queue as <code>10800</code> seconds (3 hours). Click on Save after comparing your values with the screenshot below.    </p> </li> </ol>"},{"location":"main/AI_Lab_Digital_Mission1/#task-5-website-widget-configuration","title":"Task 5. Website Widget Configuration","text":"<ol> <li> <p>Login to Webex Engage Portal.    </p> </li> <li> <p>Go to Assets -&gt; search and edit Chat_App_Your_Attendee_ID_2000 which you have created in Connect Portal.    </p> </li> <li> <p>Scroll down and click on Save Changes button.    </p> </li> <li> <p>Scroll to top of the page and choose Websites tab. Click on ADD Website.    </p> </li> <li> <p>Fill in the respective fields as per the table below:</p> Parameter Name Parameter Value Chat Widget Language English-US Display Name Flower Shop Byline Text Button Text Start Chat First message Hello! Welcome to the chat PCI Compliance Banner Message This chat is PCI compliant Domain *.glitch.me Set wait time Disabled Set Chat Announcement Enabled </li> <li> <p>Review the configurations and Save changes </p> </li> <li> <p>Scroll up, select Appearance and change the settings:</p> <ul> <li>[Optional] Widget Color</li> <li>[Optional] Widget Button Type</li> <li>[Optional[ Logo</li> <li>Enable Emojis</li> <li>Enable Attachments   Press Save changes button at the bottom of the page.  </li> </ul> </li> <li> <p>Scroll up, select Widget Visibility tab and make sure that Force Turn Off Widget switch is disabled.  Then select Widget Visibility as Show without any restrictions and save changes.      </p> </li> <li> <p>Now click on &lt; arrow near Website Settings and go-back to edit your chat asset.      </p> </li> <li> <p>Select Installation then click on Copy to copy the chat script to clipboard.      </p> </li> </ol>"},{"location":"main/AI_Lab_Digital_Mission1/#task-6-paste-the-script-to-the-test-website","title":"Task 6. Paste the script to the test website.","text":"<ol> <li> <p>In this lab, we are using the glitch.com platform to test our chat functionality on a sample website. Using your personal gmail plesae login to glitch.com and create your own custom website where you can embed the chat widget. Open index.html file to see the structure of the website.       </p> </li> <li> <p>While having index.html file open, copy the script that you have save in notepad in the prevouse Task and paste it between footer and body tags.       </p> </li> <li> <p>Click on the website preview, and you should see the chat bubble appear in the bottom-right corner.      </p> </li> </ol> <p>Congratulations, you have officially completed this mission! \ud83c\udf89\ud83c\udf89 </p>"},{"location":"main/AI_Lab_Digital_Mission2/","title":"AI Lab Digital Mission2","text":""},{"location":"main/AI_Lab_Digital_Mission2/#mission-objective","title":"Mission Objective","text":"<p>In this mission, you will download the Webex Connect flow and configure it to work with you Webex AI agent. </p>"},{"location":"main/AI_Lab_Digital_Mission2/#build","title":"Build","text":""},{"location":"main/AI_Lab_Digital_Mission2/#task-1-create-new-webex-connect-flow-from-template","title":"Task 1. Create New Webex Connect flow from template.","text":"<ol> <li> <p>Download the Webex Connect flow using the following link: Webex Connect Flow</p> </li> <li> <p>Go to Webex Connect portal and open your service with the name Your_Attendee_ID_2000_Service </p> </li> <li> <p>Click on Flows and then click on Create Flow.    </p> </li> <li> <p>Name the flow as Chat_AI_Agent_Your_Attendee_ID and select Upload flow option from the list.    </p> </li> <li> <p>Click on Choose File, select the fild that you have downloaded in the step 1, then click on Create.    </p> </li> <li> <p>On the following page click on Save </p> </li> </ol>"},{"location":"main/AI_Lab_Digital_Mission2/#task-2-configure-the-webex-connect-flow","title":"Task 2. Configure the Webex Connect Flow.","text":"<ol> <li> <p>Open up Resolve Conversation block and configure the Flow Id with the same that you can find in the URL. Click on Save.    </p> </li> <li> <p>Open up AI Agent block and select from the list the AI Agent that you have created earlier. The name can be Your_Attendee_ID_2000_AutoAI_Lab </p> </li> <li> <p>Open up Queue Task and select the queue Your_Attendee_ID_2000_Chat_Queue from the list that is related to your config.     </p> </li> <li> <p>Open up New Webex Connect Window, go to Applicaitons and find the AppID that is related to your Chat Application with name Chat_App_Your_Attendee_ID_2000 </p> </li> <li> <p>Go to your Webex Connect Flow, open up Flow Settings, click on Custom Variables and adjust the appID with the one you copied in the previous step.     </p> </li> <li> <p>For better tracking purposes, also change the liveChatDomain in the Custom Variables settings from *.glitch.me to the website that is associated with your user account. For example for my test account it is shine-rapid-freesia.glitch.me. For your account please refare the table below. [NEED to Add Table] </p> </li> <li> <p>Open the first Receive node and Save it.    </p> </li> <li> <p>Open the second Receive node and Save it.    </p> </li> <li> <p>Save and Make Live the flow. On the following page, select the Chat Application that you have created earlier. The name can be Chat_AI_Agent_Your_Attendee_ID.    </p> </li> <li> <p>If you noticed any error while making the flow Live, please wait until the flow is published and publish it one more time.     </p> </li> </ol> <p>Congratulations, you have officially completed this mission! \ud83c\udf89\ud83c\udf89 </p>"},{"location":"main/AI_Lab_Digital_Mission3/","title":"AI Lab Digital Mission3","text":""},{"location":"main/AI_Lab_Digital_Mission3/#mission-objective","title":"Mission Objective","text":"<p>In this mission, you will test the conversation with an AI Agent over the Chat Digital Channel, as well as test the chat transfer to a human agent.</p>"},{"location":"main/AI_Lab_Digital_Mission3/#test","title":"Test","text":""},{"location":"main/AI_Lab_Digital_Mission3/#task-1-test-conversation-with-ai-agent","title":"Task 1. Test conversation with AI Agent.","text":"<ol> <li> <p>Open up website that is related to your account and initiate the chant. Order flowers with delivery and email confirmation.    </p> </li> <li> <p>You should also receive the confirmation email to the specifed email address.     </p> </li> </ol>"},{"location":"main/AI_Lab_Digital_Mission3/#task-2-test-the-handoff-to-a-human-agent","title":"Task 2. Test the handoff to a human agent.","text":"<ol> <li> <p>During conversation with AI agent ask to talk to a live agent.     </p> </li> <li> <p>Login to Agent Desktop with your agent credentials to receive the test chat. You should see the transcripts with details of what the customer was discussing with the AI Agent before the conversation was handed off to the live agent.    </p> </li> </ol> <p>Congratulations, you have officially completed this mission! \ud83c\udf89\ud83c\udf89 </p>"},{"location":"main/AI_Lab_Digital_Overview/","title":"AI Lab Digital Overview","text":"<p>Congratulations on completing the Cisco Webex AI Agent Digital Channel Integration lab! </p> <p>In this lab, you\u2019ve gained hands-on experience integrating your AI Agent with a digital channel using a Webex Connect flow. You successfully configured and tested the integration through a sample website, enabling a seamless customer experience.</p> <p>You explored how the AI Agent interacts with customers to suggest flowers, assist in designing custom bouquets, generate order details and pricing, and send order information to third-party systems. Additionally, you saw how the AI Agent facilitates email confirmations and ensures a smooth handoff to a live agent, complete with conversation details. </p> <p>These skills empower you to design intelligent, end-to-end virtual agent solutions that enhance customer engagement across digital channels. Keep building and refining your expertise to create impactful conversational AI experiences!</p>"},{"location":"main/AI_Lab_Features_Overview/","title":"AI Lab Features Overview","text":""},{"location":"main/AI_Lab_Features_Overview/#story","title":"Story","text":""},{"location":"main/AI_Lab_Features_Overview/#webex-contact-center-ai-assistant-lab","title":"Webex Contact Center AI Assistant Lab.","text":"<p>This lab demonstrates how to pass contextual intelligence from AI agents to Webex Contact Center agents.</p>"},{"location":"main/AI_Lab_Features_Overview/#key-objectives","title":"Key Objectives:","text":"<ul> <li>Capture AI-generated summaries of virtual agent conversations</li> <li>Enable real-time call transcription for human agents</li> <li>Provide agents with full context before and during live interactions</li> </ul>"},{"location":"main/AI_Lab_Features_Overview/#benefits","title":"Benefits:","text":"<ul> <li>Reduce customer repetition</li> <li>Improve agent efficiency and accuracy</li> <li>Deliver smoother transitions from AI to human support</li> </ul> <p>By completing this lab, you'll learn how to enhance agent experiences using AI-powered context and live insights.</p>"},{"location":"main/AI_Lab_Features_Overview/#call-flow-overview","title":"Call Flow Overview","text":"<ol> <li>A new call enters the flow.</li> <li>The AI agent engages with the caller by asking pre-configured questions.</li> <li>The AI agent gathers all necessary details and transfers the call to a human agent.</li> <li>The human agent receives a summary of what was discussed between the caller and the AI agent.</li> <li>The human agent can view live transcripts while communicating with the caller.</li> </ol>"},{"location":"main/AI_Lab_IVR_Campaign_Conclusion/","title":"AI Lab IVR Campaign Conclusion","text":"<p>Congratulations on completing the Webex Campaign for Contact Center lab!</p> <p>In this lab, you gained practical experience in configuring and managing outbound voice campaigns using the Webex Campaign module. You explored the Webex Campaign User Interface and learned how to configure essential components such as business days, contact modes, DNC lists, suppression rules, and telephony outcomes to ensure compliance and optimize campaign performance.</p> <p>You successfully created a Progressive IVR Campaign, where an AI Virtual Agent engages with customers to promote a flower show and facilitate order creation. Additionally, you learned to create campaign flows, set up outdial channels, configure new campaigns, and upload contact lists for efficient campaign execution.</p> <p>With these skills, you are now equipped to streamline and optimize outbound campaigns, ensuring compliance while achieving specific business objectives. Keep applying these capabilities to deliver impactful and compliant customer outreach solutions!</p>"},{"location":"main/AI_Lab_IVR_Campaign_Mission1/","title":"AI Lab IVR Campaign Mission1","text":""},{"location":"main/AI_Lab_IVR_Campaign_Mission1/#mission-details","title":"Mission Details","text":"<p>You will explore the Webex Campaign User Interface and understand how to configure its key components, including business days, contact modes, DNC lists, suppression rules, telephony outcomes, and more. These configurations will help you implement and optimize a Campaign Voice Flow effectively.</p>"},{"location":"main/AI_Lab_IVR_Campaign_Mission1/#featurs-overview","title":"Featurs Overview.","text":""},{"location":"main/AI_Lab_IVR_Campaign_Mission1/#task-1-create-new-google-profile","title":"Task 1 Create new Google Profile","text":"<ol> <li> <p>Currently, users with aliases are not allowed to log in to the new Campaign Management portal. Engineering is working to resolve this issue. However, for this lab, we will all be using one user account (wxcclabscx@gmail.com). Since you are already using the default Chrome profile to log in to Control Hub, you will need to create an additional Chrome profile to log in to the Campaign Management portal.</p> </li> <li> <p>Open up Google Chrome and on the right top sides click on the profiles and then click on Add Chrome Profile.     </p> </li> <li> <p>Select Continue without an account.     </p> </li> <li> <p>Name your profile, for example, Webex Campaign and click Done. </p> </li> </ol> <p></p>"},{"location":"main/AI_Lab_IVR_Campaign_Mission1/#task-2-overview-only-explore-the-webex-campaign-user-interface","title":"Task 2 [OVERVIEW ONLY]. Explore the Webex Campaign User Interface.","text":"<ol> <li> <p>Using the following user name and the password (wxcclabscx@gmail.com/TSSumm!t_2024!$%) login to the portal  Campaign Manager.</p> </li> <li> <p>You will see a welcome message along with a list of required configurations that need to be completed to set up the Campaign Voice Flow. Click on Got it.      </p> </li> <li> <p>Navitate to Voice campaigns administration module.     </p> </li> <li> <p>Click on Business Days. You can select the swipe button of the required business day to enable or disable it. The campaign will be paused if it identifies a disabled business day and resumes on the next business day.     </p> </li> <li> <p>Click on Contact modes. You can create different contact modes in Webex Campaign to attribute a particular phone number as a Home or Office numbers.     </p> </li> <li> <p>Click on DNC List. You can create and manage multiple DNC (Do Not Contact) lists. The contacts in DNC lists will be excluded from Target Groups before deploying a campaign. Most commonly, this is used to manage contacts who have registered for DNC with telecom operators.     </p> </li> <li> <p>Click on Field mappings. This settings refer to the process of uploading a template or sample data and mapping the headers with the headers of dialer system. When you create a campaign, you have to assign the field mappings to a campaign and appropriate contact list has to be uploaded. When you upload a contact list to a campaign, and if the headers of the field mappings do not match, then you will get an error.     </p> </li> <li> <p>For this lab, Field Mapping is preconfigured. However, it is important for you to understand that, during the creation of the field mapping, we assigned the Global Variables to match the headers of the file you will be uploading when managing the campaign list.     </p> </li> <li> <p>Click on Global Variable. These attributes are configured in the control hub application. Webex Campaign will receive these variables from control hub application. At least one variable has to be made a customer unique identifier.     </p> </li> <li> <p>Click on Purpose meta-tags. This feature provides a way to separate and maintain the type of campaigns; a user can set up for particular business requirements. During campaign activation, you can tag the campaign with one or more purposes. This allows the enterprise to analyze what type of campaigns they are creating through the platform and helps to maintain a \u2018balanced diet\u2019 of communications for contacts.     </p> </li> <li> <p>Click on P&amp;L meta-tags. This section allows a business to assign a campaign to different divisions, cost centers, or products. For instance, an organization might set up different P&amp;Ls for departments.     </p> </li> <li> <p>Click on SFTP configurations. This section allows you to add SFTP connection details that can be used to access the contact list over SFTP connections.     </p> </li> <li> <p>Click on Telephony outcome settings. These settings refer to the configurations that help define and track the results of calls. These options are configured in the dialer. Webex campaign will receive these outcomes from dialer. They allow businesses to categorize and record the outcome of each call made to a customer. You can edit the outcome to suit your business use case. For example, if the dialer records the outcome as Busy and Close contact - Yes ( do not attempt to call again) can be overwritten in Webex campaign to Close contact - No ( make an attempt to call again).    </p> </li> <li> <p>While on Telephony outcome settings click on Edit of any of them and you will see the how they are configured now. You can customize it per your buisness logic.     </p> </li> <li> <p>Click on Wrap-up code settings. These settings refer to the codes that are tagged by the agent after ending the call. They allow businesses to categorize and record the outcome of each call made to a contact. These codes are created in Control Hub.    </p> </li> <li> <p>Click on Edit any of the Wrap-up code to review how it is configured.     </p> </li> </ol> <p>Congratulations, you have officially completed this mission! \ud83c\udf89\ud83c\udf89 </p>"},{"location":"main/AI_Lab_IVR_Campaign_Mission2/","title":"AI Lab IVR Campaign Mission2","text":""},{"location":"main/AI_Lab_IVR_Campaign_Mission2/#mission-details","title":"Mission Details","text":"<p>Your mission is to create a new campaign that will deliver call to your cellphone number. When you answer the call, you will be connected to the Blossom AI Agent for interaction.</p>"},{"location":"main/AI_Lab_IVR_Campaign_Mission2/#task-1-create-flow-for-the-campaign","title":"Task 1. Create Flow for the Campaign.","text":"<ol> <li> <p>Login to Control Hub</p> </li> <li> <p>Go to Contact Center &gt; Flows, click on Creat Flow.    </p> </li> <li> <p>Click on Start Fresh.    </p> </li> <li> <p>Name the flow as OutDial_Flow_2000_ and click Create Flow.    </p> </li> <li> <p>In the Main Flow, add End Flow block and connect New Phone Contact block to the End Flow block.     </p> </li> <li> <p>Click on the Event Flows.    </p> </li> <li> <p>Add GoTo node and connect it to Outbound Campaign node.     </p> </li> <li> <p>Click on GoTo node and configure it with the Flow that you created in earlier labs for AI agent. It could have the name Flow: AutonomousAI_Flow_2000_ and click Create Flow if you completed all the previous lab. If you just started from this lab, then you need to create another flow with your Virual Agent.  Also Validate and Publish the Flow.     </p> </li> </ol>"},{"location":"main/AI_Lab_IVR_Campaign_Mission2/#task-2-create-outdial-channel-for-the-campaign","title":"Task 2. Create Outdial Channel for the Campaign.","text":"<ol> <li> <p>Click on Channels then click on Create Channel </p> </li> <li> <p>Name the Channle as _2000_Channel_Outdial. Select Type as Outbound Telephony.    </p> </li> <li> <p>Configure Service Level Threshold with 300 seconds, select the flow that you have created in the previous Task, add a music on hold and select the Outdial Queue with name 2000_Campaign_Q </p> </li> </ol>"},{"location":"main/AI_Lab_IVR_Campaign_Mission2/#task-3-configure-new-campaign","title":"Task 3. Configure new Campaign.","text":"<ol> <li> <p>Login to Webex Campaign Manager using the Chrome Profile that you created in the previous Mission.     </p> </li> <li> <p>Click on Campaign groups and select 2000_Campaign_Group.     </p> </li> <li> <p>Click on Creat campaign.    </p> </li> <li> <p>Click on Dialer Configuration. Select Channel (Entry Point) that you have created in the previous Task. Dialer mode select as Progressive IVR. Then Save changies.    </p> </li> <li> <p>Click on Contact list source, select Manual file upload.     </p> </li> <li> <p>Select preconfigured field mapping with name 2000_Lab. Select experation value to 30 days. Then click on Save changies.    </p> </li> <li> <p>Select Daily schedule. Configure the start day and active hours during the day. Then Save changies </p> </li> <li> <p>Click on Schedule exlusion dates and just Save changies.    </p> </li> <li> <p>Select Contact attampt strategy and click on Configure.    </p> </li> <li> <p>Change the Cycle internval to 1 minute and click on Save.    </p> </li> <li> <p>Once the attempts strategy is configurd, click on Save changies.    </p> </li> <li> <p>Click on Suppression rule sets. Then select Suppression rule not require option. Save changes.    </p> </li> <li> <p>Confirm that you would like to Continue without supression rules.     </p> </li> <li> <p>Click on Save &amp; exit the Campaign configuration.     </p> </li> <li> <p>Name the Campaign as _2000_Campaign. For P&amp;L from the list select TrainingAB_PL_17748776940323. For Purpose select from the list Sales, and click on Save campaign.    </p> </li> <li> <p>You will see you campaign will show up in the DRAFT status.     </p> </li> </ol>"},{"location":"main/AI_Lab_IVR_Campaign_Mission2/#task-4-upload-contact-list","title":"Task 4. Upload Contact List.","text":"<ol> <li> <p>Click on Customers_List_sample to download the sample file.</p> </li> <li> <p>On the next page, click on Download.    </p> </li> <li> <p>Open the file and change the number to your 10 digits cellphone number.     </p> </li> <li> <p>Go back to Webex Campaign Manger, find your campaign and click on Manage contact lists.     </p> </li> <li> <p>Click on Upload file to create contact list.    </p> </li> <li> <p>Click on Browse, select your file and then click on Save and Proceed.    </p> </li> <li> <p>If you click on Refresh you should see the contact list is Active.     </p> </li> <li> <p>Close the Manage contact list page.     </p> </li> <li> <p>Find your Campaign and make it Active.    </p> </li> <li> <p>On the next page click on Confirm </p> </li> <li> <p>Click on Refresh you should see that you campaign is Running.     </p> </li> <li> <p>Initially, the contact will be in the Eligible Open status. Wait until the contact transitions to Sent to Dialer - Awaiting Outcome. At that point, you should receive a call. When you answer, please say \"Hello\" to allow the system to detect a live voice. Once detected, you will begin the conversation with the AI Agent.    </p> </li> <li> <p>Open up your flow, and you can trace this call.     </p> </li> <li> <p>If you need to upload the new list, first Pause the campaign. (DO NOT Stop the Campaign)    </p> </li> <li> <p>Upload the new contacts.    </p> </li> <li> <p>Resume the Campaign.    </p> </li> </ol>"},{"location":"main/AI_Lab_IVR_Campaign_Overview/","title":"AI Lab IVR Campaign Overview","text":""},{"location":"main/AI_Lab_IVR_Campaign_Overview/#story","title":"Story","text":"<p>Webex Campaign for Contact Center is an add-on module for Webex Contact Center product to streamline and optimize outbound voice campaigns while ensuring full compliance with federal and state regulations, including TCPA and FDCPA (Regulation F). Key features include intelligent time zone management, customizable suppression rules, automated retry logic for failed contact attempts, and robust tools to help achieve campaign-specific business objectives.  In this lab, you will review the Webex Campaign User Interface and understand the main configurations that need to be completed to implement Campaign Voice Flow. Using the Campaing manager you can configure Progressive IVR Campaing that would establish the call between AI virtual Agent and a customer where AI Agent can share the promotion of the flower show and try to create and order.</p>"},{"location":"main/AI_Lab_IVR_Campaign_Overview/#capabilities","title":"Capabilities","text":"<p>An Interactive Voice Response (IVR) dialing mode enables a computer to communicate with humans using voice prompts and DTMF tones entered via a keypad. Typically, when the system initiates an outbound call to a contact, it provides options to route the call to the appropriate department or agent based on the selected input. However, for this lab, the call will not interact with an IVR system but will instead be directly connected to an AI agent.</p>"},{"location":"main/AI_Lab_Overview/","title":"AI Lab Overview","text":""},{"location":"main/AI_Lab_Overview/#ai-autonomous-agent-overview","title":"AI Autonomous Agent Overview","text":"<p>The Autonomous AI Agent for performing actions can handle various tasks, including:</p> <ul> <li>Natural Language Processing (NLP)\u2014Understand and respond to human language in a natural and conversational manner.</li> <li>Decision making\u2014Make informed choices based on available information and predefined rules.</li> <li>Automation\u2014Automate repetitive or time-consuming tasks. </li> </ul>"},{"location":"main/AI_Lab_Overview/#story","title":"Story","text":"<p>You are designing a Webex Autonomous AI agent for a flower store. This AI agent will recommend flowers to customers based on the occasion, collect order details, calculate the total price, update the order information in a third-party application using APIs, and send a confirmation SMS with the order details. Remember, customers will trust the AI Agent only when they truly believe it can assist them effectively. That\u2019s exactly what you\u2019ll be working to achieve in this lab!</p> <p>Webex AI Agent</p>"},{"location":"main/AI_Lab_Overview/#call-flow-overview","title":"Call Flow Overview","text":"<ol> <li>A new call enters the voice flow. </li> <li>The AI agent will suggest flowers that suit the occasion.</li> <li>Customers will also be able to design their own bouquets from single flowers.</li> <li>AI Agent will generate the order details and total price based on the infrmation in knowledge base</li> <li>AI Agent will send the information about the order to the third party system. </li> <li>Customer will receive SMS confirmation with the order details. </li> <li>The customer can always be transferred to a live agent along with the details of the conversation between the AI agent and the caller.</li> </ol>"},{"location":"main/AI_Lab_Scripted_Conclusion/","title":"AI Lab Scripted Conclusion","text":"<p>Congratulations on completing the Cisco Webex AI Scripted Agent lab! </p> <p>In this lab, you\u2019ve learned to create and enhance virtual agents by integrating them with voice call flows, updating responses, adding intents and entities, and leveraging generative AI to improve training data. You\u2019ve also explored using fulfillment to dynamically track order statuses. </p> <p>By following the call flow, you\u2019ve seen how AI Agents can efficiently handle tasks like providing store hours and tracking orders, enabling seamless customer interactions. These skills equip you to build intelligent, effective virtual agents for real-world applications.</p>"},{"location":"main/AI_Lab_Scripted_Mission1/","title":"AI Lab Scripted Mission1","text":""},{"location":"main/AI_Lab_Scripted_Mission1/#mission-details","title":"Mission Details","text":"<p>Your mission is to create a new Scripted AI Agent from the template and configure basic Scripted AI Agent functionalities by adding intents and responses.</p>"},{"location":"main/AI_Lab_Scripted_Mission1/#build","title":"Build","text":""},{"location":"main/AI_Lab_Scripted_Mission1/#task-1-creating-a-ai-agent-using-a-template","title":"Task 1. Creating a AI Agent using a Template","text":"<ol> <li> <p>[IMPORTANT] Download the Scripted Agent.      </p> </li> <li> <p>Login in to Webex Control Hub by using your Admin profile wxcclabs+admin_ID@gmail.com. You will see another login screen with OKTA on it where you may need to enter the email address again and the password provided to you.</p> </li> <li> <p>Go to Contact Center from the left side navigation panel, and under Quick Links, click on Webex AI Agent</p> <p> </p> </li> <li> <p>Click on Import agent to create a new AI Agent by importing preconfigured template. Click on Upload button, locate and select ScriptedAIAgent.json you downloaded at the beginning of the mission.</p> </li> <li>Name your Agent as _Scripted_AI_Agent and click Import</li> <li>Make the bot live by clicking on Save Changes and then Publish button on top right.</li> <li> <p>Enter v1 in the popup comment window, then click Publish.     </p> </li> <li> <p>Click on the Preview button on the top right side to test the bot. Try the bot flow by typing What are the store hours? You will notice the following response: </p> <p>Sorry, I was unable to understand your query accurately.</p> <p> </p> </li> <li> <p>The initial response can be customized, and we also need to configure intents and responses to enable the Scripted AI Agent to answer questions about store hours.</p> </li> </ol>"},{"location":"main/AI_Lab_Scripted_Mission1/#task-2-update-the-initial-greeting","title":"Task 2. Update the initial greeting.","text":"<ol> <li> <p>As soon as the interaction reaches the Scripted AI Agent, the system initiates the Welcome response. To change the initial greeting, go to Script &gt; Responses then open the Welcome response and update the response text there. Change the text to: Hi, my name is Blossom, the virtual assistant. I can help you with tracking your order or providing the store's business hours.  Please do it for Web and Voice channels. After the change, Save and Publish the Scripted AI agent.       </p> </li> <li> <p>Click on the Preview button on the top right side to test the bot. Check if the initial greeting was changed.       </p> </li> </ol>"},{"location":"main/AI_Lab_Scripted_Mission1/#task-3-configure-scripted-ai-agent-to-answer-questions-about-store-hours","title":"Task 3. Configure Scripted AI agent to answer questions about store hours.","text":"<ol> <li> <p>Before we move on with adjusting and configuring intents and responses, it is important for you to understand the flow of the Scripted AI Agent. Once a customer asks a question, the AI engine and Natural Language Understanding (NLU) service tries to match it to an intent based on the training phrases. The intent is then configured with a response. After the customer receives the response, they can ask another question, and the same process applies. The AI engine and NLU match the customer\u2019s query to an intent, which is configured with a response. Additionally, fulfillment can also be configured as part of the response. This is the basic flow concept of the Scripted AI Agent.      </p> </li> <li> <p>While on the Script configuration page, switch to Intents tab and click on the Create Intent button located in the top right corner.</p> </li> <li> <p>Add a new intent by providing the intent name as store_hours and include the following two utterances:</p> <ul> <li>What are the store hours?</li> <li>What is the business hours for this store?</li> </ul> <p> </p> </li> <li> <p>Click on the Generate button to utilize Generative AI for creating additional training phrases.</p> </li> <li> <p>Enter a description such as Generate intents store business hours Set the Number of Variants to 10, which will determine the number of new phrases to be generated. Click Generate</p> <p>Make a note of newly created Utterances </p> </li> <li> <p>Now we need to configure a response that would be related to this intent. Scroll down and click on Create new.      </p> </li> <li> <p>Name the response as store_hours. Update Variant 1 text to The store hours are from 9 am to 5 pm. Please let me know if you have any other questions.. Move to next step before clicking Create </p> </li> <li> <p>Add one more Variant and provide the text: The store is open from 9 am to 5 pm. Is there anything else I can do for you? </p> </li> <li> <p>Add Voice Channel.      </p> </li> <li> <p>Configure Voice Channel with the same Variants and click on Create.  The store is open from 9 am to 5 pm. Is there anything else I can do for you?. The store hours are from 9 am to 5 pm. Please let me know if you have any other questions.      </p> </li> <li> <p>Now after we added the response to our intent we can complete the intent configuration. Click on Add on the right bottom corner. Save and Publish the Scripted AI Agent.       </p> </li> <li> <p>Click on the Preview button on the top right side to test the bot. Try the bot flow by typing What are the store hours? </p> </li> </ol> <p>Congratulations, you have officially completed this mission! \ud83c\udf89\ud83c\udf89 </p>"},{"location":"main/AI_Lab_Scripted_Mission2/","title":"AI Lab Scripted Mission2","text":""},{"location":"main/AI_Lab_Scripted_Mission2/#mission-details","title":"Mission Details","text":"<p>Your mission is to review preconfigured Scripted AI Agent for tracking existing order. If you would like to build it by yourself there are BONUS Missions 3,4,5 and 6 of this lab. </p>"},{"location":"main/AI_Lab_Scripted_Mission2/#build","title":"Build","text":""},{"location":"main/AI_Lab_Scripted_Mission2/#task-1-review-the-configurations-in-ai-studio-to-track-an-order","title":"Task 1. Review the Configurations in AI Studio to track an order.","text":"<ol> <li> <p>Go to AI Studio and open AI Agent with name 180_Scripted_AI_Agent.  Please do not making any changes to this agent, as this lab is for review purposes only for the entire group.</p> <p> </p> </li> <li> <p>Below is the diagram for tracking order flow. If the caller asking to track an order, track_order intent should be used as it has utterances like Can you track my order and others. This intent is configured to collect required Entity, for this the interaction will be moved to the interim response with name order_number. </p> </li> <li> <p>Open up 180_Scripted_AI_Agent  AI agent. Click on Script &gt; Intents and then open up track_order intent.        </p> </li> <li> <p>If this intent is triggered (customer request matches the Utterances), then system will initiate the response order number until the required entity is filled or the number of retries is exceeded.       </p> </li> <li> <p>Once the entity is filled, the system initiates the final response for this intent. In this case, it is track_order.       </p> </li> <li> <p>Click on Entities and review order_number Entity configuration.        </p> </li> <li> <p>Click on Responces and seach for order_number responce and review it for responce message </p> </li> </ol>"},{"location":"main/AI_Lab_Scripted_Mission2/#task-2-send-the-data-from-ai-agent-to-voice-flow","title":"Task 2. Send the data from AI Agent to Voice Flow\u200b.","text":"<ol> <li> <p>Click on Responses and open up response with name track_order </p> </li> <li> <p>Review the response configuration after clicking the Voice channel       </p> </li> <li> <p>Go to Control Hub &gt; Contact Center. Click on Flows and open the flow with name Autonomous_Scripted_Flow_2000_180.       </p> </li> <li> <p>Click on the lower VirtualAgentV2 block. You will see the Activity Output Variables. The Entity value can be found in VirtualAgentV2.MetaData.        </p> </li> <li> <p>Click on the next SetVariable block and you can see that we just assigned the value from Activity Output Variable from the previous VirtualAgentV2 block to the flow variable with name MetaData_Scripted_Agent. This is an optional step.        </p> </li> <li> <p>Click on Parse block. It is configured to parse data from MetaData_Scripted_Agent variable using JSON path $.ordernumber and assign the respon to the flow variable with name order_id.       </p> </li> <li> <p>Open up HTTP Request block. It is configured to send GET request with the parameter as the order_id value to retrive the response specifically for this order.        </p> </li> <li> <p>If we would do the same request from Postman for the order Id 17, here is the information we would get.        </p> </li> <li> <p>While on HTTP Request node, scroll down and you will see the configurations to parse the data from the response. It is configured to use JSON path $.[0].status and assign the response to the variable with name order_status.       </p> </li> <li> <p>For example if I would need to parse the status of the order 17 using this JSON path, the result would be \"new\".       </p> </li> </ol>"},{"location":"main/AI_Lab_Scripted_Mission2/#task-3-send-the-data-from-voice-flow-to-ai-agent","title":"Task 3. Send the data from Voice Flow to AI Agent.","text":"<ol> <li> <p>To send data back to AI Studio we need to use one more VirtualAgentV2 block. Click on it to review configurations. You can see that we use the same Scripted AI agent 180_Scripted_AI_Agent, but we also configured the State Event. The Event Name will refer to the response on AI Studio. And the Event Data contains the result of the order_status that can be retrieved in the AI Studio.       </p> </li> <li> <p>Go to AI Studio and open AI Agent with name 180_Scripted_AI_Agent. Please do not make any changes to this agent, as this lab is for review purposes only for the entire group. </p> </li> <li> <p>Open the response with the name order_status. The same name was specifed in the VirtualAgentV2 block as the Event Name.        </p> </li> <li> <p>Open up the response and you can see that data will be returned using the following format: ${eventStore.status}.       </p> </li> </ol>"},{"location":"main/AI_Lab_Scripted_Mission2/#task-4-place-test-call-and-review-the-trace","title":"Task 4. Place test call and review the trace.","text":"<ol> <li> <p>Call the number +15206603129 that is configured to deliver the call to the flow Autonomous_Scripted_Flow_2000_180.       </p> </li> <li> <p>Press 2 to go to the Scripted AI agent. Ask to track your order. Provide the order number as 17 or any other order that you created earlier. You should hear the response that the order status is \"new\".</p> </li> <li> <p>Open up Debug mode in the flow Autonomous_Scripted_Flow_2000_180.      </p> </li> <li> <p>Review the trace.        </p> </li> <li> <p>In the AI Agent Studio, go to Sessions and review the traces.        </p> </li> </ol> <p>Congratulations, you have officially completed this mission! \ud83c\udf89\ud83c\udf89 </p>"},{"location":"main/AI_Lab_Scripted_Mission3/","title":"AI Lab Scripted Mission3","text":""},{"location":"main/AI_Lab_Scripted_Mission3/#mission-details","title":"Mission Details","text":"<p>Your mission is to integrate the Scripted AI agent with Voiceflow to enable it to answer questions about store hours.</p>"},{"location":"main/AI_Lab_Scripted_Mission3/#build","title":"Build","text":""},{"location":"main/AI_Lab_Scripted_Mission3/#task-1-add-the-newly-created-scripted-agent-to-the-voice-flow","title":"Task 1. Add the newly created Scripted Agent to the Voice flow.","text":"<ol> <li> <p>In Control Hub go to Contact Center, click on Flows, and search for the flow with name AutonomousAI_Flow_2000_Your_Attendee_ID. Or if you created the flow with a different name in the lab \"Autonomous AI Agent, try to find your flow.       </p> </li> <li> <p>Click on Edit and rename the flow to Autonomous_Scripted_Flow_2000_Your_Attendee_ID. Publish the flow.       </p> </li> <li> <p>Add Menu node in front of the VirtualAgentV2 node.       </p> </li> <li> <p>Click on the Menu node and Enable Text-to-Speech. Select native Cisco Cloud Text-to-Speech connector, add Text-to-Speech message, remove the Audio File option. Finally enter the text: Press 1 to create a new order. Press 2 to track an order or check the store hours. </p> </li> <li> <p>Adjust the Menu node to have options 1 and 2.       </p> </li> <li> <p>Bring one more VirtualAgentV2 node. Click on it. In the Contact Center AI Config search for scripted and select Webex AI Agent (Scripted). Under the Virtual Agent option, search for the Scripted AI Agent with name Your_Attendee_ID_Scripted_AI_Agent.      </p> </li> <li> <p>Connect Option 1 of the Menu to the VirtualAgentV2 node that is configured with Autonomous AI agent. And connect Option 2 to the VirtualAgentV2 node that is configured with your Scripted AI Agent.       </p> </li> <li> <p>Connect Escalated output from the VirtualAgentV2 node to the Queue node. Connect Handled output to the Disconnect Contact node.       </p> </li> <li> <p>Validate and Publish the Flow.       </p> </li> <li> <p>From Control Hub, make sure that the Channel Your_Attendee_ID_2000_Channel is configured with Autonomous_Scripted_Flow_2000_Your_Attendee_ID.      </p> </li> <li> <p>Dial the number that is associated with Your_Attendee_ID_2000_Channel Channel.       </p> </li> <li> <p>During IVR, press 2 and ask What is the store hours?</p> </li> </ol> <p>Congratulations, you have officially completed this mission! \ud83c\udf89\ud83c\udf89 </p>"},{"location":"main/AI_Lab_Scripted_Mission4/","title":"AI Lab Scripted Mission4","text":""},{"location":"main/AI_Lab_Scripted_Mission4/#mission-details","title":"Mission Details","text":"<p>Your mission is to configure intents, entities, and responses to check the status of an existing order that you created in the Autonomous AI Agent lab. In the next Mission 4, you will configure Fulfillment for this order tracking flow.</p>"},{"location":"main/AI_Lab_Scripted_Mission4/#build","title":"Build","text":""},{"location":"main/AI_Lab_Scripted_Mission4/#task-1-test-the-order-tracking-flow","title":"Task 1. Test the Order tracking flow.","text":"<ol> <li>Click on the Preview button on the top right side to test the bot. Try the bot flow by typing \"I want to track my order\". You will see that the Scripted AI agent is not yet configured to assist with this task.      </li> </ol>"},{"location":"main/AI_Lab_Scripted_Mission4/#task-2-configure-intents-entities-and-responses","title":"Task 2. Configure intents, entities, and responses.","text":"<ol> <li> <p>While on the Script configuration page, switch to Entities tab and click on the Create entity option. Provide the name as order_number. Entity type select as Digits. Provide Length as 2.      </p> </li> <li> <p>While on the Script configuration page, switch to Intents tab and click on the Create Intent button located in the top right corner.</p> </li> <li> <p>Add a new intent by providing the intent name as track_order and include the following two utterances:</p> <ul> <li>I want to track my order</li> <li>What is my order status? </li> </ul> </li> <li> <p>Click on the Generate button to utilize Generative AI for creating additional training phrases.</p> </li> <li> <p>Enter a description such as Generate intents to track an order status Set the Number of Variants to 10, which will determine the number of new phrases to be generated.      </p> </li> <li> <p>Click on + Link and add order_number as an entity.Make it as Required. Click on the Response search and select order_number response. .      </p> </li> <li> <p>You can review it later, but for your information, the order_number response was preconfigured for you for this lab. In this response, the AI agent simply asks for the order number. Refer to the picture below. This is an interim response needed to fill the entity.      </p> </li> <li> <p>Scroll down and click on Create new response.       </p> </li> <li> <p>Name the response as track_order. Update variant 1 test to Please wait while I check the order status..      </p> </li> <li> <p>Add Voice Channel.      </p> </li> <li> <p>Configure Voice Channel with the same variants and click on Create.  Please wait while I check the order status..      </p> </li> <li> <p>Now after we added the response to our intent we can complete the intent configuration. Click on Add on the right bottom corner. Save and Publish the Scripted AI Agent.       </p> </li> <li> <p>Click on the Preview button on the top right side to test the bot. Try the bot flow by typing \"I would like to track my order\" and provide an order number that you created earlier.       </p> </li> </ol> <p>Congratulations, you have officially completed this mission! \ud83c\udf89\ud83c\udf89 </p>"},{"location":"main/AI_Lab_Scripted_Mission5/","title":"AI Lab Scripted Mission5","text":""},{"location":"main/AI_Lab_Scripted_Mission5/#mission-details","title":"Mission Details","text":"<p>In the previous Mission 3, you created intents, entities, and responses to enable the Scripted Agent to understand and respond to order-tracking requests. However, no logic or API calls were configured yet to retrieve the order information. In this mission, you will configure the fulfillment flow to use an API call to retrieve the order status and send it back to the caller.</p>"},{"location":"main/AI_Lab_Scripted_Mission5/#build","title":"Build","text":""},{"location":"main/AI_Lab_Scripted_Mission5/#task-1-configure-a-custom-event-to-send-data-from-ai-studio-to-wxcc-voice-flow","title":"Task 1. Configure a Custom Event to send data from AI Studio to WxCC Voice Flow.","text":"<ol> <li> <p>The fulfillment for Scripted AI Agent currently is done in the WxCC Voice Flow in order to comply with all policies and regulations.</p> </li> <li> <p>Open up AI Studio portal go to Scripts &gt; responses and open up response track_order. Go to Voice Channel.       </p> </li> <li> <p>Add Custom Event and configure it with the following:  Event Name: order_details Event payload: {\"ordernumber\":\"${entity.order_number}\"}. Save the updated response.       </p> </li> <li> <p>Save and Publish your changes.       </p> </li> <li> <p>Understanding why we need to use a Custom Event for fulfillment: The API call to retrieve the order status can be made from the Voice Flow. By using a Custom Event, we send the order_number entity that the Scripted Agent collects during the call to retrieve the status.      </p> </li> </ol>"},{"location":"main/AI_Lab_Scripted_Mission5/#task-2-make-api-call-from-voice-flow-to-retrieve-the-order-status","title":"Task 2. Make API call from Voice Flow to retrieve the order status.","text":"<ol> <li> <p>From Control Hub, go to Contact Center click on flows. Open up your flow. If you follow all lab steps the name should be Autonomous_Scripted_Flow_2000_Your_Attendee_ID. Or if you have different name, find your flow. Click on it to open the Flow.       </p> </li> <li> <p>Select Edit for the flow, click anywhere on the gray area in the flow, and look for the Flow Variables on the right side.      </p> </li> <li> <p>Create 3 empty String Variables with names: order_id MetaData_Scripted_Agent order_status </p> </li> <li> <p>The fulfillment will go over the Handled output. So in your Voice flow, remove the Disconnect Contact block and add SetVariable block. Connect Handled output to the SetVariable block.       </p> </li> <li> <p>In the next step, you will assign the flow variable MetaData_Scripted_Agent, which we created earlier, with the value of the MetaData from the VirtualAgentV2 block. This will allow us to decrypt and review the MetaData from the VirtualAgentV2 block, which could be useful for troubleshooting any issues with the fulfillment flow.</p> </li> <li> <p>Click on the VirtualAgentV2 block, scroll down to Activity Output Variables, and copy the MetaData variable name. Then, open the SetVariable block and configure the MetaData_Scripted_Agent variable with the variable value you copied from the VirtualAgentV2 block. Make sure to enclose it in curly brackets.      </p> </li> <li> <p>Add Parse node and connect it to SetVariable node.       </p> </li> <li> <p>Configure the Parse node with the following: Input Variable: MetaData_Scripted_Agent Content Type: JSON Output Variable: order_id  Path Expression: $.ordernumber </p> </li> <li> <p>Understanding the Parse node configuration: The goal of the Parse node is to extract the order_number entity received from AI Studio and assign it to the flow variable named order_id. This variable will be used later in the API call.      </p> </li> <li> <p>Add HTTPRequest node and connect it to parse node.      </p> </li> <li> <p>Configure the HTTP block with the following: Use Authenticated Endpoint: off Request URL: https://67e9aa0bbdcaa2b7f5b9ed62.mockapi.io/customerOrder Method: GET Queue Parameters:  Key: id Value: {{ order_id }} Content Type: Application/JSON Parse Settings: Content Type: JSON Output Variable: order_status Path Expression: $[0].status </p> </li> <li> <p>Add Disconnect Contact and connect HTTPRequest node to the Disconnect Contact node. Validate and Publish the flow.      </p> </li> <li> <p>Please test the call by dialing the number configured with the Channel and Flow. Select option 2 in the IVR and say, \"I want to track my order.\" Provide the order number that you created earlier. The call will then be disconnected. Open the Debug mode for your flow, find the latest call, and review the logs. You should see the status of your order.     </p> </li> <li> <p>In the next Mission 5 you will configure the flow to return the order status details back to the caller. </p> </li> </ol> <p>Congratulations, you have officially completed this mission! \ud83c\udf89\ud83c\udf89 </p>"},{"location":"main/AI_Lab_Scripted_Mission6/","title":"AI Lab Scripted Mission6","text":""},{"location":"main/AI_Lab_Scripted_Mission6/#mission-details","title":"Mission Details","text":"<p>In the previous Mission 4, you configured a fulfillment flow that executes an API call in the WxCC Voice flow based on the order number and parses the order status. In this mission, you will configure the flow to return this status to AI Studio so that the Scripted AI agent can deliver the result back to the caller.</p>"},{"location":"main/AI_Lab_Scripted_Mission6/#build","title":"Build","text":""},{"location":"main/AI_Lab_Scripted_Mission6/#task-1-add-virtualagentv2-block-to-bring-data-back-to-ai-studio","title":"Task 1. Add VirtualAgentV2 block to bring data back to AI Studio.","text":"<p>Note: To deliver the call back to AI Studio, you need to add an additional VirtualAgentV2 block to the flow.</p> <ol> <li> <p>Open Autonomous_Scripted_Flow_2000_Your_Attendee_ID and click Create Flow flow. Click on Edit the flow.      </p> </li> <li> <p>Delete the Disconnect Contact node and add VirtualAgentV2 node. Connect HttpRequest block to VirtualAgentV2 block.      </p> </li> <li> <p>Click on VirtualAgentV2. In the Contact Center AI Config search for scripted and select Webex AI Agent (Scripted). Under the Virtual Agent option, search for the Scripted AI Agent with name Your_Attendee_ID_Scripted_AI_Agent.     </p> </li> <li> <p>Connect Escalated output from the VirtualAgentV2 node to the Queue node.     </p> </li> <li> <p>Add Disconnect Contact node and connect Handled output to the Disconnect Contact node.     </p> </li> <li> <p>You can publish the flow at this point.      </p> </li> </ol>"},{"location":"main/AI_Lab_Scripted_Mission6/#task-2-configure-state-event-in-the-virtualagentv2-block","title":"Task 2. Configure State Event in the VirtualAgentV2 block","text":"<p>Note: We need to configure the VirtualAgentV2 block to send the order status to AI Studio, which will be retrieved in the specific response. For this, we will utilize the State Event.</p> <ol> <li> <p>Select the VirtualAgentV2 block that you have added in the previous Task and click on State Event.      </p> </li> <li> <p>Configure the State Event with the following:  Event Name: order_status  Event Data: {\"status\":\"{{ order_status }}\"} </p> </li> <li> <p>Understand the State Event configuration. See the picture below.      </p> </li> <li> <p>You can publish the flow at this point.      </p> </li> </ol>"},{"location":"main/AI_Lab_Scripted_Mission6/#task-3-review-the-order_status-response-configuration","title":"Task 3. Review the order_status Response configuration.","text":"<ol> <li> <p>Go to AI Studio and open your Scripted Agent. If you followed all the steps the name of the Scripted Agent should be Your_Attendee_ID_Scripted_AI_Agent </p> </li> <li> <p>Go to Script &gt; Responses and search for the Response with the name order_status. This response is preconfigured in this lab for you. Go to Voice channel and review the configurations.      </p> </li> <li> <p>Understand the order_status configuration. Please see the picture below.      </p> </li> </ol>"},{"location":"main/AI_Lab_Scripted_Mission6/#task-4-test-scripted-ai-agent-order-status-flow","title":"Task 4. Test Scripted AI agent order status flow.","text":"<ol> <li> <p>Dial the number that is assosiated with Your_Attendee_ID_2000_Channel Channel.       </p> </li> <li> <p>During IVR, press 2 to and say \"I want to track my order\". Provide the order details that you created earlier, or use the order with number 22 for the example.</p> </li> </ol> <p>Congratulations, you have officially completed this mission! \ud83c\udf89\ud83c\udf89 </p>"},{"location":"main/AI_Lab_Scripted_Overview/","title":"AI Lab Scripted Overview","text":""},{"location":"main/AI_Lab_Scripted_Overview/#story","title":"Story","text":"<p>This mission provides hands-on experience in building and configuring Scripted AI Agents.</p>"},{"location":"main/AI_Lab_Scripted_Overview/#key-tasks-covered","title":"Key Tasks Covered","text":"<ul> <li>Create a Scripted AI Agent using a sample template</li> <li>Integrate the AI Agent into a flow for voice calls</li> <li>Update AI Agent responses</li> <li>Add new intents and entities</li> <li>Enhance training data using Generative AI</li> <li>Use fulfillment to track order status</li> </ul>"},{"location":"main/AI_Lab_Scripted_Overview/#call-flow-overview","title":"Call Flow Overview","text":"<ol> <li>A new call enters the flow. </li> <li>The AI Agent interacts with the caller by asking configured questions. </li> <li>The AI Agent ends the conversation after collecting all the necessary details. </li> <li>The AI Agent can handoff the call to the live agent. </li> </ol>"},{"location":"main/AI_Lab_Scripted_Overview_New/","title":"AI Lab Scripted Overview New","text":""},{"location":"main/AI_Lab_Scripted_Overview_New/#story","title":"Story","text":"<p>The mission is designed to provide a hands-on understanding of creating Scripted AI Agents. It covers key tasks such as creating a virtual agent using a template, integrating the AI Agent with a flow for voice calls, updating AI Agent responses, adding new intents and entities, enhancing training data using generative AI, and using fulfillment to track order status</p>"},{"location":"main/AI_Lab_Scripted_Overview_New/#call-flow-overview","title":"Call Flow Overview","text":"<ol> <li>A new call enters the flow. </li> <li>The AI Agent interacts with the caller by asking configured questions. </li> <li>The AI Agent can response about the store business hours based on the configured intents and responses. </li> <li>The AI Agent can track an order based on the provided order number. </li> </ol>"},{"location":"main/AI_Lab_Suggested_Responseds_Conclusion/","title":"Conclusion","text":"<p>Suggested Responses Lab Overview</p> <p>In this lab, you explored the capabilities of the Webex Contact Center\u2019s Suggested Responses feature, designed to enhance agent productivity and improve customer interactions through real-time AI assistance.</p> <p>Key Capabilities Implemented:</p> <p>Enabled the Suggested Responses feature to provide agents with contextual, AI-powered recommendations during live customer interactions. Configured the system to monitor real-time transcripts of voice and digital conversations, delivering relevant response suggestions based on uploaded documentation. Integrated API calls to third-party applications, allowing agents to quickly retrieve dynamic information such as order status without manual searching.</p> <p>Configured Actions to:</p> <p>Seamlessly transfer calls from AI agents to human agents with continuous AI support. Provide agents with timely, accurate suggestions to reduce handle time and improve first contact resolution. Support both voice and digital channels, ensuring consistent assistance across communication modes.</p> <p>Enhanced Agent Experience by:</p> <p>Reducing the time and effort agents spend searching for information. Ensuring consistent and accurate customer responses. Minimizing after-call work by enabling agents to act on suggestions during interactions.</p> <p>This lab demonstrated how the Suggested Responses feature streamlines contact center workflows by leveraging AI to assist agents in real time, improving efficiency and customer satisfaction through intelligent, context-aware guidance within the Webex Contact Center platform.</p>"},{"location":"main/AI_Lab_Suggested_Responseds_Mission1/","title":"Mission 1","text":""},{"location":"main/AI_Lab_Suggested_Responseds_Mission1/#mission-1-configure-suggested-responses-with-knowledgebase","title":"Mission 1: Configure Suggested Responses with Knowledgebase.","text":""},{"location":"main/AI_Lab_Suggested_Responseds_Mission1/#mission-overview","title":"Mission overview","text":"<p>Your mission is to:</p> <p>Create a Knowledge Base for the AI Assistant skill to use. This knowledge base will contain document will provide the necessary information for the AI Assistant to knowledgeably provide suggestions to the agent.</p>"},{"location":"main/AI_Lab_Suggested_Responseds_Mission1/#build","title":"Build","text":""},{"location":"main/AI_Lab_Suggested_Responseds_Mission1/#task-1-create-knowledgebase","title":"Task 1. Create Knowledgebase.","text":"<ol> <li> <p>[IMPORTANT] Download .xlsx the file Flowrs_Catalog.     </p> <p>Flower_Catalog.xlsx - file contains information on the available single flowers and bouquets, including the price of the flowers or bouquets and occasions that suit the flowers. </p> </li> <li> <p>Open up and review the file.      </p> </li> <li> <p>From Control Hub, go to Contact Center and open Webex AI Agent Studio portal.     </p> </li> <li> <p>Select Knowledge and click on Create Knowledge base.     </p> </li> <li> <p>Provide the name as _Suggested_Responses_Knowledge and click on Create.     </p> </li> <li> <p>Add Flower_Catalog file. The same file that you used for the Autonomous AI Agent lab.     </p> </li> <li> <p>Process the file.      </p> </li> </ol>"},{"location":"main/AI_Lab_Suggested_Responseds_Mission1/#task-2-creat-ai-assistant-skills","title":"Task 2. Creat AI Assistant skills.","text":"<ol> <li> <p>Select AI Dashboard and click on Create skills.     </p> </li> <li> <p>Select Start from scretch and click Next.     </p> </li> <li> <p>Name the skill as _Suggested_Responses_Skill. Discribe the goals as Answer question about flower suggestion, flower availability, prices, delivery cost and order status.. And then click on Create.     </p> </li> <li> <p>Link the knowledge base to the skill in the Knowledge section. Save and Publish the changies.      </p> </li> </ol>"},{"location":"main/AI_Lab_Suggested_Responseds_Mission1/#task-3-assigned-ai-skills-to-your-queue","title":"Task 3. Assigned AI skills to your queue.","text":"<ol> <li>In the Webex Control Hub, go to Contact Center, scroll down until you see the AI Assistant module. Open it and scroll down to the Suggested Responses feature. Click on Assign AI Assistant skills. In the following window, select the skill that you created in the previous tab, _Suggested_Responses_Skill, and add your queue _2000_Voice_Queue. Then click Save.     </li> </ol>"},{"location":"main/AI_Lab_Suggested_Responseds_Mission1/#task-4-add-start-media-stream-block-to-the-voice-flow","title":"Task 4. Add \"Start Media Stream\" block to the voice flow.","text":"<ol> <li> <p>In the Webex Control hub find and open your flow, _SR_Voice_Flow.     </p> </li> <li> <p>Click on Edit.      </p> </li> <li> <p>Select Event Flows. Drag and drop Start Media Stream block and connect AgentAnswered block to the Start Media Stream block. Drag and drop End Flow node and connect Start Media Stream block to the End Flow block.      </p> </li> <li> <p>Validate and Publish the flow with Latest task.      </p> </li> </ol>"},{"location":"main/AI_Lab_Suggested_Responseds_Mission1/#task-5-test-suggested-responses-feature","title":"Task 5. Test Suggested Responses Feature.","text":"<ol> <li> <p>Log in to the Agent Desktop.     </p> </li> <li> <p>Place the call to the number that is related to your Channel.</p> </li> <li> <p>Once the call is connected to your Agent Desktop, click on the AI Assistance module. You will see the option Get Suggestion. Click on it and try to order some flowers. You should see that the AI Agent will suggest flower availability and prices to the human agent based on the Knowledge Base.     </p> </li> </ol>"},{"location":"main/AI_Lab_Suggested_Responseds_Mission2/","title":"Mission 2","text":""},{"location":"main/AI_Lab_Suggested_Responseds_Mission2/#mission-2-configure-fulfillment","title":"Mission 2: Configure Fulfillment.","text":""},{"location":"main/AI_Lab_Suggested_Responseds_Mission2/#mission-overview","title":"Mission overview","text":"<p>Your mission is to:</p> <p>Configure the fulfillment flow to track the status of existing orders. This functionality will allow the system to track the status of an order after the customer provides the order number, so the agent does not have to do any manual work and can simply deliver the order status to the customer. </p>"},{"location":"main/AI_Lab_Suggested_Responseds_Mission2/#build","title":"Build","text":""},{"location":"main/AI_Lab_Suggested_Responseds_Mission2/#task-1-create-flow-in-webex-connect","title":"Task 1. Create flow in Webex Connect.","text":"<ol> <li> <p>From the Control Hub login to Webex Connect.     </p> </li> <li> <p>Create new service with name _Service </p> </li> <li> <p>Creat new flow. Name it Track_Order_Flowers.     </p> </li> <li> <p>Select Integration as AI Agent. Parse the values in the AI Agent block Save and Make Live the flow. We will configure it in a later Task. For now, we just need to create the flow that will be used to complete the Action Configuration on the AI Studio side.     </p> </li> </ol>"},{"location":"main/AI_Lab_Suggested_Responseds_Mission2/#task-2-configure-action-in-ai-studio-portal","title":"Task 2. Configure Action in AI Studio portal.","text":"<ol> <li> <p>Go to the AI Studio portal.      </p> </li> <li> <p>Select AI Dashboard and find the Skill that you created earlier - _Suggested_Responses_Skill.     </p> </li> <li> <p>Select Actions and create new Action.      </p> </li> <li> <p>Name the Action as track_order.    In the Action description provide the following: If the customer want to track and order, collect the order number. With the order number execute the fulfillment and return the customer the order status. .     Select the Action scope as Slot filling and fulfillment. </p> </li> <li> <p>Add New input entity. Configure it with the following:  Name: orderNumber.  Entity type: String.  Entiry description: If the customer wants to track an order, collect the order number to this entity. .  Entity example: 17.  Required: Yes </p> </li> <li> <p>For the fulfillment flow select the Service _Service and the flow Track_Order_Flowers, that you have created in the previous Tasks. Then click Add.     </p> </li> <li> <p>Publish the recent changes of the Skill.      </p> </li> </ol>"},{"location":"main/AI_Lab_Suggested_Responseds_Mission2/#task-3-configure-fulfillment-flow-in-webex-connect","title":"Task 3. Configure Fulfillment flow in Webex Connect.","text":"<ol> <li> <p>Open up Webex Connect. Findthe the service _Service and open up flow: Track_Order_Flowers. Click on Edit the flow.      </p> </li> <li> <p>Add HTTP Request node to the flow and connect Configure AI Agent Event node to this HTTP Reqeust node.      </p> </li> <li> <p>Open up Configure AI Agent Event node and replace the Sample JSON body with the following. Then click on Parse and Save the changies of the node.      </p> <pre><code>{\n  \"orderNumber\": \"numbr\"\n}\n</code></pre> </li> <li> <p>Open up HTTP Request node and configure it with the following:</p> <p>Method: GET  Endpoint URL: https://67e9aa0bbdcaa2b7f5b9ed62.mockapi.io/customerOrder?id=$(n2.aiAgent.orderNumber) Header: Content-Type: application/json </p> <p>Output Variable Type: JSON Click on +Add Variable Output Variable Name: orderStatus Response Entity: Body Response Path $[0].status</p> <p></p> </li> <li> <p>Save changies and click on Make Live.     </p> </li> </ol>"},{"location":"main/AI_Lab_Suggested_Responseds_Mission2/#task-4-deliver-data-from-webex-connect-to-ai-studio-for-the-response-to-the-customer","title":"Task 4. Deliver data from Webex Connect to AI studio for the response to the customer.","text":"<ol> <li> <p>While on your Webex Connect flow, click on Edit the flow then click on the Settings and on the top select Flow Outcomes and expand Last Execution Status. In the Define key-value pairs to be sent to the AI Agent select Enter JSON.     </p> </li> <li> <p>You need to add the key-value pair to the existing JSON body. Add the comma after the last pair and insert \"orderStatus\": \"$(n3.orderStatus)\". Make sure there is no comma after the pair that you inserted. Then click on Save. Then click on Make Live option to publish the flow.      </p> </li> </ol>"},{"location":"main/AI_Lab_Suggested_Responseds_Mission2/#task-5-test-the-suggested-responses-feature-with-fulfillment","title":"Task 5. Test the Suggested Responses feature with fulfillment.","text":"<ol> <li> <p>Login to Agent Deskop.</p> </li> <li> <p>Please the call to the number that is related to you Channel - _2000_Channel</p> </li> <li> <p>Ask the AI Agent to transfer the call to the human agent. </p> </li> <li> <p>Once the call is connected to the Agent Desktop, select the AI widget and then click on Get suggestions.      </p> </li> <li> <p>As the caller say that you would like to track an order. You will see the suggestion will come up to ask for the order number.      </p> </li> <li> <p>As the caller, provide your order number, and you should see the AI execute the fulfillment to place an API call to the third-party application to retrieve the response. For this lab, all order statuses are \"new,\" so you should see that the AI responds that the order status is \"new.\"     </p> </li> <li> <p>(Optional) To see all order infomations you can by placing this URL in your browser.  https://67e9aa0bbdcaa2b7f5b9ed62.mockapi.io/customerOrder   </p> </li> </ol>"},{"location":"main/AI_Lab_Suggested_Responses_Overview/","title":"Lab overview","text":""},{"location":"main/AI_Lab_Suggested_Responses_Overview/#suggested-responses-feature-overview","title":"Suggested Responses Feature Overview","text":"<p>Suggested Responses is a real-time AI Assistant feature designed to support your contact center agents with contextual guidance, enabling them to deliver faster, more consistent, and positive customer experiences.</p>"},{"location":"main/AI_Lab_Suggested_Responses_Overview/#story","title":"Story","text":"<p>When a call is connected to a human agent, the Suggested Responses feature monitors the live transcripts and presents suggestions related to flower availability, pricing, and more, based on the uploaded documents containing all these details. This feature saves the agent time and effort by automatically searching through the documentation to provide the latest information to the agent and agent can review and provide it to the customer. </p> <p>Additionally, if a customer wants to track their order status, the Suggested Responses feature can place API calls to third-party applications to retrieve the order status and present it to the agent. This allows the agent to quickly access order information based on the provided order number without manually searching for it.</p>"},{"location":"main/AI_Lab_Suggested_Responses_Overview/#call-flow-overview","title":"Call Flow Overview","text":"<ol> <li>A new call enters the voice flow and connectes to an agent. </li> <li>While connected to the agent, the Suggested Responses feature recommends responses to the agent based on the uploaded documentation.</li> <li>If the customer asks to track an order, the Suggested Responses feature places an API call to a third-party application to retrieve the order status.</li> </ol>"},{"location":"main/AI_Lab_Topic_Conclusion/","title":"AI Lab Topic Conclusion","text":"<p>This capability enables you to identify key topics your customers are calling about, uncovering opportunities to introduce automation and virtual agent capabilities. For instance, topics like Flower Delivery could be automated to streamline order creation and delivery setup, reducing manual effort and call volume. </p> <p>By modifying the Topic Collection, the system separates the calls where customers called and were asking for a suggestion based on the occasion, and the system places it in the new Topic named Flower Reason.</p> <p>By leveraging Cisco Webex Topic Analytics, you can enhance self-service options, empower customers to resolve their queries independently, and improve overall satisfaction. This not only boosts efficiency but also strengthens customer relationships by delivering faster, more innovative solutions.</p>"},{"location":"main/AI_Lab_Topic_Mission1/","title":"AI Lab Topic Mission1","text":""},{"location":"main/AI_Lab_Topic_Mission1/#task-1-overview-only-review-flower-delivery-topic-collection","title":"Task 1. [OVERVIEW ONLY] Review Flower Delivery Topic Collection.","text":"<ol> <li> <p>Go to Contact centre overview. Under Quick Links , click on Topic Analytics.  Enter your administrator login user, if prompted.     </p> </li> <li> <p>On left side click on \u201cTopic Analytics\u201d and click on collection with name Flower Delivery.    </p> </li> <li> <p>Make a note of Total Analyzed interaction and how many of those has recording available.    </p> </li> <li> <p>Click on Topic. There are various Topics for which customers are contacting the Contact Center. Knowing this information gives the opportunities for automation and enhanced self-service through virtual agents. For example, one such topic could be Flower Delivery. As a CX Architect/Business leader, you might consider implementing an AI agent capable of creating an order and scheduling deliveries.    </p> </li> <li> <p>There is option for you to download the Topics with details.     </p> </li> <li> <p>Next, click on the Flower Delivery topic. This will take you to the Contact Record tab, which shows all the contacts associated with this topic, along with the date/time of those calls and the contact reason. If you open any of them, you can view details of the contact, the contact reason, transcripts, and even listen to the call recording.    </p> </li> </ol>"},{"location":"main/AI_Lab_Topic_Mission1/#task-2-overview-only-review-steps-to-edit-topic-collection","title":"Task 2. [OVERVIEW ONLY] Review steps to edit Topic Collection.","text":"<ol> <li> <p>Topic Analytics enables you to modify your topic collections, allowing you to tailor the topics to better fit specific business needs, language, and terminology. You can rename topics, merge topics, delete topics, add new topics.   Click on Edit Topics on the top-right corner.    </p> </li> <li> <p>In the Name Copy screen, edit the topic collection name. By default, Copy of existing collection name appears in the Topic collection name field. For this lab you can call it with any name you prefare.     </p> </li> <li> <p>Optionally, topics can be merged or deleted. Please do not do it while working on this lab.     </p> </li> <li> <p>Click on Add New    </p> </li> <li> <p>Configure the tops with the contact reason examples.     Add Topic Labol: Flower Reason</p> <p>Contact Reasons: </p> <p>I need flowers for the party Need to order flower for Birthday Anniversary</p> <p></p> </li> <li> <p>Click on Next.    </p> </li> <li> <p>[Read Only]  Review the Edits but for this lab overview DO NOT click on  Create new topic collection, as it would take some time for it to be created.     </p> </li> <li> <p>[Read Only]  On the next Windows you would see that new collection is creating.    </p> </li> <li> <p>[Read Only]  From Topic Analytytics you would see that a new Topic collection will be creating, and if you have enough calls with the provided reason, the data will show up in the Topic.    </p> </li> <li> <p>For this lab open up topic with name Flower Delivery 2 to see the expected results.    </p> </li> </ol> <p>Congratulations, you have officially completed this mission! \ud83c\udf89\ud83c\udf89 </p>"},{"location":"main/AI_Lab_Topic_Mission1/#task-3-review-topic-analytics-reports-in-ai-assistant-dashboard","title":"Task 3. Review Topic Analytics reports in AI Assistant Dashboard.","text":"<ol> <li> <p>From Control Hub login to Analyzer.     </p> </li> <li> <p>Click on Dashboard and search for the Dashboard with name AI Assistant Dashboard. Open the Deshboard with ID -1284.    </p> </li> <li> <p>Scroll down and select the duration as This Year </p> </li> <li> <p>To check the graph for flower-related topics, uncheck all other topics, leaving only Inquiry on Flower and Costs and Inquiry on Flower Order and Prices.    </p> </li> <li> <p>On the right side, you can see the Topic Analytics Summary card with additional information like Interactions, Avg Handle Time, and Average Auto CSAT. You can expand details about the interactions related to the topic by clicking on it.    </p> </li> </ol>"},{"location":"main/AI_Lab_Topic_Mission1/#task-4-review-custom-analyzer-report-for-topic-analytics","title":"Task 4. Review custom Analyzer report for Topic Analytics.","text":"<ol> <li> <p>While in the Analyzer portal, click on Visualizations and search for the report LAB-2342-Topic. Open the report. You should see that there are two new profile variables in Analyzer that could be used to review the Topic details: Topic Name and Contact Driver.    </p> </li> <li> <p>You can filter the report to see specific topics. Select Inquiry on Flower and Costs and Inquiry on Flower Order and Prices </p> </li> <li> <p>Review the report after applying the filter.    </p> </li> </ol> <p>Congratulations, you have officially completed this mission! \ud83c\udf89\ud83c\udf89 </p>"},{"location":"main/AI_Lab_Topic_Overview/","title":"AI Lab Topic Overview","text":""},{"location":"main/AI_Lab_Topic_Overview/#story","title":"Story","text":"<p>Topic Analytics provides easy to use interface for the Contact center administrators to identify the reasons the customers are calling into the contact center. This is achieved by transcribing existing customer recordings and using cutting-edge AI technologies to extract the contact reasons from these transcripts. Contact Reason \u2013 AI generated summary indicating the reason of the call.  Topic \u2013 A representative label for groupings of similar contact reasons. </p>"},{"location":"main/AI_Lab_Topic_Overview/#capabilities","title":"Capabilities","text":"<ul> <li>Ability to filter interactions by Topics</li> <li>View interaction details including:<ul> <li>Transcripts</li> <li>Call recordings</li> <li>Contact details</li> </ul> </li> <li>Improved coverage and accuracy with enhanced AI models</li> <li>Customize Topics to align with your business needs</li> </ul>"},{"location":"main/APITrack_Conclusion/","title":"Conclusion","text":""},{"location":"main/APITrack_Conclusion/#conclusion","title":"Conclusion","text":"<p>We hope you found the API Track both insightful and rewarding as you expanded your expertise in leveraging APIs for dynamic and intelligent call routing in Webex Contact Center. This session provided hands-on experience with key techniques to enhance flexibility, efficiency, and personalization in customer interactions.</p> <p>Key missions included:</p> <ul> <li>Emergency Configuration Change \u2013 Using API requests to instantly modify system settings for real-time adaptability.</li> <li>Routing Facilitation with Variables \u2013 Enhancing precision in call routing by dynamically adjusting logic based on real-time data.</li> <li>Last Agent Routing \u2013 Ensuring returning customers are connected with the same agent for a seamless experience.</li> <li>Reconnecting with the Same Agent \u2013 Allowing customers to reach the same agent if a call ends and they call back within 10 minutes, maintaining conversation continuity.</li> </ul> <p>By mastering these API-driven techniques, you are now equipped to design smarter, more responsive workflows that enhance both operational efficiency and customer satisfaction.</p> <p>If you have any questions or need further guidance, feel free to reach out or join the Webex discussion forums. We look forward to seeing how you apply these advanced skills in your future projects!</p> <p>Thank you for completing the API Track, and we look forward to your continued innovation with Webex Contact Center.</p>"},{"location":"main/APITrack_DeveloperPortal/","title":"Using Webex Contact Center Developer Portal","text":""},{"location":"main/APITrack_DeveloperPortal/#using-webex-contact-center-developer-portal","title":"Using Webex Contact Center Developer Portal","text":""},{"location":"main/APITrack_DeveloperPortal/#story","title":"Story","text":"<p>Webex Contact Center APIs enable automation, customization, and integration with external applications. By leveraging these APIs, administrators can streamline processes, enhance agent efficiency, and improve customer interactions. In this introduction mission, we will explore how to interact with the Developer Portal and execute different types of API calls.</p>"},{"location":"main/APITrack_DeveloperPortal/#mission-details","title":"Mission Details","text":"<p>In this mission, attendees will learn how to interact with Webex Contact Center APIs by performing API calls via the  Developer Portal. Specifically, we will work with the Address Book feature.</p> <p></p>Good to Know [Optional]<p></p> <p>Understanding API Calls with Real-Life Comparisons</p> <p>APIs (Application Programming Interfaces) allow different systems to communicate by sending and receiving structured requests. Here are the most common API call types, explained with real-world analogies:</p> <ol> <li> <p>GET \u2013 Retrieving Information Analogy: Checking your bank balance at an ATM. You request information, and the system provides it without making any changes. Example Use Case: Retrieving a customer\u2019s interaction history in Webex Contact Center before routing their call.</p> </li> <li> <p>POST \u2013 Creating New Data Analogy: Ordering a new item online. You submit details, and a new order (or record) is created in the system. Example Use Case: Creating a new customer support ticket when an issue is reported during a call.</p> </li> <li> <p>PUT \u2013 Updating Existing Data Analogy: Changing your home address in an online banking system. Instead of adding a new address, the existing one is replaced. Example Use Case: Updating a customer\u2019s preferred contact method in a CRM system.</p> </li> <li> <p>PATCH \u2013 Modifying Partial Data Analogy: Updating your phone number on a social media profile without changing other details like your name or email. Example Use Case: Changing only the priority level of an existing support ticket.</p> </li> <li> <p>DELETE \u2013 Removing Data Analogy: Canceling a hotel reservation. The record is removed, preventing further use. Example Use Case: Deleting a scheduled callback request if the customer no longer needs assistance.</p> </li> <li> <p>Webhooks \u2013 Automated Notifications Analogy: Receiving an SMS alert when your package is out for delivery. Instead of requesting updates repeatedly, you get notified when something happens. Example Use Case: Notifying an agent when a VIP customer joins the queue.</p> </li> <li> <p>SEARCH API (GraphQL Queries) \u2013 Retrieving Specific Data Efficiently Analogy: Using a restaurant menu app to filter only \"vegan dishes under $10\" instead of browsing the entire menu. Unlike traditional GET requests that return all data, GraphQL allows users to request exactly what they need. Example Use Case: Searching for all unresolved support tickets assigned to a specific agent without loading unnecessary ticket details.</p> </li> </ol> <p>APIs streamline operations by automating tasks, integrating systems, and enhancing customer experiences. Understanding these core calls helps optimize workflows in platforms like Webex Contact Center. </p><p></p>"},{"location":"main/APITrack_DeveloperPortal/#build","title":"Build","text":""},{"location":"main/APITrack_DeveloperPortal/#create-a-new-address-book-entity-by-using-post","title":"Create a New Address Book entity by using POST","text":"<ol> <li> <p>Open Developer Portal and click on Sign In.     Your login will be of the format wxcclabs+admin_IDYour_Attendee_ID@gmail.com. You will see another login screen with OKTA on it where you may need to enter the email address again and the password provided to you.</p> </li> <li> <p>Click on Documentation which is on top right corner of the portal page.</p> <p></p> </li> <li> <p>On Menu pannel on the left, scroll down to API Reference section and click on Adress Book. Observe available API calls</p> <p>Note</p> <p>Address Book Overview Address Book is available in the Webex Contact Center Agent Desktop. Agents can make outbound calls using Address Books, selecting numbers from pre-configured lists instead of entering them manually in the 'Start a New Call' field. Administrators can configure and manage Address Books via the Webex Contact Center APIs.</p> </li> <li> <p>Scroll down and click on Create a new Address Book, then click on Try Out.</p> <p></p> </li> <li> <p>Clear Request Body content. Paste the following body and replace the  with your attendee ID. Click on Run.</p> <p>Request Body: </p><pre><code>{\n    \"name\": \"AddressBook_&lt;Your_Attendee_ID&gt;\",\n    \"parentType\": \"ORGANIZATION\"\n}\n</code></pre><p></p> <p>Expected Response: 201 Response </p><pre><code>{\n  \"organizationId\": \"e56f00d4-98d8-4b62-a165-d05a41243d98\",\n  \"id\": \"4aa50a6b-a520-4221-bc9d-a050c111061f\",\n  \"version\": 0,\n  \"name\": \"AddressBook_140\",\n  \"parentType\": \"ORGANIZATION\",\n  \"createdTime\": 1738585491913,\n  \"lastUpdatedTime\": 1738585491913\n}\n</code></pre><p></p> <p></p> </li> <li> <p>Switch to Webex Control Hub and navigate to Address Book under Desktop Experience Section. Locate your new created AddressBook_Your_Attendee_ID</p> </li> <li> <p>You should see your new created AddressBook_Your_Attendee_ID. There are still no Address Book entries so let's add them.</p> </li> <li> <p>On the same Address Book configuration page, copy the AddressBook_AddressBook_ ID into notepad.</p> <p></p> </li> <li> <p>Switch to Developer Portal and select Address Book again from left menu pane.</p> <p></p> </li> <li> <p>Click on Create a new Address Book Entry, then switch to Try Out tab within the same page. </p> </li> <li> <p>In the Parameters section paste ID you copied on Step 8 of the current mission.</p> </li> <li> <p>Clear Request Body content and paste the following body, then click on Run button.</p> <p>Request Body: </p><pre><code>{\n  \"name\": \"TAC Number\",\n  \"number\": \"+14085267209\"\n}\n</code></pre><p></p> <p>Expected Response: 201 Response </p><pre><code>{\n  \"organizationId\": \"e56f00d4-98d8-4b62-a165-d05a41243d98\",\n  \"id\": \"133ec7d9-7873-40b6-be40-43e071430268\",\n  \"version\": 0,\n  \"name\": \"TAC Number\",\n  \"number\": \"+14085267209\",\n  \"createdTime\": 1738773041509,\n  \"lastUpdatedTime\": 1738773041509\n}\n</code></pre><p></p> <p></p> </li> <li> <p>Switch to Webex Control Hub. Your Addres Book configuration page should still be open. Refresh the page.</p> </li> <li> <p>But if not open, locate and open your AddressBook_Your_Attendee_ID</p> </li> <li> <p>You should see your new created Entry List with Name Tac Number and Contact Number +14085267209.</p> <p></p> </li> </ol>"},{"location":"main/APITrack_DeveloperPortal/#retrieve-address-book-entry-by-id-get","title":"Retrieve Address Book Entry by ID (GET)","text":"<p>We will retrieve information about your newly created address book using a GET API call.</p> <ol> <li> <p>Switch to Developer Portal and select Address Book again from left menu pane.</p> </li> <li> <p>Locate and open Get specific Address Book by ID, then switch to Try Out tab.</p> <p></p> </li> <li> <p>Paste the same AddressBook_AddressBook_ ID into id cell of Parameters section. You can quickly copy it by switching back to Control Hub. Then click Run.</p> <p>Expected Response: 200 Response </p><pre><code>{\n  \"id\": \"115358d7-5c46-4988-9a50-e7f40c3b7daf\",\n  \"name\": \"AddressBook_140\",\n  \"description\": \"\",\n  \"parentType\": \"ORGANIZATION\",\n  \"createdTime\": 1738771074000,\n  \"lastUpdatedTime\": 1738773007000\n}\n</code></pre> <p></p> </li> </ol>"},{"location":"main/APITrack_DeveloperPortal/#update-address-book-description-by-using-put","title":"Update Address Book Description by using PUT","text":"<ol> <li> <p>Switch to Developer Portal and select Address Book again from left menu pane.</p> </li> <li> <p>Locate and open Update specific Address Book by ID, then switch to Try Out tab.</p> <p></p> </li> <li> <p>Paste the same AddressBook_AddressBook_ ID into id cell of Parameters section. You can quickly copy name and id by switching back to Control Hub. </p> </li> <li> <p>Clear Request Body content and paste the following body. Then click Run.</p> <p>Replace value YourAddressBook_Name to your AddressBook_Your_Attendee_ID</p> <p>Replace YouAddressBook_ID to actual AddressBook_AddressBook_ ID</p> <p>Request Body: </p><pre><code>{\n  \"name\": \"YourAddressBook_Name\",\n  \"id\": \"YouAddressBook_ID\",\n  \"parentType\": \"ORGANIZATION\",\n  \"description\": \"Testing PUT requests from Develeper Portal\"\n}\n</code></pre><p></p> <p>Expected Response: 200 Response </p><pre><code>{\n  \"organizationId\": \"e56f00d4-98d8-4b62-a165-d05a41243d98\",\n  \"id\": \"115358d7-5c46-4988-9a50-e7f40c3b7daf\",\n  \"version\": 5,\n  \"name\": \"AddressBook_140\",\n  \"description\": \"Testing PUT requests from Developer Portal\",\n  \"parentType\": \"ORGANIZATION\",\n  \"createdTime\": 1738771074000,\n  \"lastUpdatedTime\": 1738775594832\n}\n</code></pre><p></p> </li> <li> <p>Switch to Webex Control Hub. You Addres Book configuration page should still be open. Refresh the page to validate Description change.</p> </li> </ol> <p></p>"},{"location":"main/APITrack_DeveloperPortal/#use-search-api-to-retrieve-data-from-analyzer-db","title":"Use Search API to retrieve data from Analyzer DB.","text":"<p>Note</p> <p>When working with Webex Contact Center (WxCC) GraphQL queries, timestamps are represented in Epoch time (Unix timestamp) format. This format counts the number of seconds (or milliseconds) that have elapsed since January 1, 1970 (UTC).  If you need to convert a regular date/time into Epoch format or vice versa, you can use this online converter: https://www.epochconverter.com/ Ensure that your queries and filters use the correct time format to retrieve accurate results.</p> <ol> <li> <p>Switch to Developer Portal then locate and select Search from API REFERENCE menu</p> </li> <li> <p>Click on Search tasks and then switch to Try Out tab   </p> </li> <li> <p>Click on Maximize Screen, clear the text from GraphQL query window. Then paste the following query. </p> <p>Request Body: </p><pre><code>{\n  #Global CAD Variables: Usage of taskDetails Object to retrieve the Value of Global Variables\n  taskDetails(\n    # NOTE: from and to are mandatory arguments that take the Epoch timestamp in milliseconds\n    from: 1738833921000 #This can be set to Date.now() - (days * 24 * 60 * 60 * 1000) for lookback in days\n    to: 1738834701000 #This can be set to Date.now() in millis\n    filter: {\n      #Filter the type of Task\n      and: [\n        { channelType: { equals: telephony } } #Telephony calls only\n        { origin: { equals: \"+14694097607\" } } #Customer ANI\n        { status: { equals: \"ended\" } } #Final Disposition\n        { direction: { equals: \"inbound\" } } #Inbound call only\n        { isActive: { equals: false } } #Resolved call only\n        { owner: { notequals: { id: null } } } #Only calls that had an Owner\n      ]\n    }\n  ) {\n    tasks {\n      id #TaskId-SessionId-CallId      \n      status #Status\n      totalDuration #CallTime\n      origin #ANI\n      destination #DNIS\n      lastAgent {\n        #Agent\n        id\n        name\n      }\n      stringGlobalVariables(name: \"Global_Language\") {\n        #GlobalCADVariable\n        name\n        value\n      }\n    }\n  }\n} \n</code></pre><p></p> <p>Note</p> <p>Current query is configured to search calls with following details from Analyzer database:</p> <ol> <li> <p>Time range: From Thursday, February 6, 2025 9:25:21 AM to Thursday, February 6, 2025 10:38:21 AM GMT+01:00.</p> </li> <li> <p>Telephony inbound calls only.</p> </li> <li> <p>Calls only from +14694097607.</p> </li> <li> <p>Ended calls only.</p> </li> <li> <p>Calls that were assigned to an owner (agent).</p> </li> </ol> <p>Expected Response: 200 Response </p><pre><code>{\n  \"data\": {\n    \"taskDetails\": {\n      \"tasks\": [\n        {\n          \"id\": \"d1364618-49a4-41f5-8b5f-a8da4d12e56c\",\n          \"status\": \"ended\",\n          \"totalDuration\": 35562,\n          \"origin\": \"+14694097607\",\n          \"destination\": \"+14694096861\",\n          \"lastAgent\": {\n            \"id\": \"b9b45479-756f-4c55-8663-8ae7800a9a18\",\n            \"name\": \"Agent140 Lab\"\n          },\n          \"stringGlobalVariables\": {\n            \"name\": \"Global_Language\",\n            \"value\": \"en-AU\"\n          }\n        }\n      ]\n    }\n  }\n}\n</code></pre><p></p> <p>Note</p> <p>Output of the query is configured to represent the following information</p> <ol> <li> <p>ID of the call</p> </li> <li> <p>Status of the call</p> </li> <li> <p>Total duration of the call</p> </li> <li> <p>Origin of the call. Who called.</p> </li> <li> <p>Destination of the call. Entry Point number.</p> </li> <li> <p>Agent, whoc accepted the call: ID and Name</p> </li> <li> <p>Language selected by the caller. Represented as Global_Language variable</p> </li> </ol> <p></p> </li> <li> <p>Open JSON Path tool https://jsonpath.com/ to test your GraphQL response. Clear the content from Document section and from JSONPath Query adress line.</p> </li> <li> <p>Switch to Developer Portal and copy the response </p> </li> <li> <p>Switch back to JSON Path tool and paste the response into the Document section.   </p> </li> <li> <p>Test the following paths by pasting them into JSONPath Query adress line one by one:</p> <p><code>$.data.taskDetails.tasks[0].id</code> - Interaction ID of the call.</p> <p><code>$.data.taskDetails.tasks[0].status</code> - Status of the call.</p> <p><code>$.data.taskDetails.tasks[0].totalDuration</code> - Total Duration of the call.</p> <p><code>$.data.taskDetails.tasks[0].destination</code> - Call destination. This is the number essigned to Entry Point.</p> <p><code>$.data.taskDetails.tasks[0].lastAgent.id</code> - Agent ID who accepted the call.</p> <p><code>$.data.taskDetails.tasks[0].lastAgent.name</code> - Agent name who accepted the call.</p> <p><code>$.data.taskDetails.tasks[0].stringGlobalVariables.Global_Language</code> - Language Global Variable that was used in the flow.</p> <p><code>$.data.taskDetails.tasks[0].stringGlobalVariables.value</code> - Language selected by a caller. </p> </li> </ol> <p></p> <p>Congratulations, you have succesfully completed Introduction to Developer Portal mission! \ud83c\udf89\ud83c\udf89 </p>"},{"location":"main/APITrack_Mission1/","title":"Macro Syntax Error","text":""},{"location":"main/APITrack_Mission1/#macro-syntax-error","title":"Macro Syntax Error","text":"<p>File: <code>main/APITrack_Mission1.md</code></p> <p>Line 231 in Markdown file: expected token 'end of print statement', got 'class' </p><pre><code>    &gt; In the Expression section write an expresion ***{{EmergencyGV_&lt;span class=\"attendee-id-placeholder\"&gt;Your_Attendee_ID&lt;/span&gt; == true}}***  \n</code></pre><p></p>"},{"location":"main/APITrack_Mission2/","title":"Macro Rendering Error","text":""},{"location":"main/APITrack_Mission2/#macro-rendering-error","title":"Macro Rendering Error","text":"<p>File: <code>main/APITrack_Mission2.md</code></p> <p>UndefinedError: 'NewPhoneContact' is undefined</p> <pre><code>Traceback (most recent call last):\n  File \"/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/mkdocs_macros/plugin.py\", line 699, in render\n    return md_template.render(**page_variables)\n           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n  File \"/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/jinja2/environment.py\", line 1295, in render\n    self.environment.handle_exception()\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n  File \"/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/jinja2/environment.py\", line 942, in handle_exception\n    raise rewrite_traceback_stack(source=source)\n  File \"&lt;template&gt;\", line 56, in top-level template code\n  File \"/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/jinja2/environment.py\", line 490, in getattr\n    return getattr(obj, attribute)\njinja2.exceptions.UndefinedError: 'NewPhoneContact' is undefined\n</code></pre>"},{"location":"main/APITrack_Mission3/","title":"Macro Syntax Error","text":""},{"location":"main/APITrack_Mission3/#macro-syntax-error","title":"Macro Syntax Error","text":"<p>File: <code>main/APITrack_Mission3.md</code></p> <p>Line 91 in Markdown file: No filter named 'epoch'. </p><pre><code>    {\"query\":\"query simulatedCSAT($from:Long! $to:Long! $timeComparator:QueryTimeType $filter:TaskFilters $name:String!){task(from:$from,to:$to,timeComparator:$timeComparator,filter:$filter){tasks{owner{name id}simulatedCSAT:doubleGlobalVariables(name:$name){name value}}}}\",\"variables\":{\"from\":\"{{now() | epoch(inMillis=true) - 604800000}}\",\"to\":\"{{now() | epoch(inMillis=true)}}\",\"timeComparator\":\"endedTime\",\"filter\":{\"and\":[{\"status\":{\"equals\":\"ended\"}},{\"origin\":{\"equals\":\"{{NewPhoneContact.ANI}}\"}},{\"doubleGlobalVariables\":{\"name\":{\"equals\":\"simulatedCSAT\"},\"value\":{\"gte\":3}}}]},\"name\":\"simulatedCSAT\"}}\n</code></pre><p></p>"},{"location":"main/APITrack_Mission3_AutoCSAT/","title":"Macro Syntax Error","text":""},{"location":"main/APITrack_Mission3_AutoCSAT/#macro-syntax-error","title":"Macro Syntax Error","text":"<p>File: <code>main/APITrack_Mission3_AutoCSAT.md</code></p> <p>Line 105 in Markdown file: No filter named 'epoch'. </p><pre><code>     {\"query\":\"query($from: Long!, $to: Long!)\\n{\\n  taskDetails(\\n      from: $from\\n      to: $to\\n    filter: {\\n      and: [\\n       { lastEntryPoint: { id: { equals: \\\"{{NewPhoneContact.EntryPointId}}\\\" } } }\\n       { status: { equals: \\\"ended\\\" } }\\n       { doubleGlobalVariables: {name:{equals:\\\"AutoCSAT_GV\\\"}, value: {gte:4} } }\\n\\n        ]\\n    }\\n  ) {\\n    tasks {\\n      csatScore  \\n      autoCsat\\n      owner {\\n        id\\n        name\\n      }\\n      doubleGlobalVariables(name: \\\"AutoCSAT_GV\\\"){\\n        name\\n        value\\n      }\\n\\n    }\\n  }\\n}\",\"variables\":{\"from\":\"{{now() | epoch(inMillis=true) - 1800000}}\",\"to\":\"{{now() | epoch(inMillis=true)}}\"}}\n</code></pre><p></p>"},{"location":"main/APITrack_Mission4/","title":"Macro Syntax Error","text":""},{"location":"main/APITrack_Mission4/#macro-syntax-error","title":"Macro Syntax Error","text":"<p>File: <code>main/APITrack_Mission4.md</code></p> <p>Line 84 in Markdown file: No filter named 'epoch'. </p><pre><code>    {\"query\":\"query lastTen($from:Long! $to:Long! $timeComparator:QueryTimeType $filter:TaskFilters){task(from:$from,to:$to,timeComparator:$timeComparator,filter:$filter){tasks{id status channelType createdTime endedTime origin destination direction terminationType isActive isCallback lastWrapupCodeName}}}\",\"variables\":{\"from\":\"{{now() | epoch(inMillis=true) - 600000}}\",\"to\":\"{{now() | epoch(inMillis=true)}}\",\"timeComparator\":\"endedTime\",\"filter\":{\"and\":[{\"status\":{\"equals\":\"ended\"}},{\"origin\":{\"equals\":\"{{NewPhoneContact.ANI}}\"}},{\"connectedCount\":{\"gte\":1}}]}}}\n</code></pre><p></p>"},{"location":"main/APITrack_Mission5_Function/","title":"Macro Rendering Error","text":""},{"location":"main/APITrack_Mission5_Function/#macro-rendering-error","title":"Macro Rendering Error","text":"<p>File: <code>main/APITrack_Mission5_Function.md</code></p> <p>UndefinedError: 'NewPhoneContact' is undefined</p> <pre><code>Traceback (most recent call last):\n  File \"/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/mkdocs_macros/plugin.py\", line 699, in render\n    return md_template.render(**page_variables)\n           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n  File \"/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/jinja2/environment.py\", line 1295, in render\n    self.environment.handle_exception()\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n  File \"/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/jinja2/environment.py\", line 942, in handle_exception\n    raise rewrite_traceback_stack(source=source)\n  File \"&lt;template&gt;\", line 304, in top-level template code\n  File \"/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/jinja2/environment.py\", line 490, in getattr\n    return getattr(obj, attribute)\njinja2.exceptions.UndefinedError: 'NewPhoneContact' is undefined\n</code></pre>"},{"location":"main/Browser_and_Desktop_Setup/","title":"Browser and Desktop Setup","text":""},{"location":"main/Browser_and_Desktop_Setup/#browser-setup","title":"Browser Setup","text":"<p>Since we will be using the same Chrome browser for different roles we will use the Chrome Browser profiles to allow multiple logins into the different components of the Webex contact center. For the control hub, use the Administrator profile created for you in the Chrome browser. Always offer Chrome to remember your credentials and password for this lab. For Agent Desktop, use Agent Desktop Application   pre-insalled on your working station by using Agent profile.   </p> <p>We will create the user profiles below - Admin, Agent</p> <p> </p>"},{"location":"main/Browser_and_Desktop_Setup/#creating-chrome-user-profiles","title":"Creating Chrome user profiles","text":"<p>Open the Windows Terminal (Windows key and type Powershell). Paste and run the following code. You will see 2 new Chrome shortcut icons on the desktop</p> <pre><code>$DesktopPath = [Environment]::GetFolderPath(\"Desktop\")\n$shell = New-Object -ComObject WScript.Shell\n$shortcut = $shell.CreateShortcut(\"$DesktopPath\\WxCC Admin.lnk\")\n$shortcut.TargetPath = \"%PROGRAMFILES%\\Google\\Chrome\\Application\\chrome.exe\"\n$Shortcut.Arguments = \"--user-data-dir=%USERPROFILE%\\chromeProfiles\\admin\"\n$Shortcut.Save()\n$shortcut = $shell.CreateShortcut(\"$DesktopPath\\WxCC Agent1.lnk\")\n$shortcut.TargetPath = \"%PROGRAMFILES%\\Google\\Chrome\\Application\\chrome.exe\"\n$Shortcut.Arguments = \"--user-data-dir=%USERPROFILE%\\chromeProfiles\\Agent1\"\n$Shortcut.Save()\n</code></pre> <p></p> <p>Check the desktop of your lab PC. You should find 2 Chrome shortcuts created - WxCC Admin and WxCC</p> <p>When you click on the links </p> <p></p> <p>You can customize each profile to be easily identifiable with a name and/or icon of your choice</p> <p></p> <p>We will use the Admin profile first in the next section.</p>"},{"location":"main/CallbackTrack_Conclusion/","title":"Conclusion","text":""},{"location":"main/CallbackTrack_Conclusion/#conclusion","title":"Conclusion","text":"<p>We hope you found the CallBack track both challenging and rewarding as you deepened your expertise with Webex Contact Center. In this session, you explored key strategies for implementing and refining the Callback feature to enhance customer experience and operational efficiency.</p> <p>Key missions included:</p> <ul> <li>Adding Basic Callback \u2013 Ensuring customers have the option to request a return call instead of waiting in the queue.</li> <li>Scheduling a Callback on Errors \u2013 Handling unexpected issues by automatically scheduling a callback when an error occurs.</li> <li>Preventing Duplicate Callbacks \u2013 Implementing safeguards to avoid redundant callback requests, improving efficiency and customer satisfaction.</li> </ul> <p>By mastering these techniques, you are now equipped to design more efficient and customer-friendly callback workflows within Webex Contact Center.</p> <p>Should you have any questions or need further assistance, feel free to reach out or join the Webex discussion forums. We\u2019re excited to see how you apply these skills in your future projects!</p> <p>Thank you for completing the Callback track, and we look forward to your continued growth with Webex Contact Center.</p>"},{"location":"main/CallbackTrack_Mission1/","title":"CallbackTrack Mission1","text":"<p>Note</p> <p>The input in the images that follow are only examples. They do not reflect the input you need to use in the lab exercises. In some cases, the input in the images may not follow the same attendee or pod ID from previous images. They are for representation only</p>"},{"location":"main/CallbackTrack_Mission1/#story","title":"Story","text":"<p>Imagine calling a contact center, seeking quick, personalized help. Behind the scenes, a flow smoothly routes your call based on your needs.</p>"},{"location":"main/CallbackTrack_Mission1/#call-flow-overview","title":"Call Flow Overview","text":"<ol> <li>A new call enters the flow. (This initiates the interaction and triggers the defined call-handling process.)</li> <li>The flow determines the caller's language preference and plays a pre-configured Text-to-Speech (TTS) prompt. (This ensures the caller receives information in their preferred language.)</li> <li>The call is routed to the appropriate queue. (This directs the caller to the right team on the flow logic.)</li> </ol>"},{"location":"main/CallbackTrack_Mission1/#mission-details","title":"Mission Details","text":"<p>Your mission is to:</p> <ol> <li>Configure key flow elements for efficient caller journeys. </li> <li>Explore Flow Templates to streamline flow creation. </li> <li>Set up routing with conditions, such as language preference. </li> <li>Gain the skills to design flows for real-world scenarios. </li> </ol> <p></p>Why Flow Templates? [Optional]  Flow Templates in Webex Contact Center are an essential feature for flow developers, offering a range of benefits that streamline the development process and enhance the efficiency and consistency of flow creation. Here\u2019s what they bring to the table:<p></p> <ul> <li> <p>Consistency and Standards: Templates ensure that flows adhere to best practices, creating consistent experiences across multiple projects.</p> </li> <li> <p>Time Savings: Pre-built structures reduce the need to start from scratch, enabling faster setup and allowing more focus on customization.</p> </li> <li> <p>Reduced Errors: Using tested templates lowers the risk of mistakes and minimizes troubleshooting.</p> </li> <li> <p>Easy Onboarding: New developers or partners can learn quickly by using templates as guides.</p> </li> <li> <p>Scalability: Templates allow developers to replicate and adapt solutions efficiently across different flows or deployments.</p> </li> <li> <p>Innovation: Developers can spend more time on unique features and integrations rather than reconfiguring basics.</p> </li> </ul> <p>Flow Templates are designed to empower developers, speed up the development lifecycle, and maintain high-quality standards across flows, making them a core asset in Webex Contact Center flow design.</p>"},{"location":"main/CallbackTrack_Mission1/#_1","title":"CallbackTrack Mission1","text":""},{"location":"main/CallbackTrack_Mission1/#build","title":"Build","text":"<ol> <li> <p>Login into Webex Control Hub by using your Admin profile.     Your login will be of the format wxcclabs+admin_IDYour_Attendee_ID@gmail.com. You will see another login screen with OKTA on it where you may need to enter the email address again and the password provided to you.</p> <p></p> <p>Note</p> <p>Remember to take up the offer from Chrome to save your password</p> </li> <li> <p>This is the Administration interface for webex contact center and is also known as the Control Hub. Look for the contact center option in the left pane under SERVICES \u2013 Contact Center and click it</p> </li> <li>Navigate to Flows, click on Manage Flows dropdown list and select Create Flows</li> <li>New Tab will be opened. Navigate to Flow Templates</li> <li>Choose Simple Inbound Call to Queue template and click Next. You can open View Details and to see observe flow structure and read flow description</li> <li> <p>Name your flow as Main_Flow_Your_Attendee_ID. Then click on Create Flow</p> <p></p> </li> <li> <p>Edit should be set to On when you create new flow, but if not switch it from Edit: Off mode to Edit: On. Select Play Message node with label WelcomePrompt and on the node settings modify Text-to-Speech Message to any greetings you like. This message will be the first message you hear while calling to your script.</p> </li> <li> <p>Select Queue node. On the General settings keep Static Queue checked and select queue Your_Attendee_ID_Queue from the drop down list</p> <p>Note</p> <p>As mentioned in Getting Started, all queues have been pre-configured so you don't need to change them at current step.</p> </li> <li> <p>[Optional] Select Play Message node (the one which goes after Queue and Play Music nodes) and on the Node settings modify Text-to-Speech Message to any message you like. This message will be played while the caller is waiting in the queue.</p> </li> <li> <p>On bottom right corner toggle Validation from Off to On to check for any potential flow errors and recommendations. </p> <p>Note</p> <p>You can ignore recommendations but cannot skip errors.</p> </li> <li> <p>Click Publish Flow</p> <p></p> </li> <li> <p>In popped-up window, click on dropdown menu to select Latest label, then click Publish.</p> </li> <li> <p>Return back to Control Hub to assign the Flow to your Channel (Entry Point) - Go to Channels, search for your channel Your_Attendee_ID_Channel.</p> </li> <li>Click on Your_Attendee_ID_Channel</li> <li> <p>In Entry Point settings section change the following, then click Save button:</p> <p>Routing Flow: Main_Flow_Your_Attendee_ID</p> <p>Version Label: Latest</p> </li> </ol> <p></p>"},{"location":"main/CallbackTrack_Mission1/#checkpoint-test","title":"Checkpoint Test","text":"<ol> <li>Launch Webex CC Desktop application  and login with agent credentials you have been provided wxcclabs+agent_IDYour_Attendee_ID@gmail.com. You will see another login screen with OKTA on it where you may need to enter the email address again and the password provided to you. </li> <li>Select your Team Your_Attendee_ID_Team. Click Submit. Allow browser to access Microphone by clicking Allow on every visit.</li> <li> <p>Make your agent Available and you're ready to make a call.</p> <p>Note</p> <p>This is the only time during the lab when you need to log in to the Webex CC Desktop application. It has been configured to keep your agent logged into the application for the entire duration of the lab. If, for any reason, you are logged out manually or due to a network error, please log in again as explained above.</p> <p></p> </li> <li> <p>Open your Webex App and dial the Support Number provided to you, which is configured in your Your_Attendee_ID_Channel configuration.</p> </li> </ol> <p></p>"},{"location":"main/CallbackTrack_Mission1/#enhance-your-flow-by-adding-language","title":"Enhance Your Flow by adding Language","text":""},{"location":"main/CallbackTrack_Mission1/#mission-details_1","title":"Mission Details","text":"<p>Your mission is to:</p> <ul> <li>Use the same flow created in the previous section.</li> <li>Modify the TTS section to use en-AU (English - Australia) and connect the Set Variable node as illustrated below.</li> <li>Place a call to verify and validate the speech functionality.</li> </ul> <p></p>Text-to-Speech (TTS) in Webex Contact Center[Optional] All supported languages can be found here: Text-to-Speech-(TTS)-in-Webex-Contact-Center <p></p>"},{"location":"main/CallbackTrack_Mission1/#build_1","title":"Build","text":"<ol> <li> <p>Open your flow Main_Flow_Your_Attendee_ID. Make sure Edit toggle is ON.</p> </li> <li> <p>On the right hand side you will see the Global Flow Properties Panel. Scroll down and Locate the Predefined Variables section. Click on the Add Global Variables button. Search for Global_Language variable and click on Add button.</p> <p></p> </li> <li> <p>Add a Set Variable with following configuration. </p> </li> </ol> <p>Delete connection between NewPhoneContact and WelcomePrompt</p> <p>Connect NewPhoneContact to Set Variable</p> <p>Connect Set Variable to WelcomePrompt</p> <p>Variable: Global_Language</p> <p>Set Value:  en-AU</p> <ol> <li> <p>Validate the flow by clicking Validate, Publish and select the Latest version of the flow</p> <p></p> </li> </ol>"},{"location":"main/CallbackTrack_Mission1/#testing","title":"Testing","text":"<ol> <li> <p>Open your Webex Desktop and make your agent Available and you're ready to make a call.</p> </li> <li> <p>Open your Webex App and dial the Support Number provided to you, which is configured in your Your_Attendee_ID_Channel configuration.</p> </li> </ol> <p></p> <ol> <li>Verify if the TTS language changed</li> </ol> <p>Congratulations on completing another mission.</p>"},{"location":"main/CallbackTrack_Mission2/","title":"Macro Rendering Error","text":""},{"location":"main/CallbackTrack_Mission2/#macro-rendering-error","title":"Macro Rendering Error","text":"<p>File: <code>main/CallbackTrack_Mission2.md</code></p> <p>UndefinedError: 'NewNumber' is undefined</p> <pre><code>Traceback (most recent call last):\n  File \"/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/mkdocs_macros/plugin.py\", line 699, in render\n    return md_template.render(**page_variables)\n           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n  File \"/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/jinja2/environment.py\", line 1295, in render\n    self.environment.handle_exception()\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n  File \"/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/jinja2/environment.py\", line 942, in handle_exception\n    raise rewrite_traceback_stack(source=source)\n  File \"&lt;template&gt;\", line 98, in top-level template code\n  File \"/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/jinja2/environment.py\", line 490, in getattr\n    return getattr(obj, attribute)\njinja2.exceptions.UndefinedError: 'NewNumber' is undefined\n</code></pre>"},{"location":"main/CallbackTrack_Mission3/","title":"Macro Syntax Error","text":""},{"location":"main/CallbackTrack_Mission3/#macro-syntax-error","title":"Macro Syntax Error","text":"<p>File: <code>main/CallbackTrack_Mission3.md</code></p> <p>Line 175 in Markdown file: expected token 'name', got 'integer' </p><pre><code>    &gt; Set Value: ***{{ ANI | 123}}***&lt;span class=\"copy-static\" data-copy-text=\"{{ ANI | 123}}\"&gt;&lt;span class=\"copy\" title=\"Click to copy!\"&gt;&lt;/span&gt;&lt;/span&gt;\n</code></pre><p></p>"},{"location":"main/CallbackTrack_Mission4/","title":"Macro Syntax Error","text":""},{"location":"main/CallbackTrack_Mission4/#macro-syntax-error","title":"Macro Syntax Error","text":"<p>File: <code>main/CallbackTrack_Mission4.md</code></p> <p>Line 162 in Markdown file: unexpected char '?' at 7105 </p><pre><code>      {{ callbackConnectTime == \"-1\" ? (callbackStatus == \"Not Processed\" ? (HTTPRequest_CallBackSearch.httpStatusCode == 200 ? \"true\" : \"false\") : \"false\") : \"false\" }}\n</code></pre><p></p>"},{"location":"main/Choose_Your_Adventure/","title":"Choose Your Adventure","text":""},{"location":"main/Choose_Your_Adventure/#welcome-to-your-lab-adventure","title":"Welcome to Your Lab Adventure!","text":""},{"location":"main/Choose_Your_Adventure/#overview","title":"Overview","text":"<p>In this session, we\u2019ve designed 15 unique labs for you to explore, grouped into 4 distinct tracks to create a focused and engaging learning experience. Each track is crafted to help you develop specific skills.</p> <p>Here\u2019s what you need to know:</p> <p>Each track offers a different number of labs, guiding you through a cohesive learning journey.</p> <p>Completing just one track is enough to achieve the session\u2019s goals.</p> <p>Want to push further? Finish 2 tracks to excel, 3 tracks to become an expert, or take on all 4 tracks to earn the ultimate title of Mega Superstar!</p> <p>Take a moment to review the tracks, choose the ones that excite you, and dive in. This is your adventure\u2014make it unforgettable!</p> <p>There\u2019s no set order\u2014start with any track that interests you most, but we recommend starting with the Core Track. One of the missions contains information you are going to use on the final troubleshooting task, which we will complete as the last mission.</p>"},{"location":"main/Choose_Your_Adventure/#track-1-core-track","title":"Track 1: Core Track","text":"<p>This track introduces the fundamental features of Flow Designer. Participants will explore flow templates, business hours, and event flows while learning to utilize additional tools like the Debugger and Analyzer.</p> <p></p>"},{"location":"main/Choose_Your_Adventure/#track-2-api-track","title":"Track 2: API Track","text":"<p>In this track, participants will work on customizing flows using a variety of API requests to interact with different data sources.</p> <p></p>"},{"location":"main/Choose_Your_Adventure/#track-3-callback-track","title":"Track 3: CallBack Track","text":"<p>The Callback track includes a series of labs focused on various callback scenarios. It begins with basic callback configuration and progresses to advanced GraphQL techniques to eliminate duplicate callbacks.</p> <p></p>"},{"location":"main/Choose_Your_Adventure/#track-4-ai-agent-track","title":"Track 4: AI Agent Track","text":"<p>A track that involves configuring Cisco\u2019s AI Assistance features and AI agents (bot) and integrating it with Flow Designer to enable flow customization. </p> <p></p>"},{"location":"main/CoreTrack_Conclusion/","title":"Conclusion","text":""},{"location":"main/CoreTrack_Conclusion/#conclusion","title":"Conclusion","text":"<p>We hope you enjoyed the hands-on experience of the Webex Contact Center Lab. Throughout this lab, you\u2019ve gained valuable insights into building and configuring essential elements of Webex Contact Center workflows. Starting with the Basic Call Routing mission, you explored foundational features like flow templates, Text-to-Speech (TTS) capabilities, and language-based routing.</p> <p>From there, you enhanced your skills with missions such as:</p> <ul> <li>Using Business Hours to introduce flexibility and adaptability to your flows.</li> <li>Leveraging Event Flows to dynamically handle real-time events.</li> <li>Designing and implementing a Post Call Survey to gather actionable customer feedback.</li> <li>You also worked extensively with the Flow Designer Tools, gaining confidence in navigating, troubleshooting, and optimizing flows.</li> </ul> <p>By completing these missions, you\u2019ve not only developed a deep understanding of Webex Contact Center features but also acquired practical skills to harness its capabilities in real-world scenarios.</p> <p>Should you need further assistance or have questions, feel free to reach out or join discussions in the Webex community. We\u2019re here to support your success as you continue to explore and implement these powerful tools in your future projects.</p> <p>Thank you for participating in Part 1 of the lab, and we encourage you to continue exploring and building on these foundational skills as you progress through the next stages of the Webex Contact Center Flow Designer Lab!</p>"},{"location":"main/CoreTrack_Mission1/","title":"CoreTrack Mission1","text":"<p>Note</p> <p>The input in the images that follow are only examples. They do not reflect the input you need to use in the lab exercises. In some cases, the input in the images may not follow the same attendee or pod ID from previous images. They are for representation only</p>"},{"location":"main/CoreTrack_Mission1/#story","title":"Story","text":"<p>Imagine calling a contact center, seeking quick, personalized help. Behind the scenes, a flow smoothly routes your call based on your needs.</p>"},{"location":"main/CoreTrack_Mission1/#call-flow-overview","title":"Call Flow Overview","text":"<ol> <li>A new call enters the flow. (This initiates the interaction and triggers the defined call-handling process.)</li> <li>The flow determines the caller's language preference and plays a pre-configured Text-to-Speech (TTS) prompt. (This ensures the caller receives information in their preferred language.)</li> <li>The call is routed to the appropriate queue. (This directs the caller to the right team on the flow logic.)</li> </ol>"},{"location":"main/CoreTrack_Mission1/#mission-details","title":"Mission Details","text":"<p>Your mission is to:</p> <ol> <li>Configure key flow elements for efficient caller journeys. </li> <li>Explore Flow Templates to streamline flow creation. </li> <li>Set up routing with conditions, such as language preference. </li> <li>Gain the skills to design flows for real-world scenarios. </li> </ol> <p></p>Why Flow Templates? [Optional]  Flow Templates in Webex Contact Center are an essential feature for flow developers, offering a range of benefits that streamline the development process and enhance the efficiency and consistency of flow creation. Here\u2019s what they bring to the table:<p></p> <ul> <li> <p>Consistency and Standards: Templates ensure that flows adhere to best practices, creating consistent experiences across multiple projects.</p> </li> <li> <p>Time Savings: Pre-built structures reduce the need to start from scratch, enabling faster setup and allowing more focus on customization.</p> </li> <li> <p>Reduced Errors: Using tested templates lowers the risk of mistakes and minimizes troubleshooting.</p> </li> <li> <p>Easy Onboarding: New developers or partners can learn quickly by using templates as guides.</p> </li> <li> <p>Scalability: Templates allow developers to replicate and adapt solutions efficiently across different flows or deployments.</p> </li> <li> <p>Innovation: Developers can spend more time on unique features and integrations rather than reconfiguring basics.</p> </li> </ul> <p>Flow Templates are designed to empower developers, speed up the development lifecycle, and maintain high-quality standards across flows, making them a core asset in Webex Contact Center flow design.</p>"},{"location":"main/CoreTrack_Mission1/#_1","title":"CoreTrack Mission1","text":""},{"location":"main/CoreTrack_Mission1/#build","title":"Build","text":"<ol> <li> <p>Login into Webex Control Hub by using your Admin profile.     Your login will be of the format wxcclabs+admin_IDYour_Attendee_ID@gmail.com. You will see another login screen with OKTA on it where you may need to enter the email address again and the password provided to you.</p> <p></p> <p>Note</p> <p>Remember to take up the offer from Chrome to save your password</p> </li> <li> <p>This is the Administration interface for webex contact center and is also known as the Control Hub. Look for the contact center option in the left pane under SERVICES \u2013 Contact Center and click it</p> </li> <li>Navigate to Flows, click on Manage Flows dropdown list and select Create Flows</li> <li>New Tab will be opened. Navigate to Flow Templates</li> <li>Choose Simple Inbound Call to Queue template and click Next. You can open View Details and to see observe flow structure and read flow description</li> <li> <p>Name your flow as Main_Flow_Your_Attendee_ID. Then click on Create Flow</p> <p></p> </li> <li> <p>Edit should be set to On when you create new flow, but if not switch it from Edit: Off mode to Edit: On. Select Play Message node with label WelcomePrompt and on the node settings modify Text-to-Speech Message to any greetings you like. This message will be the first message you hear while calling to your script.</p> </li> <li> <p>Select Queue node. On the General settings keep Static Queue checked and select queue Your_Attendee_ID_Queue from the drop down list</p> <p>Note</p> <p>As mentioned in Getting Started, all queues have been pre-configured so you don't need to change them at current step.</p> </li> <li> <p>[Optional] Select Play Message node (the one which goes after Queue and Play Music nodes) and on the Node settings modify Text-to-Speech Message to any message you like. This message will be played while the caller is waiting in the queue.</p> </li> <li> <p>On bottom right corner toggle Validation from Off to On to check for any potential flow errors and recommendations. </p> <p>Note</p> <p>You can ignore recommendations but cannot skip errors.</p> </li> <li> <p>Click Publish Flow</p> <p></p> </li> <li> <p>In popped-up window, click on dropdown menu to select Latest label, then click Publish.</p> </li> <li> <p>Return back to Control Hub to assign the Flow to your Channel (Entry Point) - Go to Channels, search for your channel Your_Attendee_ID_Channel.</p> </li> <li>Click on Your_Attendee_ID_Channel</li> <li> <p>In Entry Point settings section change the following, then click Save button:</p> <p>Routing Flow: Main_Flow_Your_Attendee_ID</p> <p>Version Label: Latest</p> </li> </ol> <p></p>"},{"location":"main/CoreTrack_Mission1/#checkpoint-test","title":"Checkpoint Test","text":"<ol> <li>Launch Webex CC Desktop application  and login with agent credentials you have been provided wxcclabs+agent_IDYour_Attendee_ID@gmail.com. You will see another login screen with OKTA on it where you may need to enter the email address again and the password provided to you. </li> <li>Select your Team Your_Attendee_ID_Team. Click Submit. Allow browser to access Microphone by clicking Allow on every visit.</li> <li> <p>Make your agent Available and you're ready to make a call.</p> <p>Note</p> <p>This is the only time during the lab when you need to log in to the Webex CC Desktop application. It has been configured to keep your agent logged into the application for the entire duration of the lab. If, for any reason, you are logged out manually or due to a network error, please log in again as explained above.</p> <p></p> </li> <li> <p>Open your Webex App and dial the Support Number provided to you, which is configured in your Your_Attendee_ID_Channel configuration.</p> </li> </ol> <p></p>"},{"location":"main/CoreTrack_Mission1/#enhance-your-flow-by-adding-language","title":"Enhance Your Flow by adding Language","text":""},{"location":"main/CoreTrack_Mission1/#mission-details_1","title":"Mission Details","text":"<p>Your mission is to:</p> <ul> <li>Use the same flow created in the previous section.</li> <li>Modify the TTS section to use en-AU (English - Australia) and connect the Set Variable node as illustrated below.</li> <li>Place a call to verify and validate the speech functionality.</li> </ul> <p></p>Text-to-Speech (TTS) in Webex Contact Center[Optional] All supported languages can be found here: Text-to-Speech-(TTS)-in-Webex-Contact-Center <p></p>"},{"location":"main/CoreTrack_Mission1/#build_1","title":"Build","text":"<ol> <li> <p>Open your flow Main_Flow_Your_Attendee_ID. Make sure Edit toggle is ON.</p> </li> <li> <p>On the right hand side you will see the Global Flow Properties Panel. Scroll down and Locate the Predefined Variables section. Click on the Add Global Variables button. Search for Global_Language variable and click on Add button.</p> <p></p> </li> <li> <p>Add a Set Variable with following configuration. </p> </li> </ol> <p>Delete connection between NewPhoneContact and WelcomePrompt</p> <p>Connect NewPhoneContact to Set Variable</p> <p>Connect Set Variable to WelcomePrompt</p> <p>Variable: Global_Language</p> <p>Set Value:  en-AU</p> <ol> <li> <p>Validate the flow by clicking Validate, Publish and select the Latest version of the flow</p> <p></p> </li> </ol>"},{"location":"main/CoreTrack_Mission1/#testing","title":"Testing","text":"<ol> <li> <p>Open your Webex Desktop and make your agent Available and you're ready to make a call.</p> </li> <li> <p>Open your Webex App and dial the Support Number provided to you, which is configured in your Your_Attendee_ID_Channel configuration.</p> </li> </ol> <p></p> <ol> <li>Verify if the TTS language changed</li> </ol> <p>Congratulations on completing another mission.</p>"},{"location":"main/CoreTrack_Mission2/","title":"CoreTrack Mission2","text":""},{"location":"main/CoreTrack_Mission2/#story","title":"Story","text":"<p>Business Hours allows you to configure the operational hours of the contact center, offering an enhanced experience in routing strategy configuration and simplifying the routing flow for improved efficiency and customer satisfaction. </p>"},{"location":"main/CoreTrack_Mission2/#call-flow-overview","title":"Call Flow Overview","text":"<ol> <li>A new call enters the flow. </li> <li>The flow determines the caller's language preference and plays a pre-configured Text-to-Speech (TTS) prompt. </li> <li>The flow determines whether it is currently within working hours and routes the call appropriately.</li> <li>The call is routed to the appropriate queue. </li> </ol>"},{"location":"main/CoreTrack_Mission2/#mission-details","title":"Mission Details","text":"<p>Your mission is to:</p> <ul> <li> <p>Continue to use same flow Main_Flow_Your_Attendee_ID we created in previous Mission.</p> </li> <li> <p>Add Business Hours functionality Your_Attendee_ID_Bussiness_Hours to your flow. Business Hours entity has been configured for you and contains the following settings:</p> <ul> <li> <p>Working Hours - Define the time during which the contact center will be operational. Each working hour configuration can include one or more shifts. Different schedules can be set for various time zones.</p> </li> <li> <p>Holidays - Specify a day or range of days declared as holidays. The entire 24 hours of the selected day(s) are marked as non-operational.</p> </li> <li> <p>Overrides - Configure working hours for special cases, such as emergencies or occasions like Christmas, when the contact center operates for additional hours.</p> </li> </ul> </li> </ul>"},{"location":"main/CoreTrack_Mission2/#build","title":"Build","text":"<ol> <li> <p>Switch to Control Hub and navigate to Business Hours under Customer Experience section. Locate your Your_Attendee_ID_Bussiness_Hours. You will see that currently only Working Hours are configured for every working day between 12:00 AM to 11:59 PM\".</p> <p></p> </li> <li> <p>Switch to Flow Designer. Open your flow Main_Flow_Your_Attendee_ID and make sure Edit toggle is ON.</p> </li> <li> <p>Drag and drop following nodes to the canvas:</p> <ul> <li> <p>Business Hours</p> </li> <li> <p>Play Message</p> </li> <li> <p>Disconnect Contact</p> </li> </ul> <p></p> </li> <li> <p>Connect Set Variable node to Business Hours and Business Hours node exits as follow:</p> <ul> <li> <p>Working Hours connect to WelcomePrompt node</p> </li> <li> <p>Holidays, Overrides and Default connect to new added Play Message node.</p> </li> <li> <p>New added Play Message connect to Disconnect contact</p> </li> </ul> <p></p> </li> <li> <p>Click on Business Hours node and select preconfigured Business Hours Entity Your_Attendee_ID_Bussiness_Hours .</p> </li> <li> <p>Configure Play Message node as follows:</p> <p>Enable Text-To-Speech</p> <p>Select the Connector: Cisco Cloud Text-to-Speech</p> <p>Click the Add Text-to-Speech Message button and paste text: It's not working hours currently. Please call later. Goodbye.</p> <p>Delete the Selection for Audio File</p> </li> <li> <p>Validate the flow by clicking Validate, Publish and select the Latest version of the flow</p> <p>Note</p> <p>We haven't changed the flow behavior yet as Working hours covers the current time. You can make a call and accept it on agent desktop to verify.</p> <p></p> </li> <li> <p>We are going to use Override option to change the logic. Overrides as well as Business hours have been preconfigured for you. Now we need to apply it on your Your_Attendee_ID_Bussiness_Hours entity. Switch to Control Hub and open Your_Attendee_ID_Bussiness_Hours in Control Hub, scroll down to Additional Settings and select Overrides_Hours from Override dropdown list. Then click Save.</p> <p>Note</p> <p>Override Hours entity was configured to overwrite Working Hours and set to duration of current Technical Summit. </p> <p></p> </li> </ol>"},{"location":"main/CoreTrack_Mission2/#testing","title":"Testing","text":"<ol> <li>Open your Webex App and dial the Support Number provided to you, which is configured in your Your_Attendee_ID_Channel configuration. Make sure you hear the message we set in Step 6.</li> </ol>"},{"location":"main/CoreTrack_Mission2/#post-testing-steps","title":"Post Testing steps","text":"<ol> <li> <p>[IMPORTANT] Now we need to revert the configuration we made in Step 8 as we are going to use same flow in upcoming tasks. Open Your_Attendee_ID_Bussiness_Hours in Control Hub, scroll down to Additional Settings and select None from Override dropdown list. Then click Save.</p> <p> </p> </li> <li> <p>Make one more call from Webex App to make sure you hear the original Welcome message you set on first steps of previous Mission.</p> </li> </ol> <p>Congratulations on completing another mission.</p>"},{"location":"main/CoreTrack_Mission3/","title":"Macro Rendering Error","text":""},{"location":"main/CoreTrack_Mission3/#macro-rendering-error","title":"Macro Rendering Error","text":"<p>File: <code>main/CoreTrack_Mission3.md</code></p> <p>UndefinedError: 'NewNumber' is undefined</p> <pre><code>Traceback (most recent call last):\n  File \"/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/mkdocs_macros/plugin.py\", line 699, in render\n    return md_template.render(**page_variables)\n           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n  File \"/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/jinja2/environment.py\", line 1295, in render\n    self.environment.handle_exception()\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n  File \"/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/jinja2/environment.py\", line 942, in handle_exception\n    raise rewrite_traceback_stack(source=source)\n  File \"&lt;template&gt;\", line 98, in top-level template code\n  File \"/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/jinja2/environment.py\", line 490, in getattr\n    return getattr(obj, attribute)\njinja2.exceptions.UndefinedError: 'NewNumber' is undefined\n</code></pre>"},{"location":"main/CoreTrack_Mission4/","title":"Macro Rendering Error","text":""},{"location":"main/CoreTrack_Mission4/#macro-rendering-error","title":"Macro Rendering Error","text":"<p>File: <code>main/CoreTrack_Mission4.md</code></p> <p>UndefinedError: 'NewPhoneContact' is undefined</p> <pre><code>Traceback (most recent call last):\n  File \"/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/mkdocs_macros/plugin.py\", line 699, in render\n    return md_template.render(**page_variables)\n           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n  File \"/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/jinja2/environment.py\", line 1295, in render\n    self.environment.handle_exception()\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n  File \"/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/jinja2/environment.py\", line 942, in handle_exception\n    raise rewrite_traceback_stack(source=source)\n  File \"&lt;template&gt;\", line 65, in top-level template code\n  File \"/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/jinja2/environment.py\", line 490, in getattr\n    return getattr(obj, attribute)\njinja2.exceptions.UndefinedError: 'NewPhoneContact' is undefined\n</code></pre>"},{"location":"main/CoreTrack_Mission5/","title":"CoreTrack Mission5","text":""},{"location":"main/CoreTrack_Mission5/#story","title":"Story","text":"<p>In this lab, you will complete a mission to enhance customer feedback collection by integrating a survey into the Webex Contact Center call flow. The lab is designed to be simple yet practical, focusing on minimal configuration within the Flow Designer, while leveraging a preconfigured survey template.</p> <p></p>Good to Know [Optional]<p></p> <p>Supported Survey Question Types in Webex Contact Center</p> <ol> <li>Customer Satisfaction (CSAT):<ul> <li>Purpose: Measure satisfaction with a specific interaction or service.</li> <li>Example Question: \"On a scale of 1 to 5, how satisfied are you with the service you received today?\"</li> <li>Use Case: Assess overall satisfaction at the end of a call or interaction.</li> </ul> </li> <li>Customer Effort Score (CES):<ul> <li>Purpose: Evaluate the ease of resolving a customer's issue or completing a task.</li> <li>Example Question: \"On a scale of 1 to 5, how easy was it to complete your task today?\"</li> <li>Use Case: Identify pain points in the customer journey or process efficiency.</li> </ul> </li> <li>Net Promoter Score (NPS):<ul> <li>Purpose: Measure customer loyalty and the likelihood of recommending the service.</li> <li>Example Question: \"On a scale of 0 to 10, how likely are you to recommend our service to a friend or colleague?\"</li> </ul> </li> <li>Use Case: Gauge long-term customer loyalty and brand advocacy. </li></ol>"},{"location":"main/CoreTrack_Mission5/#call-flow-overview","title":"Call Flow Overview","text":"<ol> <li>A new call enters the flow. </li> <li>The flow executes the logic to enable survey functionality.</li> <li>Agent answers the call.</li> <li>The flow triggers an event when the agent disconnects from the call.</li> <li>The caller remains on the line and hears the survey menu.</li> </ol>"},{"location":"main/CoreTrack_Mission5/#mission-details","title":"Mission Details","text":"<p>Your mission is to:</p> <ol> <li>Integrate a preconfigured survey into the call flow using the Flow Designer.</li> <li>Configure basic logic to determine when to route customers to the survey (e.g., after a call ends).</li> <li>Understand how Webex Contact Center supports various survey question types, including CSAT, CES, and NPS.</li> </ol> <p>Note</p> <p>The survey is prebuilt and includes key questions designed to gather actionable insights from customers. Your task is to focus on configuring the flow and ensuring the survey is triggered seamlessly during the customer journey.</p>"},{"location":"main/CoreTrack_Mission5/#pre-configured-entities","title":"Pre-configured entities","text":"<p>Survey: PCS-2025</p> <p>System defined GlobalVariable: Global_FeedbackSurveyOptIn.  </p> <p>[Optional]     In case you don't want to use pre-configured Survey you can configure your own. Expand below section to create your own Survey otherwise proceed to Build section below</p> <p></p>Create your own Survey [Optional]<p></p> <ul> <li> <p>In Control Hub -&gt; Contact Center open a Survey configuration page under Customer Expirience. Then click Create new survey.</p> </li> <li> <p>Enter survey name in Survey name field. Make sure IVR survey is selected. Then click next </p> </li> </ul> <p> </p> <ul> <li>Edit Welcome note and Thank you note by uploading the following files. Download files to your desktop prior uploading to survey. </li> </ul> <p> </p> <ul> <li> <p>Click on Add a question which is in the middle between Welcome note and Thank you note. Choose either NPS, CSAT or CES type of question.</p> </li> <li> <p>Upload respective audio prompts. Prompts can be downloaded from shared folder.</p> </li> <li> <p>Click Next. You can ignore Error Handling configuration page. Click Save*</p> </li> </ul> <p> </p>"},{"location":"main/CoreTrack_Mission5/#build","title":"Build","text":"<ol> <li> <p>Switch to the Control Hub then go to Contact Center. Navigate to the Surveys under the Customer Experience section. Locate PCS-2025 Survey and click on it to familiarise yourself with it's configuration. </p> </li> <li> <p>Switch to the Flow Designer. Open your Main_Flow_Your_Attendee_ID, make sure Edit toggle is ON.</p> </li> <li> <p>Add Global Variable Global_FeedbackSurveyOptIn to your flow.   </p> </li> <li> <p>Drag Set Variable node to canvas:</p> <p>Activity Name: FeedbackSet</p> <p>Variable: Global_FeedbackSurveyOptIn</p> <p>Set Value: true</p> <p>Delete connection between NewPhoneContact and Set Variable on which we configured Language while doing the Main Lab.</p> <p>Connect NewPhoneContact to the front of the FeedbackSet node</p> <p>Connect FeedbackSet to the front of the Set Variable node</p> <p></p> </li> <li> <p>Open Event FLows  tab and locate AgentDisconected node. If you completed previous mission you should have HTTPRequest node connected to it. Delete the connection between HTTPRequest node and DisconnectContact.</p> </li> <li> <p>Drag FeedbackV2 and Play Message</p> <p>FeedbacV2</p> <p>SurveyMethod -&gt; VoiceBased:  PCS-2025</p> <p>Connect HTTPRequest to FeedbackV2 node</p> <p>Connect FeedbackV2 node to Disconnect node</p> <p>Connect FeedbackV2 Undefined Error to Play Message node</p> <p>Play Message</p> <p>Enable Text-To-Speech</p> <p>Select the Connector: Cisco Cloud Text-to-Speech</p> <p>Click the Add Text-to-Speech Message button and paste text: Something went wrong on Feedback node. Please call later.</p> <p>Delete the selection for Audio File</p> <p>Connect Play Message created to Disconnect Contact node </p> <p> </p> </li> <li> <p>Validate the flow by clicking Validate, Publish and select the Latest version of the flow</p> </li> </ol>"},{"location":"main/CoreTrack_Mission5/#testing","title":"Testing","text":"<ol> <li>Your Agent desktop session should be still active but if not, use Webex CC Desktop application  and login with agent credentials you have been provided wxcclabs+agent_IDYour_Attendee_ID@gmail.com and become Available </li> <li>Make a test call to the Support Number and accept the call by Agent.</li> <li>Finish the call by Agent so the caller could stay on the line. </li> <li>Now the caller should hear prompts configured in PCS-2025. Complete the survey.</li> <li> <p>To check survey responses, switch to the Control Hub and navigate to the Surveys under Customer Experience section. Locate the PCS-2025 survey and click on the Download button on the right hand side to download a CSV file with the provided Survey responses.</p> <p>Note</p> <p>If you create your own survey, as described in the Optional section of this mission, you might not see the survey responses immediately, as there is a delay in edited surveys.</p> </li> </ol> <p>Congratulations on completing another mission where we have learnt how Post Call Survey can be implemented.</p>"},{"location":"main/CoreTrack_Mission6/","title":"CoreTrack Mission6","text":"<p>Note</p> <p>The current mission does not include any configuration steps, but it focuses on additional Flow Designer tools that facilitate flow troubleshooting and might provide you with ideas on how to optimize your flow logic.</p>"},{"location":"main/CoreTrack_Mission6/#debug-overview","title":"Debug Overview","text":"<p>The Debug Tool is an essential feature in the Webex Contact Center Flow Designer, designed to simplify troubleshooting and enhance visibility into the call flow behavior. Its importance lies in its ability to provide real-time insights, enabling administrators and developers to quickly identify and resolve issues that could impact customer experience.</p> <p></p>Good to Know [Optional]<p></p> <p></p>"},{"location":"main/CoreTrack_Mission6/#why-debug-is-important","title":"Why Debug is Important?","text":"<ol> <li> <p>Real-Time Analysis: Tracks the call flow execution step by step, showing which nodes are executed and the data passed between them.</p> </li> <li> <p>Error Identification: Quickly pinpoint errors, such as misconfigured nodes, incorrect variable usage, or unexpected call routing.</p> </li> <li> <p>Optimization: Provides insights into flow performance, allowing you to optimize for efficiency and accuracy. </p></li></ol>"},{"location":"main/CoreTrack_Mission6/#how-to-use-the-debug-tool","title":"How to Use the Debug Tool","text":"<ol> <li> <p>Switch to the Flow Designer and open your flow, Main_Flow_Your_Attendee_ID. Then, click the Debug button at the bottom of the Flow Designer.</p> </li> <li> <p>You can view the calls you've made today during the previous exercises. Please click on the one at the top.</p> <ol> <li> <p>You can search your call by Intercation ID</p> </li> <li> <p>Filter by Date Range and by Label</p> </li> </ol> <p>Note</p> <p>You might see an allert as on the following screenshot. Click refresh button to reload the diagram.   </p> </li> <li> <p>Observe the execution path, with visual indicators highlighting the flow nodes being executed. You can switch between Event Flows and Main Flows to see all nodes executed.</p> </li> <li> <p>By clicking on each activity name you will see it's details. Examples: Entry point ID, Flow Label, DNIS, selected Business Hours, also TTS value and what events were triggered.</p> <p></p> </li> <li> <p>Spend some time to explore the tool. Identify bottlenecks, loops, or errors if any. </p> </li> <li>As an option, you can break something in your flow and see how Debug tool shows that error.</li> </ol> <p>By leveraging the Debug Tool effectively, you can ensure your call flows function as intended, providing a seamless experience for both customers and agents.</p>"},{"location":"main/CoreTrack_Mission6/#flow-analytics-overview","title":"Flow Analytics Overview","text":"<p>Flow Analytics feature is designed to provide flow developer, administrators and supervisors with a comprehensive, graphical view of how Flow paths are being utilized across all customer interactions. This feature enables better analysis of IVR flow operations, helping to identify areas for improvement and increase self-service containment. The feature provides an aggregated view that allows users to:</p> <ul> <li>Analyze traces aggregated over a period of time.</li> <li>Visualize the aggregated data in a flow diagram, with various metrics like, average call duration, error percentage, along with some activities level metrics. </li> <li>Show interaction traces for a selected activity.</li> <li>Switch between multiple versions of analytics views.</li> <li>Color-coded links between activities based on the number of activity executions, and status.</li> </ul> <p></p>Good to Know [Optional]<p></p> <p></p>"},{"location":"main/CoreTrack_Mission6/#why-flow-analytics-is-important","title":"Why Flow Analytics is Important?","text":"<ol> <li> <p>Performance Monitoring: Tracks key metrics, such as flow usage, execution frequency, and processing times, helping you assess flow efficiency.</p> </li> <li> <p>Behavior Analysis: Identifies patterns in customer interactions and highlights potential issues, such as abandoned calls or potential loops.</p> </li> <li> <p>Proactive Optimization: Offers data-driven insights to fine-tune flow configurations, ensuring optimal performance and alignment with business objectives. </p></li></ol>"},{"location":"main/CoreTrack_Mission6/#how-to-use-the-flow-analytics-tool","title":"How to Use the Flow Analytics Tool","text":"<ol> <li> <p>On the Flow Designer, click on the Analyze tab at the bottom of the Flow Designer to open the Flow Analytics Tool</p> </li> <li> <p>Specify a DateTime range for the report. All calls we made happened today hence select Today option.</p> </li> <li> <p>Review visualizations and reports showing flow metrics, such as:</p> <ul> <li> <p>Total flow Executions</p> </li> <li> <p>Execution paths and their frequency</p> </li> <li> <p>Avarage flow duraion</p> </li> <li> <p>Average activities per contact</p> </li> <li> <p>Activity errors | Activity error %</p> </li> </ul> <p></p> </li> <li> <p>Drill down into specific interactions by clicking on desired node.</p> </li> <li> <p>If you spot any errors, click on that node. In the popped-up Activity Usage Details window, you can find call details, including Interaction ID, Start and End time, Duration, and a cross-launch link to the Debugger.</p> <p></p> </li> <li> <p>Observe older flow versions by selecting Version History. Then expand Other Versions. Choose anyone you like and click View. You might need to specify DateTime range again if the selected flow version was never executed withing the chosen range in Step 2.</p> <p></p> </li> </ol> <p>By leveraging the Flow Analytics Tool, you gain a comprehensive understanding of how your flows perform and interact with customers, enabling you to make data-backed decisions to improve both efficiency and user satisfaction.</p>"},{"location":"main/FinalBossFight_Hint1/","title":"FinalBossFight Hint1","text":"<ol> <li> <p>Debug the flow using the Webex Contact Center Debug tool to inspect HTTP request logs.</p> </li> <li> <p>Use Flow Designer Analytics to analyze call flow behavior and spot issues in logic execution.</p> </li> <li> <p>To find out correct JSON path to BossQueue use https://674481b1b4e2e04abea27c6e.mockapi.io/flowdesigner/Lab/DynVars?dn={DNIS}</p> </li> <li> <p>Replace {DNIS} with the provided Support Number number stripping +1</p> </li> <li>[Example:] If your number +14694096861, then your GET Query should be https://674481b1b4e2e04abea27c6e.mockapi.io/lowdesigner/Lab/DynVars?dn=4694096861</li> <li>Open Chrome browser and past your URL. You should get the follwoing result</li> <li></li> <li>Test JSON Path in the following tool https://jsonpath.com/</li> <li>Paste your GET URL into the Browser address line and copy the output in square brackets (including brackets)</li> <li>Open https://jsonpath.com/ and paste the copied response into Inputs window</li> <li>In JSONPath box copy and paste one of the path expression from FetchFlowSettings to verify your results.</li> <li></li> </ol>"},{"location":"main/FinalBossFight_Mission/","title":"FinalBossFight Mission","text":""},{"location":"main/FinalBossFight_Mission/#welcome-final-challenge-mission","title":"Welcome Final Challenge Mission!","text":""},{"location":"main/FinalBossFight_Mission/#story","title":"Story","text":"<p>In this short troubleshooting task you're are going to play a technical engineer who got a request from end customer regarding broken production flow. You as an engineer must fix the reported issue before contact center opens in just 30 mins.  So NO PRESSURE HERE AT ALL!!!</p>"},{"location":"main/FinalBossFight_Mission/#problem-description","title":"Problem Description","text":"<p>A customer reports a critical issue with their call flow: callers cannot land in the queue and are being redirected to the TAC Service number, which is not an intended outcome. Initially, the problem seemed to be related to the queue configuration, but after the customer attempted some adjustments, the situation worsened. Now, callers cannot even reach the queue node, and it seems like the HTTP request has been broken completely.</p>"},{"location":"main/FinalBossFight_Mission/#mission-details","title":"Mission Details","text":"<p>Your task is to identify and fix the issues causing this behavior. Specifically:</p> <ol> <li>The flow should correctly execute the HTTP request and retrieve the expected value of BossQueue.</li> <li>The queue node should reference the queue dynamically using a variable, ensuring that calls are directed to BossQueue.</li> <li>Calls should land in the intended queue.</li> <li>The phone in the middle of the room should ring, signaling a successful fix.</li> </ol>"},{"location":"main/FinalBossFight_Mission/#before-you-start-troubleshooting","title":"Before you start troubleshooting...","text":"<ol> <li> <p>[IMPORTANT] Download your troublshooting flow from shared folder.</p> </li> <li> <p>In Search in Drive line search for FinalBoss_Flow_Your_Attendee_ID. Then download the file to your local drive.</p> <p></p> </li> <li> <p>Switch to Control Hub and navigate to Flows. Click on Manage Flows, then select Import Flows.</p> </li> <li> <p>Click on Choose a file, then navigate to the folder where you saved your FinalBoss_Flow_Your_Attendee_ID. Select the file and click Open</p> </li> <li> <p>Click Import. This step will create your personal troubleshooting flow.</p> </li> <li> <p>Switch Edit from  Off to On. Switch Validation from  Off to On. Then Publish your flow.</p> <p></p> </li> <li> <p>Assign FinalBoss_Flow_Your_Attendee_ID to your Your_Attendee_ID_Channel.</p> <p></p> </li> <li> <p>Open the FinalBoss_Flow_Your_Attendee_ID and you're ready to start troubleshooting.</p> </li> </ol>"},{"location":"main/FinalBossFight_Mission/#competition-rewards","title":"Competition &amp; Rewards","text":"<p>A real IP phone is placed in the middle of the room, and an agent logs into Webex Desktop using that phone as the telephony option. Once the call flow is successfully fixed, the phone will ring, and the agent will accept the call. The first 2 participants to successfully make the phone ring\u2014WITHOUT CHEATING and by following the rules explained previously\u2014will win a prize. This encourages fast and accurate troubleshooting, making the exercise more engaging and competitive.</p> <p>This exercise will help attendees practice debugging and resolving common Webex Contact Center API integration issues. Ensure they document their troubleshooting steps to reinforce learning.</p>"},{"location":"main/FinalBossFight_Solution/","title":"Macro Rendering Error","text":""},{"location":"main/FinalBossFight_Solution/#macro-rendering-error","title":"Macro Rendering Error","text":"<p>File: <code>main/FinalBossFight_Solution.md</code></p> <p>UndefinedError: 'NewPhoneContact' is undefined</p> <pre><code>Traceback (most recent call last):\n  File \"/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/mkdocs_macros/plugin.py\", line 699, in render\n    return md_template.render(**page_variables)\n           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n  File \"/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/jinja2/environment.py\", line 1295, in render\n    self.environment.handle_exception()\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n  File \"/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/jinja2/environment.py\", line 942, in handle_exception\n    raise rewrite_traceback_stack(source=source)\n  File \"&lt;template&gt;\", line 1, in top-level template code\n  File \"/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/jinja2/environment.py\", line 490, in getattr\n    return getattr(obj, attribute)\njinja2.exceptions.UndefinedError: 'NewPhoneContact' is undefined\n</code></pre>"},{"location":"main/FlowDesignerOverview/","title":"FlowDesignerOverview","text":""},{"location":"main/FlowDesignerOverview/#canvas-main-flow-and-event-flows","title":"Canvas, Main Flow, and Event Flows","text":"<p>The Canvas is the gray working space on which you drop the activities. Use the controls in the bottom left side of the screen to move around the canvas and zoom in and zoom out. There are no constraints on the flow size or canvas usage.</p> <p>Flow Designer has two tabs that allow extra canvas space:   - Main Flow   - Event Flows</p> <p>These tabs logically separate different paths of your flow and create a more organized workspace.</p>"},{"location":"main/FlowDesignerOverview/#main-flow","title":"Main Flow","text":"<p>Use the Main Flow tab to script the primary flow based on the Trigger Event defined in the Start Flow activity. In the Main Flow tab, configure the end-to-end experience for a caller, starting from the Cisco Unified IP Interactive Voice Response (IVR) menu, until opting out or wrapping up the call. The flow contains predictable steps that the system executes in a sequence.</p>"},{"location":"main/FlowDesignerOverview/#event-flows","title":"Event Flows","text":"<p>At any point during the execution of the Main Flow, the system triggers events that interrupt the Main Flow. For example, when an agent answers a phone call, the caller\u2019s experience in the queue is interrupted. If you want to define unique behavior when these events are triggered, you can script optional Event Flows. Event Flows are asynchronous to the Main Flow. You can\u2019t predict if or when an Event Flow will be triggered. For this reason, Event Flows are optional and are intended to extend the Main Flow functionality.</p> <p>Note</p> <p>You can configure multiple event handling flows in the Event Flows canvas. Each event flow must have a unique start and end,with no shared activities.</p>"},{"location":"main/FlowDesignerOverview/#zoom-toolbar","title":"Zoom Toolbar","text":"<p>The zoom toolbar in Flow Designer has Global Properties, zoom-in, and zoom-out buttons to display the Global Properties pane, and minimize or maximize the contents in the canvas.</p> <ul> <li> <p>Global Properties: Click the  icon to open the Global Properties pane.</p> </li> <li> <p>Zoom-in: Click the icon  on the toolbar. When you reach the maximum limit, the button is disabled.</p> </li> <li> <p>Zoom-out: Click the icon on the toolbar. When you reach the maximum limit, the button is disabled.</p> </li> <li> <p>Fit to View: Click the icon  in the toolbar to adjust the canvas view so the entire flow is visible.</p> </li> <li> <p>Copy and paste activities: Click the icon  on the toolbar to copy and paste selected activities on the canvas.</p> </li> <li> <p>Undo: Click the icon  on the toolbar to undo the last performed action.</p> </li> <li> <p>Redo: Click the icon  on the toolbar to redo the last performed action.</p> </li> <li> <p>Arrange All: Click the icon   on the toolbar to organize all the activities in the flowdesigner canvas.</p> </li> </ul>"},{"location":"main/FlowDesignerOverview/#canvas-control-actions-and-shortcut-keys","title":"Canvas control actions and shortcut keys","text":"<p>To enhance the efficiency and productivity of flow developers, the Flow Designer canvas provides the following options:</p> <ul> <li> <p>Undo-redo actions: To undo and redo up to last 10 actions. Use the undo, redo buttons in thezoom toolbar or right-click on the canvas for the context menu.</p> </li> <li> <p>Cut, copy, and paste: To cut, copy, and paste activites and links within and across flows, event flows, and subflows.</p> </li> <li> <p>Auto arrange: To automatically organize all activities in the canvas for better understaning and easy maintenance.</p> </li> <li> <p>Display gridlines: To change the background of the canvas from dot grid to line grid and vice-eversa.</p> </li> <li> <p>Snap to grid: To align the activity to the grid line.</p> </li> <li> <p>Keyboard shortcuts: To edit quickly using keyboard shortcuts. Click the help icon. Choose Keyboard shortcuts to view the list of available keyboard shortcuts.</p> </li> </ul>"},{"location":"main/FlowDesignerOverview/#keyboard-shortcuts","title":"Keyboard Shortcuts","text":"<p>The Flow Designer canvas provides the following keyboard shortcuts:</p> Shortcut Key Description General Open Keyboard Shortcuts Ctrl + Alt + K Tools H Hand tool Shift + A Auto arrange Edit Ctrl + C Copy Ctrl + X Cut Ctrl + V Paste Ctrl + Z Undo Ctrl + Shift + Z Redo Backspace Delete Ctrl + A Select All View Ctrl + + Zoom in Ctrl + - Zoom out Ctrl + Scroll Zoom in or out Shift + Scroll Scroll left or right Shift + 1 Fit to view"},{"location":"main/Lab2/","title":"Lab2","text":"<p>Previously, it was not possible to make calls directly from a Flow to the WxCC API Gateway. Instead, a third-party application, such as WxConnect, was required to make an API call back to the WxCC API Gateway. The third-party application utilized the HTTP POST method to communicate with the WxCC API Gateway. Now, this functionality is directly supported within the Flow, allowing API calls to be made to the WxCC API Gateway without the need for an intermediary application. This simplifies the configuration process and eliminates an additional potential point of failure.</p>"},{"location":"main/Lab2/#how-it-was","title":"How it was","text":""},{"location":"main/Lab2/#how-it-is-now","title":"How it is now","text":""},{"location":"main/Lab2/#_1","title":"Lab2","text":""},{"location":"main/Lab3/","title":"Introductory Lab","text":""},{"location":"main/Lab3/#introductory-lab","title":"Introductory Lab","text":""},{"location":"main/Lab3/#another-task","title":"Another Task","text":"<p>Some more example</p>"},{"location":"main/PreRequisites/","title":"Configure Inbound Flow","text":""},{"location":"main/PreRequisites/#inbound-flow-configurations","title":"Inbound Flow Configurations.","text":"<p>Before you test Suggested Responses, we need to configure basic inbound call flow. </p>"},{"location":"main/PreRequisites/#task-1-configure-new-team","title":"Task 1. Configure new Team.","text":"<ol> <li> <p>Login to Control Hub with your admin credentials.</p> </li> <li> <p>Go to Contact Center service.     </p> </li> <li> <p>Find Team section.      </p> </li> <li> <p>Create new Team with name _SR_Team </p> </li> <li> <p>Open up the team you have just created and add your user to the team.      </p> </li> </ol>"},{"location":"main/PreRequisites/#task-2-configure-new-queue","title":"Task 2. Configure new Queue.","text":"<ol> <li> <p>Find Queue section and click on Create a queue.     </p> </li> <li> <p>Name the queue as _SR_Voice_Queue.     </p> </li> <li> <p>Scroll down until you will see Create a group section. Add your team that you created in the previouse Task to this team.      </p> </li> <li> <p>Configure Service level, Max time in queue and Default music in queue, then click Create </p> </li> </ol>"},{"location":"main/PreRequisites/#task-3-configure-new-flow","title":"Task 3. Configure new Flow.","text":"<ol> <li> <p>Find Queue section and click on Create Flows.     </p> </li> <li> <p>On the next window select Start Fresh.      </p> </li> <li> <p>Name the flow as _SR_Voice_Flow. Then click on Creat Flow.     </p> </li> <li> <p>Open up flow. Click on Edit and add Queue Contact node. Select the queue: _SR_Voice_Queue , that you have created earlier.     </p> </li> <li> <p>Add Play Music node. Connect Queue Contact node to the Play Music node. Loop Play Music node to itself. Select default music in queue file in the Play Music node.      </p> </li> <li> <p>Validate and Publish the flow with Latest label.      </p> </li> <li> <p>Go to Channels, and consult with the proctor which Channel to select to continue with the lab.  Channel_Suggested_Rerponses_1  Channel_Suggested_Rerponses_2  Channel_Suggested_Rerponses_3  Channel_Suggested_Rerponses_4  Channel_Suggested_Rerponses_5  </p> </li> <li> <p>Note what number is associated with your Channel. You will use it for further testings.      </p> </li> <li> <p>Open up the Channel and select the the flow _SR_Voice_Flow. Select a Music on hold file and lable as Latest </p> </li> <li> <p>At this point you should have the following configurations:</p> </li> </ol> <p>Entry Point/Channels:  Check with proctor</p> <p>Flow: _SR_Voice_Flow</p> <p>Queue:  _SR_Voice_Queue</p> <p>Team:  _SR_Team</p>"},{"location":"main/PreRequisites/#task-4-test-inbound-call-delivery-to-the-agent-desktop","title":"Task 4. Test inbound call delivery to the Agent Desktop.","text":"<ol> <li> <p>Login to the Desktop. You can do it from Quick Links section.      </p> </li> <li> <p>Select Desktop telephony option, make sure you select your team _SR_Team and click on Submit.      </p> </li> <li> <p>Change the state to Available.     </p> </li> <li> <p>Call the number that is assosiated with the Channel that you use for this lab.      </p> </li> <li> <p>Answer the inbound call     </p> </li> <li> <p>If you are able to answer the call you can continue to the Suggested Responses lab. </p> </li> </ol> <p>Congratulations, you have officially completed Getting Started section! \ud83c\udf89\ud83c\udf89 </p>"},{"location":"main/Related_Sessions/","title":"Related Sessions","text":"Session ID Subject Session Type LABCOL-2007 Webex Contact Center with Google CCAI Walk-in Lab LABCCT-2016 Autonomous Webex AI Agent functionalities in Webex Contact Center Walk-in Lab CTF-1039 Next-Gen Customer Experience: Exploring Webex Contact Center's AI Capabilities. TAC Speaker Sessions LABCOL-1027 Unlock the Power of AI in Webex Contact Center Walk-in Lab BRKCCT-2345 Boosting Customer Experience with Flow Orchestration in Webex Contact Center Breakout"},{"location":"main/overview/","title":"Lab Overview","text":"**Enter your Last Name as the Attendee ID** All configuration entries in the lab guide will be renamed to include your Attendee ID. Attendee ID: Save <p>Your stored Attendee ID is: No ID stored</p>"},{"location":"main/overview/#login-credentials","title":"Login Credentials.","text":"<p>Choose from any login credentials in the list below:</p>"},{"location":"main/overview/#what-is-suggested-responses","title":"What is Suggested Responses","text":"<p>Suggested Responses uses AI and natural language processing (NLP) to analyze incoming customer messages in real time. Based on the customer\u2019s query or message, the system presents agents with relevant, pre-composed response options based on the uploaded knowledgebase. Agents can review, edit, and send these responses, improving efficiency and consistency in customer communication. </p> <p>Key Benefits</p> <p>Increased Agent Productivity: Agents spend less time crafting responses from scratch. Consistency: Ensures standardized, high-quality messaging across agents. Faster Response Times: Reduces wait times for customers by accelerating agent replies. Reduced Training Time: New agents can leverage AI-suggested responses to handle queries more effectively.</p>"},{"location":"main/overview/#suggested-responses-ai-assistant-feature-for-flower-shop","title":"Suggested Responses AI Assistant Feature for Flower Shop","text":"<ul> <li>Recommending flowers based on customer preferences or occasions and share it with the agent. </li> <li>Calculating total price in real time and share it with the agent.  </li> <li>Check order status based on provided order ID, and share it with the agent. </li> </ul>"},{"location":"main/overview/#disclaimer","title":"Disclaimer","text":"<p>The lab design and configuration examples provided are for educational purposes. For production design queries, please consult your Cisco representative or an authorized Cisco partner. Let\u2019s get started and discover how Webex Contact Center Flow Designer takes customer experiences from good to great!</p>"}]}